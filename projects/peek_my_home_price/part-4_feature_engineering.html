<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adam Cseresznye">
<meta name="dcterms.date" content="2024-11-23">

<title>Peek My Home Price Part-4: Feature engineering – Adam Cseresznye</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon_lower_A.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-b697eb10549dbab267b4169cc0aac045.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d6f6a3df318ae731e7885b4e8bdb9d5b.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-BQF3JENT9N', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Peek My Home Price Part-4: Feature engineering – Adam Cseresznye">
<meta property="og:description" content="">
<meta property="og:site_name" content="Adam Cseresznye">
<meta name="twitter:title" content="Peek My Home Price Part-4: Feature engineering – Adam Cseresznye">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Adam Cseresznye</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../scientific_output.html"> 
<span class="menu-text">Scientific Output</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../articles.html"> 
<span class="menu-text">Articles</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/adamcseresznye"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/csenye22"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/adam-cseresznye"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Peek My Home Price Part-4: Feature engineering</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">Belgian Housing Market Insights</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Adam Cseresznye </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 23, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prepare-dataframe-before-modelling" id="toc-prepare-dataframe-before-modelling" class="nav-link active" data-scroll-target="#prepare-dataframe-before-modelling">Prepare dataframe before modelling</a>
  <ul class="collapse">
  <li><a href="#read-in-dataframe" id="toc-read-in-dataframe" class="nav-link" data-scroll-target="#read-in-dataframe">Read in dataframe</a></li>
  </ul></li>
  <li><a href="#cross-validation-strategy" id="toc-cross-validation-strategy" class="nav-link" data-scroll-target="#cross-validation-strategy">Cross-validation strategy</a></li>
  <li><a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">Outlier detection</a></li>
  <li><a href="#feature-engineering" id="toc-feature-engineering" class="nav-link" data-scroll-target="#feature-engineering">Feature Engineering</a>
  <ul class="collapse">
  <li><a href="#utilize-categorical-columns-for-grouping-and-transform-each-numerical-variable-based-on-the-median" id="toc-utilize-categorical-columns-for-grouping-and-transform-each-numerical-variable-based-on-the-median" class="nav-link" data-scroll-target="#utilize-categorical-columns-for-grouping-and-transform-each-numerical-variable-based-on-the-median">Utilize categorical columns for grouping and transform each numerical variable based on the median</a></li>
  <li><a href="#generate-bins-from-the-continuous-variables" id="toc-generate-bins-from-the-continuous-variables" class="nav-link" data-scroll-target="#generate-bins-from-the-continuous-variables">Generate bins from the continuous variables</a></li>
  <li><a href="#introduce-polynomial-features" id="toc-introduce-polynomial-features" class="nav-link" data-scroll-target="#introduce-polynomial-features">Introduce polynomial features</a>
  <ul class="collapse">
  <li><a href="#n1" id="toc-n1" class="nav-link" data-scroll-target="#n1">n=1</a></li>
  <li><a href="#n2" id="toc-n2" class="nav-link" data-scroll-target="#n2">n=2</a></li>
  </ul></li>
  <li><a href="#form-clusters-of-instances-using-k-means-clustering" id="toc-form-clusters-of-instances-using-k-means-clustering" class="nav-link" data-scroll-target="#form-clusters-of-instances-using-k-means-clustering">Form clusters of instances using k-means clustering</a></li>
  <li><a href="#implement-other-ideas-derived-from-empirical-observations-or-assumptions" id="toc-implement-other-ideas-derived-from-empirical-observations-or-assumptions" class="nav-link" data-scroll-target="#implement-other-ideas-derived-from-empirical-observations-or-assumptions">Implement other ideas derived from empirical observations or assumptions</a></li>
  </ul></li>
  <li><a href="#summary-table-of-the-tested-conditions" id="toc-summary-table-of-the-tested-conditions" class="nav-link" data-scroll-target="#summary-table-of-the-tested-conditions">Summary table of the tested conditions</a></li>
  <li><a href="#final-feature-selection" id="toc-final-feature-selection" class="nav-link" data-scroll-target="#final-feature-selection">Final feature selection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://images.unsplash.com/photo-1549407408-4b016f497e4d?q=80&amp;w=2070&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Photo by Christian Allard UnSplash</figcaption>
</figure>
</div>
<p>In Part 3, we looked at the significance of features in the initial scraped dataset using both the <code>feature_importances_</code> method of CatBoostRegressor and SHAP values. We conducted feature elimination based on their importance and predictive capability.</p>
<p>In this upcoming section, we’ll implement a robust cross-validation strategy to accurately and consistently evaluate our model’s performance across multiple folds of the data. We will also identify and address potential outliers within our dataset, which is crucial to prevent their influence on the model’s predictions.</p>
<p>Additionally, we’ll further refine and expand our feature engineering efforts by exploring new methodologies to create informative features that increase our model’s predictive capabilities. Looking forward to these steps!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can explore the project’s app on its <a href="https://peek-my-home-price.fly.dev/">website</a>. For more details, visit the <a href="https://github.com/adamcseresznye/peek_my_home_price">GitHub repository</a>.</p>
<p>Check out the series for a deeper dive: - <a href="https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-1_characterizing_the_data.html">Part 1: Characterizing the Data</a> - <a href="https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-2_building_a_baseline_model.html">Part 2: Building a Baseline Model</a> - <a href="https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-3_feature_selection.html">Part 3: Feature Selection</a> - <a href="https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-4_feature_engineering.html">Part 4: Feature Engineering</a> - <a href="https://adamcseresznye.github.io/blog/projects/peek_my_home_price/part-5_fine_tuning.html">Part 5: Fine-Tuning</a></p>
</div>
</div>
<div id="44e3f512-9015-4941-9e7d-12db057fee2d" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>sys.path.append(<span class="bu">str</span>(Path.cwd()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cc3c6a54-530c-4491-bb08-3dfc054d78a6" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-tags="[]" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> List, Optional, Tuple</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> catboost</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> clear_output</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lets_plot <span class="im">import</span> <span class="op">*</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lets_plot.mapping <span class="im">import</span> as_discrete</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> (</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    cluster,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    compose,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    ensemble,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    impute,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    metrics,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    model_selection,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    neighbors,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    pipeline,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    preprocessing,</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> helper <span class="im">import</span> feature_engineering, pre_process, train_model, utils</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>LetsPlot.setup_html()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

            <div id="yjSUWw"></div>
            <script type="text/javascript" data-lets-plot-script="library">
                if(!window.letsPlotCallQueue) {
                    window.letsPlotCallQueue = [];
                }; 
                window.letsPlotCall = function(f) {
                    window.letsPlotCallQueue.push(f);
                };
                (function() {
                    var script = document.createElement("script");
                    script.type = "text/javascript";
                    script.src = "https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.1/js-package/distr/lets-plot.min.js";
                    script.onload = function() {
                        window.letsPlotCall = function(f) {f();};
                        window.letsPlotCallQueue.forEach(function(f) {f();});
                        window.letsPlotCallQueue = [];
                        
                    };
                    script.onerror = function(event) {
                        window.letsPlotCall = function(f) {};    // noop
                        window.letsPlotCallQueue = [];
                        var div = document.createElement("div");
                        div.style.color = 'darkred';
                        div.textContent = 'Error loading Lets-Plot JS';
                        document.getElementById("yjSUWw").appendChild(div);
                    };
                    var e = document.getElementById("yjSUWw");
                    e.appendChild(script);
                })()
            </script>
            
</div>
</div>
<section id="prepare-dataframe-before-modelling" class="level1">
<h1>Prepare dataframe before modelling</h1>
<section id="read-in-dataframe" class="level2">
<h2 class="anchored" data-anchor-id="read-in-dataframe">Read in dataframe</h2>
<p>Drawing from our findings in part 3, particularly with regards to our initial feature reduction efforts, we’ve developed a function named <code>prepare_data_for_modelling</code>. This function resides in the <code>pre_process.py</code> file, ensuring its reusability. The function performs essential data preprocessing steps, which include:</p>
<ol type="1">
<li>Randomly shuffling the rows in the DataFrame.</li>
<li>Transforming the ‘price’ column by taking the base 10 logarithm.</li>
<li>Handling missing values in categorical variables by replacing them with ‘missing value.’</li>
<li>Separating the dataset into features (X) and the target variable (y).</li>
</ol>
<p>Let’s dive into the details of this function and prepare our X and y for the subsequent processing pipeline.</p>
<div id="72d6ba3f-01d0-4f8d-9a08-1c3d99c01210" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_parquet(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    Path.cwd().joinpath(<span class="st">"data"</span>).joinpath(<span class="st">"2023-10-01_Processed_dataset_for_NB_use.gzip"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="d5ad608f-e618-4753-ae85-5ee5d94dd62f" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_data(df: pd.DataFrame) <span class="op">-&gt;</span> Tuple[pd.DataFrame, pd.Series]:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Prepare data for machine learning modeling.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function takes a DataFrame and prepares it for machine learning by performing the following steps:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Randomly shuffles the rows of the DataFrame.</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Converts the 'price' column to the base 10 logarithm.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Fills missing values in categorical variables with 'missing value'.</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">    4. Separates the features (X) and the target (y).</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">    - df (pd.DataFrame): The input DataFrame containing the dataset.</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">    - Tuple[pd.DataFrame, pd.Series]: A tuple containing the prepared features (X) and the target (y).</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Example use case:</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your dataset into a DataFrame (e.g., df)</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co">    df = load_data()</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">    # Prepare the data for modeling</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y = prepare_data_for_modelling(df)</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">    # Now you can use X and y for machine learning tasks.</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    processed_df <span class="op">=</span> (</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>utils.Configuration.seed)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        .assign(price<span class="op">=</span><span class="kw">lambda</span> df: np.log10(df.price))</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fill missing categorical variables with "missing value"</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> processed_df.columns:</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> processed_df[col].dtype.name <span class="kw">in</span> (<span class="st">"bool"</span>, <span class="st">"object"</span>, <span class="st">"category"</span>):</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>            processed_df[col] <span class="op">=</span> processed_df[col].fillna(<span class="st">"missing value"</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Separate features (X) and target (y)</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> processed_df.loc[:, utils.Configuration.features_to_keep_v1]</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> processed_df[utils.Configuration.target_col]</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Shape of X and y: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="5cd828f2-657c-49d9-96d3-7a731a64d95f" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> prepare_data(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of X and y: (3660, 16), (3660,)</code></pre>
</div>
</div>
</section>
</section>
<section id="cross-validation-strategy" class="level1">
<h1>Cross-validation strategy</h1>
<p>Our next critical step is to establish a well-structured cross-validation strategy. This step is imperative as it enables us to assess the effectiveness of various feature engineering approaches without risking overfitting our model. A robust cross-validation strategy ensures that our model’s performance evaluations are reliable and that the insights gained are generalizable to new data. To accomplish this, we will employ <code>RepeatedKFold</code> validation, setting the parameters with n_splits as 10 and n_repeats as 1.</p>
<p>In essence, this configuration signifies that we will perform a 10-fold cross-validation, and this entire process will be repeated once. Importantly, due to the modular nature of this function, we retain the flexibility to easily adapt and alter the design of our cross-validation strategy as needed.</p>
<div id="fd6b5995-8d42-4139-8795-c29d7c258151" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_catboost_CV(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    y: pd.Series,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    n_splits: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    n_repeats: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    pipeline: Optional[<span class="bu">object</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[<span class="bu">float</span>, <span class="bu">float</span>]:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Perform Cross-Validation with CatBoost for regression.</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">    This function conducts Cross-Validation using CatBoost for regression tasks. It iterates</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">    through folds, trains CatBoost models, and computes the mean and standard deviation of the</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Root Mean Squared Error (RMSE) scores across folds.</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co">    - X (pd.DataFrame): The feature matrix.</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">    - y (pd.Series): The target variable.</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">    - n_splits (int, optional): The number of splits in K-Fold cross-validation.</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co">      Defaults to 2.</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co">    - n_repeats (int, optional): The number of times the K-Fold cross-validation is repeated.</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co">      Defaults to 1.</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">    - pipeline (object, optional): Optional data preprocessing pipeline. If provided,</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co">      it's applied to the data before training the model. Defaults to None.</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co">    - Tuple[float, float]: A tuple containing the mean RMSE and standard deviation of RMSE</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co">      scores across cross-validation folds.</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your feature matrix (X) and target variable (y)</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y = load_data()</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">    # Perform Cross-Validation with CatBoost</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co">    mean_rmse, std_rmse = run_catboost_CV(X, y, n_splits=5, n_repeats=2, pipeline=data_pipeline)</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co">    print(f"Mean RMSE: {mean_rmse:.4f}")</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a><span class="co">    print(f"Standard Deviation of RMSE: {std_rmse:.4f}")</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co">    Notes:</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a><span class="co">    - Ensure that the input data `X` and `y` are properly preprocessed and do not contain any</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="co">      missing values.</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="co">    - The function uses CatBoost for regression with optional data preprocessing via the `pipeline`.</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="co">    - RMSE is a common metric for regression tasks, and lower values indicate better model</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co">      performance.</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract feature names and data types</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> X.columns[<span class="op">~</span>X.columns.<span class="bu">str</span>.contains(<span class="st">"price"</span>)]</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>    numerical_features <span class="op">=</span> X.select_dtypes(<span class="st">"number"</span>).columns.to_list()</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    categorical_features <span class="op">=</span> X.select_dtypes(<span class="st">"object"</span>).columns.to_list()</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a K-Fold cross-validator</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    CV <span class="op">=</span> model_selection.RepeatedKFold(</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        n_splits<span class="op">=</span>n_splits, n_repeats<span class="op">=</span>n_repeats, random_state<span class="op">=</span>utils.Configuration.seed</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> train_fold_index, val_fold_index <span class="kw">in</span> tqdm(CV.split(X)):</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        X_train_fold, X_val_fold <span class="op">=</span> X.loc[train_fold_index], X.loc[val_fold_index]</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        y_train_fold, y_val_fold <span class="op">=</span> y.loc[train_fold_index], y.loc[val_fold_index]</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply optional data preprocessing pipeline</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> pipeline <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>            X_train_fold <span class="op">=</span> pipeline.fit_transform(X_train_fold)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>            X_val_fold <span class="op">=</span> pipeline.transform(X_val_fold)</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create CatBoost datasets</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        catboost_train <span class="op">=</span> Pool(</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            X_train_fold,</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            y_train_fold,</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>            cat_features<span class="op">=</span>categorical_features,</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>        catboost_valid <span class="op">=</span> Pool(</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>            X_val_fold,</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>            y_val_fold,</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>            cat_features<span class="op">=</span>categorical_features,</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize and train the CatBoost model</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> catboost.CatBoostRegressor(<span class="op">**</span>utils.Configuration.catboost_params)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>        model.fit(</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>            catboost_train,</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>            eval_set<span class="op">=</span>[catboost_valid],</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>            early_stopping_rounds<span class="op">=</span>utils.Configuration.early_stopping_round,</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>            verbose<span class="op">=</span>utils.Configuration.verbose,</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>            use_best_model<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate OOF validation predictions</span></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>        valid_pred <span class="op">=</span> model.predict(X_val_fold)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>        RMSE_score <span class="op">=</span> metrics.root_mean_squared_error(y_val_fold, valid_pred)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>        results.append(RMSE_score)</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(results), np.std(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now, let’s proceed to train our model with the updated settings:</p>
<div id="45fee9ec-c1d7-4768-ad35-e94dc7eeddac" class="cell" data-scrolled="true" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_model.run_catboost_CV(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(0.11251233080551612, 0.004459362099695207)</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that we’ve reduced the number of iterations in Notebook 6 compared to Notebook 5 to minimize the training duration. In Notebook 5: iterations = 1000, default learning rate = 0.03 In Notebook 6: iterations = 100, learning rate = 0.2</p>
<p>The performance of the baseline model: 0.1125</p>
</div>
</div>
</section>
<section id="outlier-detection" class="level1">
<h1>Outlier detection</h1>
<p>An outlier is a data point that significantly differs from the rest of the data. One common way to define an outlier is a data point that falls more than 1.5 interquartile ranges (IQRs) below the first quartile or above the third quartile. Detecting and removing outliers from the dataset is crucial for building a stable model that can effectively generalize to new data.</p>
<p>When we create a scatter plot of our features (as shown in <a href="#fig-fig1" class="quarto-xref">Figure&nbsp;1</a>), such as cadastral income against living area, and adjust the points’ color and size based on price, we can identify at least two data points that notably deviate from the expected range of values. One data point suggests a 300 m2 property is associated with a cadastral income exceeding 320,000 EURO, while the other point indicates a 2,500 EUR cadastral income for an 11,000 m2 property. Both observations seem implausible when compared to the majority of data points on the graph.</p>
<div id="cell-fig-fig1" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pd.concat([X, y], axis<span class="op">=</span><span class="dv">1</span>).pipe(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> df: ggplot(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        df, aes(<span class="st">"cadastral_income"</span>, <span class="st">"living_area"</span>, fill<span class="op">=</span><span class="st">"price"</span>, size<span class="op">=</span><span class="st">"price"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> geom_point(alpha<span class="op">=</span><span class="fl">0.5</span>, shape<span class="op">=</span><span class="dv">21</span>, stroke<span class="op">=</span><span class="fl">0.5</span>, show_legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> scale_fill_continuous(low<span class="op">=</span><span class="st">"#1a9641"</span>, high<span class="op">=</span><span class="st">"#d7191c"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> labs(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Assessing Potential Outliers"</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        subtitle<span class="op">=</span><span class="st">""" Outliers pose a challenge for gradient boosting methods since boosting constructs each tree based on the errors of the previous trees. </span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="st">        Outliers, having significantly larger errors than non-outliers, can excessively divert the model's attention toward these data points.</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="st">            """</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">"Cadastral income (EUR)"</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">"Living area (m2)"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> theme(</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        plot_subtitle<span class="op">=</span>element_text(</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>            size<span class="op">=</span><span class="dv">12</span>, face<span class="op">=</span><span class="st">"italic"</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        ),  <span class="co"># Customize subtitle appearance</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        plot_title<span class="op">=</span>element_text(size<span class="op">=</span><span class="dv">15</span>, face<span class="op">=</span><span class="st">"bold"</span>),  <span class="co"># Customize title appearance</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> ggsize(<span class="dv">800</span>, <span class="dv">600</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-fig1" class="cell-output cell-output-display quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="8">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fig1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
   <div id="1psbr0"></div>
   <script type="text/javascript" data-lets-plot-script="plot">
   
   (function() {
   // ----------
   
   var containerDiv = document.getElementById("1psbr0");
   var observer = new ResizeObserver(function(entries) {
       for (let entry of entries) {
           var width = containerDiv.clientWidth
           if (entry.contentBoxSize && width > 0) {
           
               // Render plot
               if (observer) {
                   observer.disconnect();
                   observer = null;
               }

               var plotSpec={
"data":{
"cadastral_income":[565.0,3544.0,1725.0,966.0,1690.0,2102.0,2382.0,577.0,3661.0,1221.0,409.0,396.0,null,1036.0,560.0,null,552.0,503.0,671.0,null,485.0,1251.0,594.0,null,329.0,867.0,373.0,null,4318.0,null,964.0,342.0,2435.0,null,2150.0,null,3973.0,null,1095.0,523.0,768.0,1891.0,8398.0,617.0,null,632.0,580.0,1857.0,262.0,null,275.0,null,2331.0,743.0,677.0,2875.0,null,863.0,1378.0,384.0,1155.0,null,1383.0,null,1417.0,1232.0,917.0,1068.0,359.0,393.0,537.0,1670.0,545.0,720.0,218.0,2530.0,257.0,733.0,1641.0,17668.0,991.0,446.0,4568.0,528.0,1289.0,4619.0,1265.0,5862.0,1960.0,2170.0,1831.0,906.0,null,399.0,1460.0,1368.0,null,1442.0,null,594.0,743.0,null,null,1243.0,4191.0,994.0,1088.0,505.0,454.0,1077.0,3408.0,1100.0,1048.0,null,1152.0,875.0,1462.0,null,940.0,745.0,404.0,1351.0,359.0,null,4972.0,null,745.0,3391.0,748.0,null,1730.0,1950.0,260.0,297.0,4241.0,null,1115.0,null,314.0,null,178.0,1704.0,417.0,null,2159.0,567.0,669.0,1078.0,1203.0,4102.0,384.0,400.0,364.0,1668.0,3205.0,451.0,1911.0,8205.0,354.0,825.0,1579.0,705.0,null,1384.0,1273.0,748.0,3569.0,844.0,1489.0,832.0,411.0,4254.0,701.0,null,null,5662.0,null,null,478.0,null,2243.0,1725.0,1641.0,1867.0,384.0,332.0,1921.0,1705.0,1221.0,2010.0,704.0,9073.0,941.0,644.0,909.0,307.0,456.0,428.0,968.0,2031.0,null,843.0,1829.0,356.0,10299.0,470.0,537.0,null,null,1534.0,386.0,3329.0,924.0,null,null,956.0,2452.0,null,411.0,453.0,300.0,468.0,842.0,3535.0,null,null,2426.0,736.0,485.0,null,475.0,708.0,421.0,498.0,1057.0,666.0,3658.0,733.0,1075.0,324.0,1077.0,1336.0,null,627.0,446.0,1448.0,null,369.0,399.0,427.0,835.0,803.0,2425.0,null,2602.0,959.0,1410.0,3354.0,1314.0,null,479.0,2667.0,9258.0,584.0,2119.0,964.0,5764.0,null,2357.0,null,555.0,461.0,5514.0,1472.0,456.0,1570.0,672.0,590.0,null,2969.0,1462.0,null,371.0,703.0,413.0,389.0,3235.0,null,413.0,1137.0,null,1051.0,null,711.0,798.0,979.0,357.0,356.0,null,889.0,745.0,401.0,480.0,null,1043.0,1095.0,1098.0,577.0,3160.0,1169.0,6492.0,795.0,580.0,2511.0,537.0,null,970.0,745.0,2381.0,974.0,8934.0,1487.0,391.0,null,3057.0,661.0,456.0,1368.0,774.0,3758.0,3479.0,964.0,2037.0,794.0,694.0,354.0,11514.0,1707.0,null,1095.0,1115.0,337.0,1177.0,747.0,null,null,797.0,193.0,808.0,641.0,4348.0,619.0,607.0,7615.0,1229.0,1522.0,857.0,245.0,null,166.0,1031.0,1797.0,1105.0,396.0,7615.0,738.0,1643.0,541.0,985.0,null,946.0,886.0,485.0,262.0,2664.0,null,null,369.0,2362.0,1921.0,null,null,934.0,423.0,null,818.0,324.0,2388.0,1497.0,null,493.0,310.0,439.0,533.0,3755.0,440.0,null,2027.0,2397.0,745.0,2018.0,1233.0,468.0,672.0,483.0,1083.0,951.0,3574.0,null,1.0,1170.0,null,637.0,609.0,661.0,701.0,1707.0,533.0,934.0,2766.0,1400.0,null,null,978.0,1032.0,4637.0,594.0,null,2474.0,1177.0,426.0,1155.0,1220.0,513.0,661.0,1205.0,1500.0,null,null,1.0,646.0,null,991.0,594.0,2816.0,594.0,426.0,1234.0,385.0,752.0,1447.0,null,null,3512.0,3656.0,946.0,319.0,3378.0,null,369.0,1013.0,null,null,4930.0,934.0,1125.0,255.0,977.0,null,1683.0,436.0,9226.0,1373.0,911.0,3277.0,726.0,null,2164.0,4081.0,790.0,2029.0,null,654.0,1098.0,null,null,7454.0,141.0,1928.0,1400.0,2000.0,446.0,409.0,1333.0,2216.0,726.0,null,1536.0,904.0,2540.0,1928.0,1229.0,131.0,659.0,2789.0,572.0,751.0,929.0,904.0,1643.0,1260.0,354.0,null,null,780.0,null,null,1563.0,null,860.0,756.0,null,1719.0,1621.0,1207.0,422.0,1499.0,267.0,1626.0,2263.0,867.0,null,null,1507.0,2678.0,null,null,null,661.0,null,280.0,null,2493.0,2895.0,532.0,411.0,1127.0,null,726.0,7545.0,428.0,230.0,624.0,null,257.0,557.0,null,null,1665.0,510.0,684.0,950.0,892.0,989.0,2897.0,286.0,1932.0,426.0,884.0,428.0,2223.0,887.0,951.0,1065.0,2654.0,null,1483.0,1070.0,2927.0,1999.0,1134.0,906.0,743.0,483.0,1112.0,637.0,609.0,421.0,3772.0,595.0,757.0,1876.0,460.0,null,6000.0,748.0,1593.0,4459.0,311.0,1765.0,1520.0,1666.0,3341.0,5141.0,666.0,null,379.0,562.0,2412.0,1585.0,964.0,null,887.0,1083.0,381.0,1930.0,991.0,2883.0,1395.0,null,590.0,453.0,1249.0,1253.0,null,1305.0,null,976.0,null,null,1722.0,null,520.0,2253.0,null,488.0,null,1075.0,null,null,2744.0,294.0,240.0,562.0,1054.0,376.0,null,587.0,830.0,829.0,null,null,2723.0,null,null,null,960.0,1137.0,null,347.0,null,748.0,null,299.0,435.0,null,7969.0,null,404.0,307.0,1172.0,389.0,1269.0,741.0,1651.0,444.0,null,438.0,650.0,null,1000.0,594.0,null,2379.0,413.0,1411.0,711.0,1075.0,704.0,716.0,1712.0,1212.0,857.0,1498.0,262.0,2436.0,374.0,1274.0,1224.0,1353.0,null,971.0,1184.0,483.0,2518.0,3368.0,null,713.0,188.0,643.0,null,518.0,1318.0,941.0,344.0,431.0,685.0,545.0,167.0,1729.0,389.0,null,null,null,5902.0,654.0,null,1108.0,null,null,560.0,null,681.0,1219.0,null,775.0,743.0,356.0,723.0,4154.0,null,5433.0,null,230.0,1368.0,9641.0,1732.0,null,null,null,null,356.0,379.0,3423.0,833.0,null,3068.0,1491.0,2305.0,1029.0,823.0,334.0,285.0,505.0,844.0,null,null,775.0,1079.0,302.0,309.0,257.0,1368.0,644.0,1125.0,327.0,733.0,857.0,761.0,713.0,428.0,7102.0,810.0,723.0,688.0,null,null,989.0,null,647.0,699.0,832.0,null,1139.0,null,1308.0,334.0,334.0,178.0,381.0,null,490.0,null,203.0,409.0,null,450.0,null,200.0,438.0,2200.0,609.0,null,1192.0,1017.0,649.0,3344.0,949.0,391.0,654.0,914.0,1525.0,null,141.0,null,652.0,356.0,741.0,505.0,955.0,414.0,2258.0,null,927.0,928.0,null,647.0,4395.0,1519.0,594.0,148.0,1179.0,null,null,681.0,6219.0,9641.0,773.0,null,1740.0,4438.0,null,null,1556.0,4923.0,409.0,2161.0,2322.0,745.0,null,1336.0,null,2699.0,827.0,855.0,546.0,818.0,1170.0,1623.0,1588.0,328.0,441.0,155.0,483.0,375.0,550.0,null,594.0,391.0,602.0,250.0,1555.0,941.0,483.0,327.0,1467.0,299.0,null,null,1771.0,662.0,1.0,627.0,411.0,null,535.0,484.0,416.0,1.0,912.0,1308.0,1447.0,627.0,1274.0,696.0,1351.0,1953.0,null,1231.0,2278.0,528.0,null,874.0,3353.0,1243.0,891.0,427.0,null,null,1477.0,994.0,3487.0,352.0,689.0,null,null,1330.0,null,748.0,null,450.0,null,527.0,329.0,null,993.0,null,1382.0,815.0,270.0,404.0,1767.0,null,188.0,540.0,485.0,480.0,399.0,1219.0,203.0,1663.0,1279.0,null,null,2533.0,1740.0,3249.0,null,1318.0,null,756.0,490.0,null,null,null,null,1200.0,993.0,null,1370.0,892.0,241.0,763.0,731.0,720.0,null,1812.0,1395.0,792.0,1901.0,708.0,540.0,661.0,599.0,1083.0,null,408.0,null,null,359.0,438.0,2098.0,223.0,null,302.0,null,1328.0,404.0,null,4632.0,1866.0,3455.0,582.0,1100.0,736.0,567.0,2968.0,1333.0,615.0,null,1121.0,441.0,null,616.0,null,1080.0,713.0,699.0,466.0,733.0,null,604.0,null,3155.0,null,null,430.0,1333.0,1090.0,1861.0,2404.0,1202.0,423.0,642.0,1103.0,381.0,null,1416.0,null,1346.0,1277.0,1653.0,1492.0,446.0,1554.0,495.0,550.0,729.0,451.0,850.0,null,233.0,1984.0,null,null,552.0,null,null,null,307.0,1250.0,null,null,null,525.0,1229.0,235.0,null,1402.0,null,1058.0,924.0,null,354.0,706.0,575.0,283.0,1734.0,743.0,805.0,1300.0,null,null,354.0,272.0,721.0,218.0,470.0,1590.0,1227.0,451.0,1651.0,446.0,846.0,745.0,190.0,null,540.0,267.0,null,519.0,1162.0,500.0,null,1026.0,895.0,639.0,null,3339.0,609.0,770.0,761.0,null,null,314.0,1260.0,4437.0,3048.0,541.0,302.0,1683.0,1132.0,1417.0,1232.0,619.0,1196.0,674.0,null,3480.0,1313.0,2344.0,898.0,2031.0,901.0,4135.0,null,1950.0,1249.0,676.0,1147.0,572.0,334.0,451.0,3650.0,356.0,1244.0,null,6145.0,null,288.0,5000.0,485.0,302.0,1891.0,1051.0,560.0,1363.0,428.0,null,null,723.0,580.0,1849.0,691.0,218.0,470.0,701.0,850.0,282.0,1298.0,null,280.0,null,800.0,1830.0,1150.0,null,1463.0,991.0,689.0,751.0,446.0,null,252.0,null,1387.0,1028.0,8205.0,979.0,2313.0,null,null,666.0,255.0,1898.0,null,498.0,2070.0,3472.0,1077.0,409.0,null,3356.0,2881.0,865.0,null,null,575.0,null,850.0,736.0,822.0,223.0,654.0,1224.0,793.0,null,478.0,848.0,2203.0,294.0,711.0,1532.0,1742.0,2540.0,1238.0,5966.0,null,null,566.0,4640.0,2811.0,1249.0,1782.0,null,270.0,726.0,1202.0,860.0,2012.0,1317.0,775.0,null,1510.0,861.0,601.0,678.0,null,null,null,1740.0,602.0,669.0,1308.0,681.0,1115.0,null,null,null,15311.0,null,1435.0,null,399.0,2583.0,null,285.0,861.0,669.0,2029.0,418.0,609.0,1325.0,null,null,865.0,743.0,912.0,346.0,520.0,6336.0,null,644.0,null,null,null,null,1197.0,510.0,2110.0,1078.0,1197.0,745.0,651.0,1534.0,277.0,2072.0,null,1641.0,984.0,1177.0,623.0,342.0,null,937.0,624.0,1115.0,761.0,1028.0,859.0,740.0,939.0,867.0,255.0,null,562.0,488.0,272.0,438.0,200.0,733.0,1070.0,832.0,null,1.0,671.0,null,458.0,1083.0,1060.0,924.0,7578.0,520.0,null,null,1095.0,null,null,716.0,841.0,369.0,null,542.0,404.0,1016.0,2623.0,3194.0,813.0,2223.0,2402.0,523.0,null,3200.0,1839.0,1546.0,2773.0,495.0,null,3175.0,2580.0,2949.0,9816.0,1363.0,null,null,1665.0,4151.0,1936.0,444.0,666.0,null,1526.0,null,1889.0,748.0,299.0,1001.0,461.0,1078.0,1683.0,null,1132.0,319.0,450.0,1653.0,505.0,null,729.0,356.0,624.0,4638.0,322.0,9816.0,null,917.0,null,922.0,2494.0,null,644.0,1859.0,592.0,3194.0,302.0,null,535.0,339.0,1653.0,592.0,436.0,847.0,297.0,448.0,7578.0,7858.0,1629.0,null,711.0,418.0,513.0,1021.0,612.0,332.0,681.0,3021.0,651.0,1251.0,null,461.0,10440.0,null,809.0,2230.0,1888.0,334.0,344.0,374.0,null,438.0,3389.0,416.0,null,1395.0,null,7636.0,334.0,null,825.0,4449.0,712.0,1200.0,null,1078.0,null,1840.0,446.0,null,null,371.0,886.0,1606.0,1108.0,577.0,1648.0,483.0,null,1105.0,964.0,1569.0,680.0,376.0,null,1984.0,2648.0,null,null,637.0,1140.0,2154.0,601.0,2430.0,1179.0,2558.0,3155.0,1494.0,1424.0,547.0,401.0,null,411.0,3055.0,701.0,274.0,636.0,null,null,null,899.0,1065.0,null,null,1068.0,540.0,974.0,745.0,1490.0,1372.0,488.0,1234.0,3024.0,503.0,866.0,837.0,1023.0,203.0,5583.0,null,null,252.0,1135.0,null,889.0,748.0,2459.0,null,410.0,834.0,607.0,285.0,4375.0,799.0,2952.0,498.0,null,347.0,559.0,null,936.0,342.0,886.0,null,null,null,622.0,520.0,1650.0,1417.0,10259.0,671.0,1614.0,260.0,713.0,424.0,null,718.0,1432.0,535.0,1306.0,359.0,3896.0,1740.0,632.0,897.0,594.0,null,951.0,2508.0,748.0,1705.0,2368.0,2699.0,485.0,null,null,3805.0,7000.0,null,768.0,421.0,1649.0,1908.0,1448.0,null,null,null,null,937.0,null,1280.0,3145.0,704.0,324.0,1417.0,421.0,1489.0,759.0,907.0,651.0,523.0,1274.0,1859.0,676.0,1008.0,null,369.0,null,null,929.0,1001.0,4105.0,827.0,927.0,726.0,2181.0,null,1463.0,null,null,310.0,409.0,374.0,1365.0,832.0,1266.0,741.0,null,743.0,null,1720.0,1876.0,1021.0,743.0,277.0,2658.0,1125.0,1003.0,696.0,1370.0,null,700.0,337.0,768.0,857.0,550.0,2451.0,418.0,null,930.0,null,503.0,2791.0,531.0,2691.0,347.0,null,996.0,713.0,493.0,824.0,1730.0,190.0,255.0,1083.0,3477.0,892.0,317.0,null,null,679.0,314.0,null,2092.0,812.0,480.0,228.0,1008.0,642.0,null,null,949.0,null,2104.0,746.0,null,955.0,374.0,1973.0,null,1070.0,753.0,1467.0,null,949.0,676.0,1452.0,743.0,696.0,null,1298.0,847.0,2507.0,null,1063.0,342.0,3368.0,560.0,null,null,null,366.0,1.0,null,416.0,1981.0,489.0,6216.0,null,493.0,463.0,870.0,374.0,4300.0,640.0,793.0,null,535.0,520.0,552.0,713.0,353.0,270.0,1131.0,null,12295.0,384.0,2678.0,5514.0,null,2643.0,3118.0,null,2850.0,624.0,1303.0,314.0,572.0,3542.0,1065.0,1218.0,2607.0,1169.0,490.0,1408.0,352.0,518.0,1983.0,2732.0,null,669.0,null,3455.0,534.0,669.0,926.0,null,null,null,3339.0,9792.0,null,860.0,360.0,649.0,null,413.0,1140.0,1507.0,2557.0,2669.0,1063.0,361.0,3785.0,1117.0,2552.0,1157.0,5282.0,941.0,1202.0,8633.0,1209.0,6392.0,null,778.0,225.0,null,null,545.0,513.0,2751.0,null,3222.0,683.0,725.0,530.0,726.0,null,2343.0,719.0,210.0,1093.0,1031.0,2678.0,604.0,209.0,2020.0,699.0,927.0,5379.0,1249.0,1134.0,980.0,null,257.0,null,1083.0,309.0,365.0,867.0,691.0,1088.0,384.0,242.0,394.0,null,290.0,1137.0,null,242.0,1757.0,null,808.0,950.0,503.0,2735.0,705.0,1110.0,3337.0,302.0,3570.0,null,3579.0,null,560.0,7578.0,7662.0,520.0,536.0,4300.0,482.0,1405.0,1041.0,null,1649.0,1043.0,698.0,1606.0,701.0,null,1221.0,null,2156.0,980.0,null,654.0,2508.0,1742.0,736.0,4612.0,535.0,364.0,859.0,565.0,555.0,1147.0,null,1065.0,1236.0,null,null,2216.0,3200.0,1135.0,718.0,461.0,1224.0,null,null,2545.0,null,1341.0,485.0,985.0,2530.0,267.0,718.0,1272.0,850.0,null,1236.0,1550.0,2451.0,null,475.0,262.0,17785.0,297.0,539.0,null,1348.0,431.0,null,null,null,483.0,743.0,674.0,3106.0,null,513.0,523.0,4819.0,716.0,4045.0,3000.0,3428.0,null,1370.0,1150.0,808.0,null,1214.0,1601.0,280.0,2409.0,277.0,391.0,870.0,6794.0,803.0,535.0,1365.0,337.0,473.0,null,null,null,664.0,null,428.0,426.0,562.0,398.0,550.0,null,1090.0,1722.0,287.0,866.0,1681.0,403.0,916.0,1878.0,760.0,1725.0,2870.0,1370.0,401.0,1298.0,null,359.0,1085.0,1068.0,2456.0,524.0,694.0,892.0,663.0,1928.0,3073.0,651.0,672.0,902.0,1040.0,463.0,447.0,312.0,null,null,null,1631.0,974.0,743.0,6639.0,2568.0,null,592.0,1070.0,810.0,2969.0,366.0,436.0,745.0,3242.0,1325.0,1752.0,561.0,1140.0,null,595.0,1211.0,1166.0,null,609.0,2667.0,null,null,1085.0,null,892.0,946.0,1165.0,null,436.0,1331.0,1564.0,292.0,431.0,658.0,448.0,1387.0,550.0,302.0,400.0,1025.0,339.0,1078.0,null,525.0,810.0,1600.0,431.0,463.0,null,3184.0,284.0,69.0,639.0,null,683.0,null,null,1864.0,3691.0,499.0,null,416.0,1527.0,620.0,964.0,1199.0,956.0,1720.0,1103.0,null,1088.0,null,485.0,71.0,542.0,889.0,686.0,691.0,2345.0,619.0,null,null,null,674.0,447.0,1338.0,1275.0,831.0,689.0,473.0,844.0,416.0,2300.0,411.0,null,1246.0,2740.0,1150.0,389.0,569.0,815.0,null,728.0,null,null,null,6100.0,685.0,null,440.0,null,1070.0,null,2927.0,436.0,404.0,476.0,1990.0,412.0,null,912.0,1083.0,290.0,334.0,1563.0,371.0,498.0,null,964.0,485.0,null,2942.0,null,956.0,609.0,null,null,2052.0,421.0,871.0,1175.0,651.0,223.0,654.0,2863.0,null,3344.0,488.0,null,1070.0,null,208.0,null,4614.0,418.0,464.0,null,490.0,791.0,1011.0,669.0,1365.0,922.0,864.0,null,1051.0,359.0,947.0,327.0,426.0,1075.0,444.0,null,null,654.0,null,5069.0,4700.0,813.0,null,282.0,6556.0,652.0,1336.0,778.0,1148.0,932.0,2949.0,null,241.0,845.0,312.0,700.0,513.0,270.0,663.0,2870.0,null,550.0,6145.0,1385.0,1115.0,720.0,2507.0,537.0,349.0,1412.0,426.0,730.0,705.0,2107.0,3544.0,423.0,1831.0,520.0,970.0,2263.0,null,500.0,510.0,567.0,294.0,1492.0,714.0,1313.0,null,710.0,null,null,976.0,978.0,399.0,null,null,396.0,1078.0,1947.0,925.0,270.0,5111.0,518.0,332.0,536.0,540.0,1241.0,418.0,726.0,null,2397.0,null,null,null,602.0,3922.0,null,356.0,null,null,868.0,2650.0,null,971.0,669.0,1046.0,825.0,null,null,451.0,null,324.0,null,745.0,607.0,588.0,301.0,587.0,2374.0,2317.0,1073.0,1953.0,null,1556.0,757.0,521.0,981.0,814.0,null,1955.0,null,270.0,1653.0,null,607.0,735.0,6755.0,1053.0,1189.0,391.0,1085.0,249.0,604.0,684.0,3170.0,null,null,937.0,892.0,1182.0,686.0,1874.0,332.0,198.0,860.0,478.0,5130.0,877.0,2968.0,666.0,2244.0,320231.0,1140.0,1300.0,528.0,260.0,338.0,475.0,1279.0,null,1100.0,369.0,1359.0,409.0,892.0,null,745.0,741.0,223.0,2426.0,483.0,1725.0,null,null,469.0,null,7895.0,1088.0,299.0,996.0,null,null,4141.0,592.0,743.0,null,5666.0,null,1529.0,572.0,null,3631.0,745.0,892.0,421.0,356.0,1103.0,280.0,null,1243.0,1833.0,5550.0,887.0,349.0,996.0,272.0,1100.0,495.0,1303.0,421.0,895.0,null,null,null,253.0,1207.0,1.0,null,1236.0,3857.0,1327.0,1083.0,585.0,718.0,401.0,8390.0,4328.0,null,null,1390.0,null,2654.0,1584.0,855.0,1020.0,540.0,1003.0,327.0,2314.0,832.0,1140.0,6279.0,null,1135.0,832.0,485.0,1621.0,453.0,null,5589.0,557.0,null,902.0,510.0,1145.0,669.0,null,403.0,772.0,891.0,810.0,1017.0,528.0,2010.0,1479.0,1358.0,319.0,619.0,null,371.0,1553.0,299.0,1232.0,1088.0,1479.0,2027.0,466.0,743.0,null,1217.0,785.0,964.0,null,726.0,null,1558.0,946.0,532.0,null,null,1105.0,null,4459.0,null,267.0,563.0,745.0,2424.0,3106.0,505.0,985.0,2027.0,569.0,656.0,2392.0,329.0,1200.0,334.0,1534.0,2667.0,671.0,null,1294.0,1645.0,920.0,497.0,1125.0,585.0,null,1873.0,1313.0,1033.0,592.0,1636.0,349.0,1045.0,1532.0,null,373.0,917.0,1321.0,1558.0,404.0,780.0,1010.0,2992.0,2668.0,855.0,369.0,327.0,857.0,null,1070.0,1194.0,318.0,618.0,2890.0,null,672.0,3371.0,null,384.0,500.0,null,null,1579.0,null,1859.0,5862.0,1747.0,2813.0,592.0,null,null,944.0,1217.0,null,537.0,null,1.0,220.0,null,2092.0,490.0,null,1036.0,1626.0,1623.0,277.0,null,null,2821.0,null,null,1048.0,1966.0,483.0,547.0,null,946.0,609.0,5210.0,687.0,728.0,null,597.0,656.0,1616.0,986.0,1147.0,592.0,null,null,null,1850.0,null,1256.0,7662.0,770.0,1437.0,1103.0,850.0,1179.0,795.0,733.0,null,530.0,178.0,684.0,310.0,485.0,null,1135.0,907.0,2002.0,1436.0,508.0,626.0,989.0,428.0,1197.0,312.0,null,461.0,756.0,null,1782.0,null,267.0,575.0,null,743.0,394.0,null,null,1013.0,null,null,857.0,null,1083.0,2568.0,1147.0,null,1116.0,4962.0,1023.0,213.0,825.0,438.0,1525.0,null,976.0,585.0,803.0,null,423.0,null,1.0,1641.0,448.0,null,708.0,null,1794.0,13401.0,null,null,1638.0,null,1068.0,3480.0,2528.0,1314.0,560.0,651.0,676.0,572.0,706.0,null,1289.0,2053.0,603.0,2426.0,null,1001.0,2379.0,704.0,3046.0,991.0,1754.0,2493.0,2537.0,null,608.0,1290.0,1023.0,535.0,null,null,null,1162.0,1460.0,2368.0,369.0,1510.0,1422.0,697.0,721.0,1115.0,872.0,3948.0,313.0,505.0,null,233.0,998.0,773.0,983.0,null,1207.0,478.0,994.0,713.0,453.0,null,2247.0,830.0,1477.0,null,1611.0,449.0,794.0,null,1566.0,884.0,893.0,1368.0,null,1839.0,1239.0,1690.0,null,1162.0,null,699.0,1274.0,2679.0,2568.0,1016.0,547.0,780.0,738.0,1579.0,null,376.0,null,347.0,null,null,1463.0,null,228.0,694.0,547.0,746.0,483.0,374.0,1950.0,null,null,null,505.0,null,894.0,1.0,500.0,2002.0,1115.0,650.0,1.0,2010.0,532.0,null,272.0,null,327.0,null,2540.0,3391.0,426.0,2653.0,1762.0,1105.0,376.0,594.0,1591.0,1115.0,299.0,null,null,1807.0,298.0,null,433.0,769.0,2233.0,761.0,null,6315.0,666.0,218.0,null,1301.0,840.0,321.0,null,359.0,892.0,null,1427.0,1938.0,312.0,473.0,413.0,401.0,290.0,1173.0,371.0,4561.0,null,1276.0,2330.0,966.0,799.0,976.0,731.0,247.0,857.0,1167.0,3973.0,728.0,null,193.0,null,null,null,376.0,1963.0,6355.0,260.0,null,679.0,1865.0,1817.0,null,470.0,716.0,949.0,451.0,7532.0,523.0,null,null,null,null,1489.0,1279.0,null,490.0,523.0,1500.0,1993.0,1038.0,280.0,null,705.0,1150.0,1080.0,null,1080.0,1130.0,null,3408.0,1001.0,5193.0,1162.0,1135.0,1799.0,1665.0,443.0,977.0,1576.0,null,1130.0,null,914.0,520.0,425.0,1831.0,426.0,null,1355.0,null,null,null,319.0,775.0,null,909.0,3048.0,366.0,575.0,1370.0,1130.0,null,1056.0,785.0,651.0,2174.0,null,null,892.0,936.0,421.0,null,1730.0,1421.0,null,1368.0,1660.0,5091.0,763.0,722.0,2465.0,null,null,973.0,880.0,930.0,null,1380.0,1137.0,1.0,null,166.0,493.0,294.0,null,805.0,1243.0,573.0,null,null,917.0,1259.0,927.0,3272.0,1341.0,547.0,null,1202.0,1088.0,1861.0,572.0,1031.0,778.0,228.0,1836.0,810.0,562.0,1208.0,882.0,892.0,17785.0,1174.0,null,482.0,1482.0,740.0,7662.0,649.0,null,396.0,null,743.0,704.0,594.0,585.0,1320.0,null,null,null,2881.0,null,389.0,680.0,null,413.0,582.0,17037.0,null,null,674.0,1308.0,603.0,null,1021.0,null,null,null,1212.0,322.0,1070.0,220.0,810.0,600.0,1353.0,1011.0,805.0,null,1186.0,2350.0,158.0,null,null,713.0,343.0,null,1201.0,280.0,1078.0,367.0,1220.0,1055.0,1363.0,443.0,2735.0,557.0,1794.0,694.0,488.0,1011.0,463.0,1854.0,885.0,null,1249.0,null,372.0,1080.0,800.0,344.0,1240.0,1355.0,731.0,null,726.0,1199.0,null,619.0,548.0,535.0,null,463.0,null,null,565.0,272.0,null,1451.0,696.0,null,811.0,1779.0,624.0,389.0,783.0,null,null,753.0,594.0,461.0,842.0,1175.0,1427.0,null,2322.0,1209.0,3487.0,788.0,708.0,738.0,815.0,null,1192.0,1150.0,914.0,1167.0,1013.0,664.0,384.0,443.0,null,294.0,null,1808.0,null,669.0,337.0,297.0,349.0,122.0,409.0,1612.0,1095.0,924.0,218.0,681.0,null,null,1631.0,842.0,1100.0,743.0,373.0,null,656.0,716.0,446.0,458.0,null,1730.0,352.0,2000.0,1623.0,null,null,468.0,808.0,null,614.0,304.0,1703.0,null,null,1462.0,892.0,null,674.0,327.0,433.0,237.0,998.0,null,2546.0,713.0,669.0,414.0,3048.0,911.0,1239.0,505.0,705.0,347.0,1016.0,1048.0,580.0,645.0,1023.0,813.0,647.0,null,644.0,2530.0,505.0,720.0,1067.0,null,398.0,null,null,971.0,null,342.0,2231.0,557.0,null,508.0,1088.0,1.0,753.0,2867.0,2553.0,1021.0,282.0,2166.0,null,773.0,562.0,null,null,null,null,3544.0,897.0,706.0,200.0,609.0,745.0,505.0,800.0,null,542.0,null,1053.0,null,596.0,307.0,247.0,884.0,null,535.0,513.0,837.0,3373.0,701.0,661.0,2604.0,2654.0,null,607.0,1232.0,null,null,null,617.0,968.0,993.0,null,415.0,7441.0,1002.0,466.0,null,null,877.0,240.0,894.0,1614.0,null,592.0,342.0,null,null,597.0,1285.0,788.0,882.0,265.0,1606.0,1227.0,366.0,1366.0,null,959.0,577.0,743.0,1065.0,635.0,322.0,null,2728.0,4395.0,1623.0,1859.0,661.0,1588.0,2421.0,421.0,733.0,1018.0,4241.0,2066.0,2599.0,1395.0,null,null,790.0,617.0,1074.0,1.0,651.0,736.0,1571.0,979.0,855.0,3585.0,545.0,1794.0,1088.0,null,837.0,3170.0,312.0,2932.0,1052.0,560.0,316.0,1395.0,700.0,null,8085.0,null,413.0,391.0,null,null,396.0,451.0,839.0,null,null,5550.0,null,null,2654.0,426.0,917.0,518.0,946.0,null,null,2017.0,null,1460.0,743.0,null,827.0,2880.0,374.0,428.0,1.0,null,1636.0,1187.0,1164.0,738.0,384.0,2511.0,290.0,null,619.0,null,537.0,null,869.0,685.0,2565.0,788.0,3428.0,373.0,877.0,840.0,929.0,416.0,687.0,null,364.0,979.0,null,857.0,null,1117.0,1276.0,391.0,465.0,1477.0,927.0,361.0,252.0,null,412.0,1370.0,617.0,845.0,689.0,1139.0,3354.0,null,1005.0,302.0,438.0,971.0,null,354.0,495.0,null,2140.0,654.0,1060.0,null,659.0,null,339.0,null,2211.0,1400.0,null,696.0,696.0,5406.0,617.0,3066.0,null,null,null,4981.0,1798.0,3116.0,1878.0,697.0,2089.0,609.0,null,null,656.0,686.0,544.0,3161.0,2620.0,954.0,1393.0,1844.0,2135.0,1767.0,225.0,714.0,null,611.0,711.0,2226.0,485.0,364.0,null,1265.0,300.0,null,null,null,495.0,1717.0,795.0,604.0,null,617.0,null,1448.0,644.0,null,2859.0,1202.0,null,614.0,706.0,null,4040.0,674.0,null,2164.0,976.0,null,319.0,2317.0,null,null,874.0,705.0,644.0,297.0,808.0,null,2789.0,1234.0,1184.0,1284.0,374.0,null,null,1251.0,659.0,557.0,743.0,542.0,423.0,null,null,720.0,290.0,1024.0,473.0,332.0,453.0,null,656.0,1983.0,9226.0,null,1388.0,956.0,488.0,882.0,null,374.0,1536.0,472.0,505.0,782.0,5862.0,810.0,null,296.0,2465.0,1613.0,1615.0,480.0,497.0,624.0,565.0,null,590.0,794.0,785.0,1003.0,1417.0,914.0,1222.0,716.0,null,1319.0,1298.0,513.0,1112.0,230.0,587.0,475.0,562.0,312.0,575.0,478.0,2317.0,411.0,1638.0,null,565.0,865.0,991.0,711.0,3572.0,398.0,54.0,862.0,1415.0,815.0,2248.0,386.0,2216.0,1519.0,null,null,578.0,1826.0,1.0,null,null,1242.0,706.0,855.0,351.0,1140.0,521.0,1.0,339.0,1122.0,null,459.0,null,1.0,721.0,1756.0,535.0,3353.0,null,2170.0,614.0,406.0,1412.0,2193.0,1068.0,1779.0,1241.0,1224.0,359.0,1077.0,560.0,1048.0,391.0,1363.0,1028.0,2597.0,803.0,2119.0,311.0,488.0,null,null,null,401.0,1095.0,418.0,1165.0,null,178.0,788.0,810.0,1095.0,1207.0,null,2092.0,3210.0,null,1389.0,null,1546.0,650.0,475.0,null,892.0,null,null,null,null,null,null,1127.0,null,379.0,525.0,629.0,1.0,1462.0,null,null,null,1952.0,2421.0,null,619.0,1399.0,null,null,1544.0,406.0,594.0,1299.0,780.0,null,1077.0,null,461.0,2732.0,1266.0,2261.0,null,821.0,null,null,null],
"living_area":[67.0,285.0,170.0,282.0,150.0,209.0,160.0,140.0,343.0,120.0,195.0,123.0,100.0,150.0,168.0,250.0,173.0,205.0,167.0,260.0,110.0,144.0,200.0,102.0,106.0,90.0,60.0,180.0,450.0,103.0,208.0,76.0,158.0,265.0,399.0,583.0,327.0,300.0,214.0,190.0,130.0,320.0,822.0,161.0,203.0,174.0,135.0,160.0,81.0,null,119.0,184.0,887.0,160.0,167.0,145.0,376.0,165.0,185.0,140.0,180.0,256.0,255.0,167.0,133.0,168.0,190.0,275.0,150.0,252.0,161.0,205.0,205.0,171.0,100.0,250.0,45.0,184.0,384.0,594.0,null,200.0,300.0,228.0,377.0,185.0,287.0,513.0,135.0,460.0,206.0,94.0,235.0,62.0,253.0,217.0,230.0,206.0,144.0,200.0,284.0,240.0,312.0,null,220.0,156.0,170.0,215.0,254.0,370.0,230.0,227.0,120.0,194.0,180.0,130.0,110.0,664.0,200.0,180.0,105.0,501.0,90.0,103.0,448.0,284.0,130.0,300.0,297.0,170.0,154.0,1056.0,85.0,40.0,535.0,126.0,388.0,180.0,195.0,225.0,90.0,161.0,112.0,176.0,277.0,130.0,135.0,215.0,160.0,421.0,100.0,210.0,130.0,160.0,null,185.0,422.0,null,180.0,141.0,225.0,232.0,222.0,213.0,120.0,140.0,700.0,155.0,171.0,159.0,168.0,420.0,97.0,450.0,165.0,264.0,145.0,131.0,127.0,405.0,null,415.0,280.0,243.0,158.0,94.0,260.0,263.0,120.0,375.0,150.0,438.0,217.0,125.0,167.0,124.0,null,96.0,199.0,210.0,233.0,206.0,321.0,75.0,650.0,136.0,140.0,350.0,230.0,280.0,156.0,150.0,142.0,300.0,225.0,100.0,283.0,173.0,133.0,110.0,80.0,155.0,129.0,260.0,218.0,303.0,325.0,160.0,125.0,200.0,145.0,134.0,135.0,149.0,166.0,255.0,450.0,128.0,290.0,220.0,370.0,157.0,null,166.0,122.0,160.0,212.0,140.0,110.0,107.0,115.0,273.0,385.0,205.0,195.0,109.0,132.0,320.0,220.0,270.0,120.0,308.0,594.0,135.0,200.0,160.0,890.0,691.0,400.0,225.0,122.0,120.0,514.0,285.0,105.0,300.0,196.0,117.0,180.0,1165.0,285.0,230.0,118.0,168.0,163.0,115.0,493.0,373.0,122.0,737.0,326.0,208.0,314.0,130.0,185.0,150.0,138.0,130.0,174.0,414.0,160.0,138.0,114.0,191.0,137.0,195.0,83.0,200.0,195.0,458.0,478.0,139.0,100.0,390.0,212.0,315.0,240.0,171.0,421.0,126.0,520.0,127.0,210.0,75.0,557.0,175.0,267.0,345.0,193.0,270.0,220.0,124.0,300.0,180.0,160.0,120.0,773.0,200.0,182.0,123.0,224.0,78.0,136.0,178.0,40.0,122.0,296.0,238.0,214.0,200.0,200.0,150.0,203.0,420.0,null,226.0,267.0,140.0,251.0,72.0,240.0,null,326.0,160.0,420.0,198.0,242.0,140.0,250.0,229.0,170.0,90.0,137.0,140.0,225.0,150.0,270.0,120.0,300.0,577.0,371.0,267.0,222.0,146.0,550.0,126.0,122.0,400.0,469.0,220.0,93.0,75.0,215.0,145.0,184.0,145.0,341.0,150.0,190.0,171.0,225.0,234.0,172.0,175.0,194.0,200.0,266.0,323.0,210.0,171.0,135.0,300.0,185.0,260.0,103.0,117.0,159.0,145.0,284.0,550.0,318.0,300.0,550.0,160.0,410.0,239.0,150.0,217.0,268.0,232.0,136.0,234.0,280.0,92.0,120.0,220.0,1700.0,null,200.0,174.0,137.0,177.0,165.0,143.0,165.0,75.0,153.0,229.0,130.0,260.0,260.0,540.0,320.0,763.0,264.0,183.0,162.0,329.0,138.0,123.0,230.0,129.0,130.0,240.0,200.0,210.0,110.0,490.0,286.0,344.0,155.0,500.0,297.0,178.0,304.0,298.0,177.0,190.0,300.0,157.0,715.0,720.0,150.0,286.0,126.0,385.0,719.0,55.0,185.0,280.0,307.0,105.0,124.0,160.0,185.0,186.0,175.0,286.0,null,250.0,185.0,281.0,52.0,172.0,380.0,180.0,216.0,224.0,256.0,285.0,408.0,177.0,700.0,160.0,237.0,332.0,250.0,530.0,167.0,190.0,40.0,150.0,190.0,360.0,132.0,270.0,244.0,100.0,125.0,274.0,236.0,86.0,420.0,120.0,322.0,563.0,140.0,600.0,297.0,310.0,100.0,null,140.0,220.0,160.0,110.0,264.0,160.0,115.0,350.0,173.0,67.0,112.0,728.0,70.0,217.0,263.0,396.0,219.0,123.0,176.0,175.0,182.0,160.0,175.0,110.0,166.0,180.0,118.0,99.0,218.0,185.0,250.0,260.0,415.0,130.0,237.0,174.0,200.0,222.0,145.0,146.0,181.0,207.0,187.0,112.0,151.0,141.0,530.0,150.0,178.0,550.0,100.0,130.0,525.0,120.0,197.0,380.0,130.0,550.0,607.0,200.0,250.0,281.0,423.0,868.0,160.0,103.0,191.0,183.0,175.0,260.0,145.0,288.0,180.0,175.0,146.0,925.0,262.0,122.0,284.0,120.0,130.0,160.0,310.0,137.0,164.0,184.0,120.0,353.0,415.0,200.0,250.0,189.0,190.0,156.0,300.0,150.0,120.0,270.0,205.0,55.0,110.0,170.0,285.0,130.0,null,152.0,134.0,null,326.0,162.0,689.0,140.0,217.0,148.0,148.0,192.0,250.0,165.0,230.0,190.0,220.0,102.0,120.0,156.0,400.0,250.0,193.0,61.0,115.0,128.0,200.0,178.0,340.0,103.0,275.0,142.0,114.0,280.0,160.0,null,165.0,360.0,132.0,180.0,178.0,130.0,241.0,124.0,300.0,205.0,275.0,83.0,90.0,240.0,194.0,165.0,234.0,196.0,null,330.0,100.0,139.0,180.0,390.0,218.0,168.0,90.0,137.0,135.0,128.0,229.0,136.0,115.0,115.0,125.0,104.0,63.0,220.0,161.0,126.0,140.0,250.0,350.0,158.0,176.0,195.0,428.0,167.0,100.0,426.0,150.0,267.0,95.0,163.0,155.0,110.0,138.0,280.0,370.0,458.0,232.0,95.0,217.0,1016.0,224.0,174.0,null,180.0,285.0,155.0,150.0,230.0,145.0,139.0,244.0,600.0,224.0,150.0,178.0,127.0,220.0,115.0,221.0,250.0,340.0,160.0,320.0,90.0,115.0,108.0,120.0,90.0,210.0,127.0,190.0,175.0,267.0,241.0,83.0,400.0,240.0,145.0,110.0,115.0,null,165.0,178.0,133.0,180.0,220.0,null,166.0,151.0,260.0,87.0,140.0,null,167.0,119.0,131.0,319.0,100.0,317.0,115.0,127.0,607.0,135.0,215.0,260.0,120.0,372.0,230.0,88.0,100.0,266.0,127.0,120.0,105.0,286.0,220.0,345.0,110.0,720.0,177.0,155.0,236.0,110.0,159.0,207.0,448.0,106.0,266.0,182.0,488.0,315.0,495.0,429.0,135.0,90.0,175.0,123.0,1230.0,125.0,429.0,1016.0,135.0,276.0,225.0,540.0,180.0,144.0,164.0,485.0,150.0,170.0,120.0,120.0,189.0,150.0,98.0,308.0,193.0,138.0,135.0,173.0,116.0,246.0,115.0,133.0,140.0,85.0,201.0,142.0,144.0,null,105.0,136.0,445.0,68.0,150.0,330.0,188.0,190.0,163.0,80.0,250.0,210.0,302.0,223.0,176.0,344.0,146.0,200.0,80.0,142.0,160.0,176.0,105.0,206.0,260.0,114.0,115.0,110.0,158.0,135.0,178.0,148.0,234.0,164.0,160.0,202.0,220.0,260.0,198.0,153.0,448.0,245.0,190.0,205.0,225.0,130.0,179.0,100.0,567.0,282.0,172.0,190.0,1054.0,76.0,140.0,130.0,100.0,400.0,181.0,215.0,235.0,130.0,107.0,85.0,240.0,174.0,125.0,290.0,147.0,87.0,152.0,207.0,100.0,265.0,304.0,153.0,135.0,265.0,135.0,282.0,346.0,169.0,116.0,240.0,60.0,330.0,168.0,null,179.0,90.0,180.0,175.0,179.0,null,103.0,200.0,150.0,148.0,285.0,180.0,200.0,133.0,265.0,229.0,80.0,150.0,130.0,340.0,255.0,555.0,324.0,226.0,106.0,142.0,410.0,109.0,188.0,60.0,285.0,251.0,170.0,200.0,350.0,200.0,220.0,147.0,120.0,204.0,174.0,380.0,259.0,135.0,287.0,197.0,370.0,720.0,113.0,154.0,164.0,214.0,315.0,73.0,240.0,400.0,137.0,166.0,466.0,160.0,224.0,148.0,232.0,290.0,386.0,218.0,176.0,176.0,147.0,202.0,91.0,316.0,473.0,326.0,559.0,250.0,252.0,266.0,135.0,189.0,179.0,140.0,140.0,73.0,203.0,265.0,118.0,165.0,250.0,250.0,278.0,135.0,138.0,70.0,105.0,222.0,125.0,200.0,150.0,200.0,200.0,70.0,230.0,250.0,142.0,320.0,140.0,173.0,107.0,117.0,180.0,112.0,276.0,222.0,267.0,365.0,129.0,125.0,112.0,80.0,172.0,null,167.0,258.0,191.0,150.0,173.0,135.0,130.0,175.0,90.0,430.0,260.0,195.0,184.0,160.0,240.0,279.0,267.0,249.0,208.0,186.0,312.0,350.0,143.0,160.0,142.0,170.0,112.0,123.0,408.0,282.0,317.0,113.0,140.0,307.0,184.0,118.0,260.0,269.0,800.0,164.0,176.0,467.0,208.0,270.0,119.0,347.0,800.0,207.0,100.0,1056.0,340.0,133.0,185.0,185.0,170.0,168.0,290.0,125.0,136.0,125.0,550.0,192.0,151.0,450.0,221.0,132.0,315.0,166.0,180.0,140.0,130.0,140.0,284.0,155.0,null,217.0,180.0,99.0,160.0,110.0,95.0,80.0,189.0,515.0,107.0,160.0,200.0,505.0,180.0,200.0,337.0,null,210.0,150.0,220.0,110.0,117.0,320.0,214.0,250.0,null,154.0,300.0,429.0,146.0,122.0,110.0,285.0,222.0,93.0,200.0,288.0,370.0,136.0,320.0,440.0,420.0,85.0,610.0,590.0,150.0,123.0,195.0,130.0,170.0,66.0,120.0,150.0,148.0,368.0,155.0,170.0,300.0,100.0,148.0,190.0,260.0,218.0,null,260.0,595.0,393.0,148.0,546.0,328.0,160.0,200.0,988.0,156.0,60.0,434.0,392.0,440.0,382.0,293.0,261.0,275.0,285.0,200.0,182.0,215.0,470.0,256.0,160.0,95.0,200.0,234.0,170.0,243.0,322.0,369.0,132.0,720.0,125.0,321.0,400.0,90.0,449.0,400.0,120.0,169.0,207.0,286.0,219.0,120.0,330.0,241.0,115.0,183.0,178.0,147.0,102.0,66.0,400.0,268.0,197.0,250.0,202.0,213.0,117.0,250.0,146.0,235.0,132.0,250.0,102.0,201.0,216.0,82.0,150.0,168.0,280.0,222.0,136.0,194.0,106.0,130.0,194.0,100.0,281.0,164.0,180.0,167.0,275.0,237.0,123.0,149.0,175.0,114.0,130.0,40.0,130.0,110.0,375.0,170.0,463.0,200.0,234.0,204.0,190.0,160.0,260.0,275.0,405.0,535.0,120.0,750.0,173.0,278.0,315.0,240.0,104.0,216.0,133.0,135.0,107.0,81.0,177.0,190.0,181.0,156.0,340.0,202.0,126.0,243.0,210.0,370.0,255.0,239.0,200.0,135.0,176.0,636.0,220.0,650.0,506.0,280.0,200.0,230.0,450.0,276.0,303.0,170.0,253.0,570.0,200.0,260.0,225.0,60.0,445.0,87.0,320.0,344.0,540.0,150.0,130.0,110.0,476.0,180.0,270.0,244.0,142.0,120.0,350.0,152.0,650.0,629.0,135.0,233.0,149.0,363.0,350.0,240.0,300.0,113.0,181.0,113.0,262.0,160.0,211.0,476.0,160.0,211.0,176.0,128.0,101.0,535.0,416.0,163.0,700.0,110.0,145.0,179.0,185.0,220.0,90.0,77.0,361.0,240.0,209.0,305.0,174.0,552.0,200.0,198.0,356.0,154.0,123.0,121.0,172.0,280.0,153.0,170.0,110.0,312.0,140.0,400.0,331.0,89.0,155.0,131.0,890.0,175.0,145.0,200.0,320.0,131.0,330.0,85.0,221.0,564.0,136.0,219.0,146.0,201.0,264.0,250.0,162.0,175.0,150.0,124.0,257.0,127.0,110.0,155.0,165.0,405.0,240.0,289.0,176.0,350.0,200.0,114.0,507.0,126.0,314.0,524.0,125.0,273.0,170.0,184.0,160.0,76.0,500.0,128.0,68.0,159.0,252.0,125.0,181.0,285.0,258.0,291.0,180.0,185.0,null,107.0,220.0,243.0,415.0,160.0,161.0,250.0,93.0,280.0,95.0,186.0,65.0,450.0,128.0,300.0,135.0,158.0,429.0,80.0,275.0,336.0,130.0,115.0,105.0,92.0,120.0,399.0,172.0,140.0,142.0,287.0,239.0,159.0,212.0,148.0,142.0,219.0,533.0,215.0,247.0,126.0,133.0,151.0,133.0,970.0,125.0,445.0,118.0,200.0,240.0,180.0,157.0,275.0,116.0,145.0,150.0,495.0,135.0,153.0,192.0,250.0,297.0,100.0,673.0,170.0,230.0,225.0,285.0,240.0,140.0,192.0,210.0,1100.0,180.0,115.0,110.0,260.0,260.0,160.0,180.0,155.0,336.0,436.0,178.0,210.0,131.0,208.0,187.0,119.0,144.0,92.0,512.0,163.0,445.0,100.0,256.0,263.0,421.0,200.0,100.0,390.0,168.0,90.0,216.0,230.0,138.0,234.0,193.0,106.0,150.0,200.0,200.0,153.0,310.0,407.0,135.0,116.0,92.0,200.0,220.0,144.0,228.0,null,127.0,450.0,281.0,550.0,275.0,103.0,81.0,251.0,null,211.0,175.0,133.0,250.0,252.0,168.0,150.0,191.0,120.0,423.0,100.0,232.0,267.0,231.0,174.0,300.0,200.0,405.0,148.0,217.0,140.0,162.0,75.0,148.0,210.0,61.0,100.0,200.0,365.0,170.0,100.0,241.0,165.0,160.0,100.0,138.0,155.0,135.0,126.0,50.0,247.0,630.0,250.0,370.0,127.0,69.0,361.0,200.0,234.0,170.0,125.0,320.0,304.0,182.0,180.0,188.0,300.0,248.0,161.0,92.0,125.0,103.0,160.0,257.0,null,11000.0,292.0,180.0,106.0,250.0,153.0,65.0,198.0,245.0,218.0,238.0,180.0,98.0,103.0,221.0,375.0,120.0,159.0,122.0,200.0,113.0,216.0,147.0,120.0,165.0,180.0,156.0,180.0,184.0,240.0,90.0,353.0,287.0,1190.0,167.0,407.0,514.0,32.0,260.0,710.0,1200.0,310.0,340.0,168.0,154.0,80.0,440.0,188.0,165.0,382.0,526.0,150.0,239.0,105.0,126.0,217.0,538.0,321.0,135.0,330.0,220.0,300.0,202.0,203.0,560.0,250.0,215.0,350.0,560.0,164.0,102.0,145.0,133.0,132.0,139.0,234.0,276.0,350.0,800.0,119.0,72.0,460.0,85.0,500.0,288.0,450.0,181.0,171.0,null,250.0,363.0,268.0,150.0,110.0,197.0,548.0,120.0,160.0,null,220.0,300.0,171.0,167.0,185.0,181.0,90.0,351.0,128.0,90.0,275.0,115.0,407.0,190.0,95.0,377.0,194.0,281.0,580.0,200.0,190.0,335.0,485.0,140.0,370.0,294.0,104.0,69.0,448.0,244.0,175.0,140.0,36.0,146.0,151.0,null,156.0,705.0,108.0,383.0,120.0,154.0,160.0,132.0,300.0,220.0,172.0,165.0,105.0,200.0,220.0,null,330.0,98.0,370.0,425.0,130.0,132.0,216.0,150.0,385.0,171.0,350.0,260.0,398.0,112.0,245.0,230.0,554.0,370.0,155.0,304.0,195.0,147.0,170.0,307.0,260.0,125.0,333.0,125.0,204.0,270.0,120.0,159.0,132.0,190.0,250.0,366.0,120.0,135.0,200.0,492.0,229.0,172.0,187.0,null,329.0,270.0,277.0,120.0,194.0,169.0,145.0,250.0,104.0,277.0,107.0,137.0,248.0,247.0,230.0,386.0,224.0,150.0,110.0,1100.0,128.0,119.0,215.0,400.0,121.0,702.0,232.0,215.0,172.0,145.0,150.0,221.0,188.0,168.0,null,610.0,123.0,200.0,275.0,265.0,126.0,133.0,240.0,273.0,140.0,207.0,246.0,117.0,220.0,60.0,200.0,133.0,791.0,109.0,135.0,272.0,140.0,180.0,660.0,200.0,160.0,136.0,239.0,148.0,178.0,172.0,98.0,100.0,297.0,150.0,255.0,100.0,280.0,356.0,89.0,126.0,500.0,125.0,240.0,262.0,200.0,123.0,270.0,167.0,127.0,null,130.0,630.0,116.0,218.0,135.0,215.0,185.0,170.0,187.0,248.0,98.0,145.0,130.0,80.0,118.0,162.0,110.0,275.0,140.0,198.0,200.0,360.0,240.0,850.0,147.0,164.0,174.0,1165.0,145.0,116.0,236.0,200.0,176.0,290.0,157.0,175.0,400.0,195.0,226.0,303.0,232.0,120.0,258.0,200.0,400.0,90.0,230.0,150.0,131.0,210.0,185.0,214.0,272.0,274.0,70.0,156.0,171.0,86.0,176.0,288.0,104.0,84.0,128.0,119.0,157.0,345.0,129.0,130.0,196.0,170.0,140.0,67.0,485.0,80.0,52.0,108.0,231.0,200.0,450.0,117.0,259.0,500.0,135.0,368.0,140.0,113.0,124.0,160.0,260.0,190.0,230.0,242.0,140.0,263.0,236.0,190.0,364.0,370.0,250.0,190.0,159.0,224.0,130.0,130.0,166.0,152.0,204.0,90.0,323.0,188.0,91.0,139.0,130.0,221.0,160.0,369.0,119.0,330.0,340.0,500.0,220.0,177.0,120.0,180.0,640.0,305.0,144.0,162.0,260.0,400.0,153.0,null,311.0,132.0,235.0,290.0,450.0,85.0,191.0,220.0,183.0,140.0,811.0,135.0,257.0,120.0,83.0,400.0,100.0,101.0,448.0,145.0,75.0,227.0,155.0,240.0,112.0,311.0,500.0,400.0,212.0,105.0,191.0,262.0,205.0,100.0,185.0,360.0,158.0,300.0,147.0,290.0,246.0,321.0,96.0,130.0,326.0,115.0,86.0,220.0,150.0,140.0,190.0,236.0,228.0,216.0,148.0,394.0,282.0,131.0,231.0,93.0,128.0,137.0,303.0,168.0,300.0,null,209.0,330.0,270.0,182.0,150.0,80.0,1005.0,257.0,450.0,114.0,287.0,150.0,205.0,290.0,166.0,155.0,214.0,260.0,133.0,105.0,140.0,240.0,137.0,115.0,550.0,440.0,404.0,150.0,11000.0,139.0,116.0,184.0,235.0,122.0,552.0,195.0,340.0,106.0,416.0,205.0,240.0,297.0,163.0,100.0,146.0,118.0,55.0,175.0,150.0,265.0,190.0,200.0,570.0,173.0,367.0,213.0,116.0,229.0,168.0,130.0,239.0,198.0,400.0,86.0,300.0,178.0,106.0,null,185.0,363.0,92.0,205.0,175.0,190.0,160.0,200.0,200.0,215.0,415.0,257.0,146.0,168.0,191.0,196.0,400.0,170.0,128.0,237.0,201.0,181.0,166.0,288.0,160.0,251.0,176.0,95.0,115.0,125.0,150.0,130.0,157.0,600.0,250.0,280.0,317.0,120.0,275.0,200.0,173.0,223.0,182.0,340.0,264.0,165.0,98.0,231.0,135.0,192.0,null,450.0,300.0,150.0,70.0,165.0,120.0,170.0,90.0,180.0,null,203.0,253.0,150.0,175.0,160.0,282.0,104.0,82.0,150.0,206.0,450.0,250.0,356.0,267.0,280.0,300.0,480.0,170.0,116.0,125.0,100.0,261.0,197.0,295.0,165.0,152.0,180.0,125.0,135.0,75.0,334.0,174.0,86.0,355.0,162.0,170.0,null,289.0,82.0,265.0,700.0,185.0,102.0,147.0,152.0,265.0,338.0,128.0,213.0,177.0,890.0,260.0,156.0,80.0,null,260.0,150.0,219.0,180.0,130.0,242.0,111.0,818.0,260.0,413.0,295.0,112.0,148.0,140.0,120.0,300.0,131.0,202.0,140.0,238.0,650.0,513.0,182.0,107.0,155.0,197.0,211.0,237.0,260.0,285.0,180.0,150.0,120.0,121.0,476.0,744.0,270.0,130.0,269.0,300.0,181.0,150.0,95.0,157.0,221.0,110.0,130.0,614.0,463.0,417.0,451.0,411.0,160.0,130.0,189.0,360.0,125.0,150.0,375.0,220.0,325.0,171.0,115.0,177.0,135.0,200.0,125.0,200.0,144.0,195.0,329.0,214.0,300.0,277.0,300.0,315.0,269.0,440.0,147.0,519.0,85.0,150.0,150.0,185.0,310.0,150.0,140.0,116.0,175.0,200.0,328.0,153.0,195.0,145.0,252.0,170.0,null,650.0,161.0,217.0,250.0,380.0,175.0,132.0,180.0,130.0,568.0,221.0,105.0,200.0,150.0,284.0,452.0,123.0,98.0,200.0,81.0,290.0,308.0,175.0,180.0,396.0,255.0,177.0,170.0,253.0,170.0,336.0,224.0,88.0,179.0,137.0,230.0,72.0,129.0,190.0,205.0,100.0,135.0,325.0,176.0,87.0,185.0,465.0,410.0,252.0,216.0,81.0,130.0,225.0,387.0,164.0,194.0,70.0,110.0,230.0,176.0,65.0,478.0,179.0,111.0,132.0,null,193.0,368.0,194.0,421.0,758.0,200.0,335.0,147.0,237.0,250.0,301.0,392.0,315.0,130.0,176.0,224.0,60.0,172.0,390.0,158.0,430.0,160.0,343.0,265.0,110.0,48.0,259.0,207.0,215.0,143.0,227.0,285.0,194.0,125.0,395.0,240.0,175.0,360.0,117.0,127.0,90.0,93.0,185.0,379.0,218.0,165.0,93.0,404.0,270.0,215.0,642.0,125.0,184.0,425.0,227.0,372.0,null,80.0,234.0,212.0,135.0,null,188.0,107.0,178.0,127.0,200.0,350.0,194.0,190.0,310.0,160.0,120.0,200.0,133.0,162.0,301.0,120.0,228.0,53.0,137.0,202.0,125.0,535.0,92.0,144.0,352.0,null,125.0,490.0,155.0,180.0,120.0,55.0,140.0,535.0,250.0,240.0,297.0,320.0,284.0,340.0,138.0,116.0,188.0,160.0,220.0,210.0,125.0,200.0,132.0,180.0,124.0,180.0,174.0,280.0,91.0,400.0,145.0,183.0,367.0,1038.0,65.0,220.0,150.0,148.0,155.0,574.0,195.0,275.0,137.0,246.0,151.0,155.0,241.0,90.0,377.0,610.0,162.0,325.0,218.0,184.0,360.0,180.0,291.0,208.0,320.0,188.0,320.0,139.0,180.0,230.0,null,160.0,144.0,150.0,114.0,158.0,142.0,227.0,140.0,275.0,140.0,93.0,128.0,211.0,180.0,728.0,80.0,192.0,217.0,96.0,130.0,68.0,320.0,125.0,420.0,138.0,156.0,120.0,160.0,260.0,320.0,151.0,207.0,141.0,213.0,125.0,149.0,160.0,140.0,210.0,151.0,217.0,173.0,350.0,340.0,295.0,265.0,173.0,650.0,75.0,285.0,363.0,240.0,180.0,253.0,237.0,125.0,250.0,424.0,162.0,285.0,110.0,171.0,300.0,153.0,222.0,90.0,140.0,387.0,160.0,194.0,160.0,291.0,167.0,702.0,422.0,125.0,160.0,151.0,144.0,127.0,310.0,229.0,162.0,125.0,495.0,155.0,193.0,131.0,275.0,72.0,117.0,261.0,320.0,70.0,120.0,286.0,190.0,110.0,165.0,260.0,182.0,154.0,160.0,509.0,245.0,110.0,360.0,100.0,151.0,135.0,187.0,270.0,200.0,68.0,79.0,1200.0,294.0,115.0,60.0,209.0,59.0,160.0,330.0,241.0,290.0,218.0,105.0,223.0,null,148.0,240.0,115.0,510.0,252.0,88.0,368.0,204.0,150.0,367.0,115.0,103.0,151.0,177.0,327.0,195.0,210.0,85.0,310.0,137.0,490.0,110.0,166.0,1264.0,192.0,300.0,214.0,280.0,256.0,75.0,61.0,200.0,180.0,130.0,1461.0,183.0,323.0,321.0,null,240.0,267.0,190.0,159.0,132.0,140.0,90.0,185.0,265.0,138.0,750.0,552.0,383.0,230.0,125.0,218.0,259.0,153.0,230.0,445.0,319.0,190.0,264.0,99.0,150.0,142.0,215.0,280.0,688.0,200.0,200.0,339.0,73.0,300.0,255.0,100.0,321.0,348.0,370.0,346.0,157.0,114.0,95.0,188.0,110.0,317.0,133.0,220.0,178.0,247.0,317.0,336.0,125.0,153.0,250.0,216.0,null,139.0,95.0,130.0,207.0,192.0,197.0,185.0,294.0,350.0,376.0,120.0,225.0,478.0,182.0,230.0,133.0,141.0,130.0,110.0,163.0,174.0,260.0,217.0,200.0,277.0,150.0,270.0,152.0,298.0,141.0,165.0,140.0,200.0,176.0,155.0,350.0,280.0,153.0,330.0,254.0,null,245.0,175.0,209.0,130.0,50.0,269.0,228.0,136.0,230.0,122.0,140.0,800.0,240.0,320.0,202.0,394.0,145.0,425.0,100.0,150.0,85.0,250.0,125.0,176.0,238.0,187.0,236.0,200.0,175.0,157.0,420.0,310.0,150.0,191.0,240.0,169.0,122.0,1200.0,202.0,120.0,196.0,230.0,130.0,310.0,218.0,300.0,320.0,400.0,385.0,120.0,164.0,90.0,115.0,100.0,333.0,218.0,121.0,173.0,195.0,160.0,null,373.0,142.0,198.0,197.0,210.0,252.0,120.0,320.0,116.0,139.0,270.0,506.0,130.0,300.0,135.0,111.0,90.0,158.0,120.0,143.0,290.0,135.0,256.0,180.0,200.0,103.0,206.0,135.0,117.0,194.0,348.0,170.0,114.0,60.0,264.0,152.0,155.0,144.0,176.0,440.0,150.0,117.0,161.0,132.0,85.0,180.0,210.0,160.0,500.0,149.0,215.0,181.0,150.0,188.0,243.0,180.0,160.0,165.0,150.0,155.0,367.0,344.0,260.0,240.0,250.0,225.0,120.0,160.0,183.0,115.0,261.0,178.0,180.0,85.0,106.0,204.0,260.0,102.0,93.0,542.0,140.0,420.0,209.0,264.0,210.0,75.0,82.0,180.0,135.0,108.0,214.0,253.0,136.0,85.0,188.0,380.0,299.0,238.0,350.0,139.0,244.0,71.0,125.0,183.0,125.0,120.0,124.0,501.0,192.0,70.0,423.0,230.0,363.0,945.0,169.0,106.0,230.0,235.0,80.0,250.0,179.0,208.0,155.0,135.0,235.0,157.0,114.0,75.0,110.0,132.0,265.0,295.0,264.0,305.0,140.0,488.0,190.0,110.0,140.0,552.0,115.0,363.0,183.0,110.0,122.0,268.0,148.0,210.0,825.0,162.0,250.0,161.0,134.0,184.0,260.0,150.0,null,240.0,150.0,158.0,141.0,129.0,95.0,80.0,103.0,263.0,202.0,180.0,200.0,200.0,150.0,80.0,155.0,327.0,68.0,144.0,165.0,64.0,175.0,350.0,285.0,114.0,300.0,42.0,null,220.0,111.0,200.0,375.0,124.0,132.0,327.0,null,160.0,137.0,108.0,345.0,120.0,124.0,152.0,170.0,461.0,90.0,200.0,162.0,314.0,366.0,85.0,null,180.0,189.0,290.0,162.0,160.0,181.0,425.0,193.0,340.0,133.0,118.0,475.0,112.0,175.0,100.0,160.0,445.0,292.0,188.0,112.0,144.0,324.0,175.0,223.0,225.0,197.0,80.0,150.0,202.0,100.0,126.0,210.0,157.0,163.0,253.0,268.0,137.0,118.0,181.0,715.0,495.0,150.0,162.0,200.0,150.0,350.0,209.0,210.0,179.0,150.0,173.0,210.0,140.0,145.0,212.0,240.0,206.0,192.0,326.0,139.0,110.0,219.0,250.0,175.0,475.0,100.0,316.0,200.0,230.0,226.0,420.0,78.0,509.0,186.0,170.0,146.0,140.0,121.0,200.0,156.0,153.0,121.0,120.0,180.0,125.0,131.0,263.0,146.0,120.0,450.0,295.0,230.0,389.0,181.0,120.0,282.0,130.0,213.0,176.0,75.0,345.0,132.0,253.0,179.0,92.0,126.0,497.0,115.0,185.0,null,176.0,250.0,200.0,270.0,144.0,65.0,390.0,92.0,300.0,90.0,225.0,130.0,300.0,201.0,133.0,380.0,120.0,265.0,98.0,281.0,279.0,null,137.0,117.0,250.0,166.0,250.0,135.0,267.0,279.0,336.0,180.0,140.0,145.0,204.0,319.0,141.0,43.0,287.0,150.0,228.0,185.0,145.0,149.0,334.0,320.0,106.0,157.0,162.0,150.0,180.0,270.0,111.0,125.0,105.0,340.0,110.0,230.0,150.0,145.0,296.0,110.0,134.0,316.0,267.0,190.0,116.0,121.0,340.0,110.0,217.0,240.0,275.0,900.0,397.0,420.0,500.0,500.0,234.0,279.0,160.0,60.0,177.0,250.0,166.0,165.0,336.0,350.0,269.0,165.0,186.0,362.0,138.0,110.0,167.0,193.0,250.0,125.0,199.0,135.0,174.0,198.0,260.0,116.0,197.0,120.0,182.0,182.0,110.0,110.0,233.0,115.0,175.0,48.0,290.0,96.0,270.0,280.0,215.0,89.0,130.0,153.0,140.0,190.0,163.0,204.0,190.0,144.0,578.0,162.0,700.0,164.0,429.0,300.0,552.0,148.0,130.0,195.0,459.0,380.0,160.0,153.0,164.0,156.0,402.0,287.0,220.0,110.0,217.0,100.0,160.0,171.0,193.0,281.0,140.0,151.0,175.0,94.0,157.0,116.0,423.0,452.0,315.0,549.0,300.0,296.0,288.0,168.0,208.0,250.0,100.0,356.0,111.0,116.0,250.0,758.0,162.0,null,68.0,850.0,280.0,341.0,130.0,100.0,231.0,308.0,131.0,92.0,180.0,242.0,168.0,150.0,220.0,120.0,176.0,294.0,235.0,280.0,75.0,187.0,104.0,136.0,80.0,201.0,107.0,155.0,300.0,550.0,127.0,401.0,300.0,170.0,523.0,156.0,181.0,209.0,72.0,200.0,120.0,238.0,254.0,300.0,131.0,210.0,307.0,360.0,313.0,155.0,521.0,174.0,220.0,192.0,192.0,175.0,130.0,84.0,119.0,190.0,197.0,182.0,163.0,180.0,115.0,515.0,174.0,139.0,381.0,96.0,220.0,249.0,410.0,200.0,145.0,170.0,230.0,155.0,193.0,239.0,240.0,130.0,292.0,263.0,178.0,121.0,506.0,94.0,200.0,109.0,244.0,117.0,123.0,130.0,287.0,251.0,212.0,190.0,137.0,216.0,305.0,111.0,160.0,240.0,199.0,384.0,279.0,156.0,297.0,105.0,195.0,534.0,255.0,130.0,160.0,195.0,130.0,184.0,200.0,133.0,218.0,256.0,178.0,120.0,50.0,102.0,113.0,150.0,171.0,145.0,650.0,75.0,350.0,345.0,350.0,177.0,115.0,210.0,129.0,101.0,257.0,227.0,80.0,205.0,262.0,192.0,370.0,269.0,109.0,538.0,300.0,160.0,264.0,249.0,225.0,195.0,1157.0],
"price":[5.278753600952829,5.997823080745725,5.662757831681574,5.2552725051033065,5.681241237375588,6.036628895362161,5.662757831681574,5.423245873936808,5.928907690243952,5.872156272748293,5.113609151073028,5.596597095626461,5.378397900948138,5.596597095626461,5.252853030979893,5.371067862271736,5.096910013008056,5.230448921378274,5.298853076409706,5.238046103128795,5.173186268412274,5.567026366159061,5.371067862271736,5.623249290397901,4.977723605288848,5.431363764158987,5.176091259055681,5.628388930050312,6.239299479126893,5.252853030979893,5.414973347970818,5.1303337684950066,5.252853030979893,6.039414119176137,5.826074802700826,6.921686475483602,6.012837224705172,5.7774268223893115,5.648360010980932,5.69810054562339,5.676693609624866,5.396199347095736,6.243038048686294,5.1303337684950066,5.7774268223893115,5.371067862271736,5.230448921378274,5.653212513775344,5.201397124320452,5.547774705387822,5.396199347095736,5.517195897949974,6.431363764158987,5.243038048686294,5.54282542695918,5.740362689494244,6.458637849025649,5.648360010980932,5.447002898466162,5.505149978319906,5.6180480967120925,5.896526217489555,5.9164539485499255,5.68930885912362,5.860338006570994,5.298853076409706,5.841984804590114,5.76715586608218,5.298853076409706,5.662757831681574,5.3404441148401185,5.7363965022766426,5.2552725051033065,5.342422680822207,5.096910013008056,5.7596678446896306,4.977723605288848,5.396199347095736,5.5301996982030825,6.371067862271736,5.600972895686748,5.518513939877887,6.469822015978163,5.57978359661681,5.662757831681574,6.088136088700551,5.47567118832443,6.078819183098848,5.6020599913279625,6.058805486675907,5.8750612633917,5.332438459915605,5.396199347095736,5.037426497940624,5.697229342759718,5.841984804590114,5.770852011642144,5.739572344450092,5.378397900948138,5.525044807036846,5.276461804173244,5.6523430550627145,5.902546779313991,5.5910646070264995,5.997823080745725,5.69810054562339,5.413299764081252,5.544068044350276,5.469822015978163,5.748188027006201,6.037426497940624,5.396199347095736,5.662757831681574,5.8444771757456815,5.662757831681574,5.429752280002408,5.385606273598312,5.933993163831242,5.439332693830263,5.555094448578319,5.342422680822207,5.929418925714293,5.359835482339888,5.252853030979893,6.161368002234975,5.917505509552547,5.361727836017593,5.841984804590114,5.589949601325708,5.819543935541868,5.7558748556724915,6.150756439860309,5.596597095626461,5.021189299069938,6.1303337684950066,5.575224804587434,5.715585551893196,5.159867847092567,5.676693609624866,5.9164539485499255,5.298853076409706,5.653212513775344,5.276461804173244,5.517195897949974,5.690196080028514,5.447158031342219,5.623249290397901,5.638489256954637,5.643353961976863,6.392696953259666,5.201397124320452,5.47567118832443,5.2552725051033065,5.653212513775344,6.079181246047625,5.469822015978163,5.652246341003323,6.276461804173244,5.2027606873932,5.47567118832443,5.652246341003323,5.298853076409706,5.628388930050312,5.648360010980932,5.252853030979893,5.544068044350276,6.174641192660449,5.469822015978163,5.574031267727719,5.378397900948138,5.230448921378274,5.951823035315912,5.290034611362518,5.832508912706237,5.5910646070264995,6.071882007306125,5.7596678446896306,5.518184804218403,5.267171728403014,6.229169702539101,5.951823035315912,5.6414741105041,5.694605198933568,5.76715586608218,5.359835482339888,5.060697840353612,5.899820502427096,6.295567099962479,5.872156272748293,5.812244696800369,5.525044807036846,5.951823035315912,5.54282542695918,5.1303337684950066,5.54282542695918,5.161368002234975,5.54282542695918,5.503790683057181,5.589949601325708,5.740362689494244,6.3414345245781405,5.69810054562339,5.854306041801081,5.176091259055681,6.439332693830263,5.209515014542631,5.371067862271736,6.290034611362518,5.77451696572855,5.298853076409706,5.4281347940287885,5.756636108245848,5.652246341003323,5.380211241711606,5.414973347970818,5.174641192660449,6.079181246047625,5.434568904034199,4.989004615698537,5.28443073384452,5.397070549959409,5.378397900948138,5.217483944213907,5.894869656745253,5.589949601325708,6.3979400086720375,6.073718350346122,5.3414345245781405,5.342225229360791,5.698970004336019,5.298853076409706,5.469822015978163,5.290034611362518,5.352182518111363,5.477121254719663,5.47567118832443,5.993436230497612,5.445604203273597,5.7596678446896306,5.414973347970818,5.748188027006201,5.173186268412274,5.54282542695918,5.675778341674085,5.267171728403014,5.653212513775344,5.531478917042255,5.378397900948138,5.363611979892144,5.173186268412274,5.537819095073274,5.460897842756548,5.872156272748293,5.447158031342219,5.8750612633917,5.1702617153949575,5.697229342759718,5.874481817699467,5.812244696800369,6.2552725051033065,5.389166084364533,5.685741738602264,6.371067862271736,5.173186268412274,5.720159303405957,5.498310553789601,6.210853365314893,5.8750612633917,6.290034611362518,5.9003671286564705,5.352182518111363,5.173186268412274,6.174641192660449,5.628388930050312,5.161368002234975,5.707570176097937,5.350248018334163,5.371067862271736,5.694605198933568,6.290034611362518,5.911157608739977,5.763427993562937,4.99563519459755,5.600972895686748,5.423245873936808,5.267171728403014,5.984527313343793,5.989004615698537,5.173186268412274,5.724275869600789,6.095169351431755,5.567026366159061,5.825426117767823,5.201397124320452,5.600972895686748,5.378397900948138,5.397070549959409,5.3979400086720375,5.217483944213907,5.7626785637274365,5.54282542695918,5.6985354925620015,5.230193378869045,5.77451696572855,5.361727836017593,5.47567118832443,5.041392685158225,5.431363764158987,5.7774268223893115,5.860338006570994,6.567614442730845,5.505149978319906,5.201397124320452,5.76715586608218,5.276461804173244,6.077367905284157,5.8750612633917,5.6127838567197355,5.77451696572855,5.596597095626461,6.491361693834273,5.54282542695918,5.176091259055681,5.146128035678238,5.997823080745725,5.143014800254095,5.439332693830263,5.685741738602264,5.474216264076255,5.812913356642856,5.929418925714293,5.585460729508501,6.297760511099134,5.739572344450092,5.354108439147401,5.389166084364533,6.628388930050312,5.77451696572855,5.860338006570994,5.694605198933568,5.4769764657595275,4.838849090737256,5.585460729508501,5.230448921378274,4.788875115775417,5.413299764081252,5.812244696800369,5.54282542695918,5.47567118832443,5.537819095073274,5.785329835010767,5.567026366159061,5.638489256954637,6.088136088700551,5.650307523131937,5.54282542695918,5.544068044350276,5.174641192660449,5.841984804590114,5.230193378869045,5.54282542695918,5.628388930050312,5.694605198933568,5.423245873936808,6.088136088700551,5.652246341003323,5.278753600952829,5.556302500767287,5.537819095073274,5.9003671286564705,5.544068044350276,5.447158031342219,5.267171728403014,5.379305517750582,5.477121254719663,5.252853030979893,5.993436230497612,5.298853076409706,5.928907690243952,6.113943352306837,6.088136088700551,5.748188027006201,5.648360010980932,5.439332693830263,6.2878017299302265,5.429752280002408,4.903089986991944,6.112269768417271,6.229169702539101,5.589949601325708,5.3404441148401185,5.201397124320452,5.384711742938283,5.47567118832443,5.76715586608218,5.5301996982030825,5.902546779313991,5.77451696572855,5.8095597146352675,5.544068044350276,6.1303337684950066,5.676693609624866,5.469822015978163,5.1303337684950066,5.739572344450092,5.623249290397901,5.556302500767287,5.812913356642856,5.811909980420099,5.5532760461371,5.57287160220048,5.8061799739838875,5.252853030979893,5.413299764081252,5.361727836017593,5.537819095073274,5.176091259055681,5.47567118832443,5.638489256954637,5.812244696800369,5.47567118832443,5.511883360978874,6.290034611362518,5.596597095626461,5.628388930050312,5.6127838567197355,5.3404441148401185,5.619615005742807,5.698970004336019,5.676693609624866,5.250420002308894,5.439332693830263,5.76715586608218,5.342422680822207,5.230448921378274,5.841984804590114,6.295567099962479,5.396199347095736,5.578639209968072,5.56643749219507,5.518513939877887,5.523746466811565,5.589949601325708,5.469822015978163,5.942008053022313,5.359835482339888,5.146128035678238,5.77451696572855,5.298853076409706,5.69810054562339,5.690196080028514,5.951823035315912,6.318063334962762,6.161368002234975,5.812913356642856,5.600972895686748,5.439332693830263,6.02530586526477,5.845098040014257,5.394451680826216,5.6674529528899535,5.5301996982030825,5.359835482339888,6.075546961392531,5.445604203273597,5.732393759822968,5.252853030979893,6.060697840353612,5.643452676486188,5.977723605288848,5.252853030979893,6.414137362184476,5.7626785637274365,5.653212513775344,6.075546961392531,5.69810054562339,5.585460729508501,5.643452676486188,5.997823080745725,5.697229342759718,5.9003671286564705,6.077367905284157,5.447158031342219,5.6512780139981444,5.190331698170292,5.77451696572855,6.1303337684950066,4.949390006644912,5.6875289612146345,5.77451696572855,5.770852011642144,5.418301291319746,5.110589710299249,5.694605198933568,5.652246341003323,5.45484486000851,5.311753861055754,5.731588765186738,5.469822015978163,5.740362689494244,5.6875289612146345,5.671172842715083,4.949390006644912,5.227886704613674,6.144574207609616,5.290034611362518,5.3222192947339195,5.600972895686748,5.662757831681574,5.662757831681574,5.977266212427293,5.503790683057181,5.902546779313991,5.589949601325708,5.45484486000851,5.954242509439325,5.993436230497612,5.919078092376074,5.9164539485499255,5.690196080028514,5.143014800254095,5.928907690243952,5.76715586608218,6.096910013008056,5.4623979978989565,5.544068044350276,5.7160033436347994,5.1303337684950066,5.600972895686748,5.658011396657113,5.531478917042255,5.079181246047625,6.439332693830263,5.6674529528899535,6.138302698166282,5.963787827345556,5.60151678365001,6.690196080028514,5.47567118832443,5.795184589682424,5.229169702539101,5.371067862271736,5.697229342759718,5.469822015978163,5.352182518111363,5.53135116458306,5.445604203273597,5.204119982655925,5.243038048686294,6.469822015978163,5.320146286111054,4.954242509439325,5.389166084364533,6.249198357391113,5.161368002234975,5.060697840353612,5.623249290397901,5.90200289135073,5.652246341003323,5.623249290397901,5.5439439424829065,5.676693609624866,5.413299764081252,5.77451696572855,5.812913356642856,5.414806279501013,5.537819095073274,5.413299764081252,5.460897842756548,5.204119982655925,5.720159303405957,5.252853030979893,5.793790384690818,5.54282542695918,6.040997692423491,5.574030109607556,5.6674529528899535,5.498310553789601,5.854306041801081,6.567614442730845,5.638489256954637,5.556302500767287,5.676693609624866,5.469822015978163,5.190331698170292,5.54282542695918,5.4769764657595275,5.600972895686748,6.290034611362518,5.54282542695918,5.511883360978874,6.277609214304091,5.3404441148401185,5.431041945335886,5.989004615698537,5.252853030979893,5.694605198933568,6.190331698170292,5.444044795918076,5.99563519459755,5.997823080745725,5.885926339801431,5.77451696572855,6.296665190261531,5.578639209968072,5.977723605288848,5.523746466811565,5.201397124320452,5.681241237375588,5.437750562820388,5.596597095626461,5.587710965018911,5.503790683057181,5.812244696800369,5.361727836017593,5.8228216453031045,5.537819095073274,5.832508912706237,5.47567118832443,5.681241237375588,5.600972895686748,5.139879086401237,5.7774268223893115,5.56466606425209,5.926856708949693,5.47567118832443,5.489958479424835,5.517195897949974,5.515634121156461,6.144574207609616,5.868644438394826,5.788875115775417,5.45484486000851,5.860338006570994,5.628388930050312,5.396199347095736,5.942008053022313,5.623249290397901,5.566816818546551,6.108903127667313,5.798650645445269,4.977723605288848,5.041392685158225,5.252853030979893,5.600972895686748,5.396199347095736,5.812913356642856,5.544068044350276,5.585460729508501,5.361727836017593,5.929418925714293,5.677515704798758,6.174641192660449,5.252853030979893,5.6875289612146345,5.574031267727719,5.173186268412274,5.986771734266245,5.685741738602264,5.45484486000851,6.077367905284157,5.474216264076255,5.489958479424835,5.250420002308894,5.389166084364533,5.740362689494244,6.525044807036846,5.812913356642856,5.276461804173244,4.986771734266245,5.469822015978163,5.201397124320452,5.110589710299249,5.628388930050312,5.7596678446896306,5.0,6.342422680822207,5.145817714491828,5.201397124320452,6.041392685158225,5.652246341003323,5.143014800254095,5.596597095626461,5.902546779313991,5.332438459915605,5.795880017344075,5.264817823009537,5.439332693830263,5.447158031342219,5.518513939877887,5.99563519459755,5.3414345245781405,5.423245873936808,5.562292864456475,5.243038048686294,5.738780558484369,5.243038048686294,5.650793039651931,5.795880017344075,5.829303772831025,5.841984804590114,5.638489256954637,5.469822015978163,5.342422680822207,5.681241237375588,5.841984804590114,6.299942900022767,5.096910013008056,5.361727836017593,5.57978359661681,5.556302500767287,5.359835482339888,5.6674529528899535,5.484299839346786,5.176091259055681,5.143014800254095,5.498310553789601,5.296665190261531,4.544068044350276,5.883661435153617,5.460897842756548,5.57172746066306,5.694605198933568,5.361727836017593,6.141449773400467,5.648360010980932,5.517195897949974,5.54282542695918,5.9003671286564705,5.60151678365001,5.276461804173244,5.872156272748293,5.378397900948138,5.290034611362518,5.389166084364533,5.76715586608218,5.439332693830263,5.648360010980932,5.574031267727719,6.0700378666077555,5.778151250383644,6.173186268412274,5.731588765186738,5.252853030979893,5.201397124320452,6.3222192947339195,5.77451696572855,5.217483944213907,4.99563519459755,5.845098040014257,6.555698894718901,5.243038048686294,5.342422680822207,6.060697840353612,5.652246341003323,5.648360010980932,5.951823035315912,6.021189299069938,5.838849090737256,5.622214022966295,5.744292983122676,5.203848463746235,5.359835482339888,5.113943352306837,5.565847818673518,5.99563519459755,6.439332693830263,5.518513939877887,5.76715586608218,5.161368002234975,5.469822015978163,5.352182518111363,5.54282542695918,5.45484486000851,5.732393759822968,5.190331698170292,5.176091259055681,5.477121254719663,5.599883072073688,5.252853030979893,5.176091259055681,5.997823080745725,5.5910646070264995,5.544068044350276,5.685741738602264,5.623249290397901,5.54282542695918,5.503790683057181,5.648360010980932,5.489958479424835,5.498310553789601,5.694605198933568,5.078819183098848,5.653212513775344,5.676693609624866,5.929418925714293,5.653212513775344,5.396199347095736,5.2405492482825995,5.431363764158987,5.676693609624866,5.041392685158225,6.397070549959409,5.596597095626461,5.694605198933568,5.54282542695918,5.204119982655925,5.997823080745725,5.300812794118117,5.342422680822207,5.863322860120456,5.445604203273597,5.889301702506311,5.585460729508501,5.267171728403014,5.2552725051033065,5.843855422623161,5.1303337684950066,4.951823035315912,5.633468455579586,5.69810054562339,5.7774268223893115,6.060697840353612,5.201397124320452,5.977723605288848,5.445604203273597,5.332438459915605,5.54282542695918,5.3404441148401185,5.54282542695918,5.361727836017593,5.977723605288848,5.672097857935717,5.562292864456475,5.633468455579586,6.146128035678238,5.396199347095736,6.4734869700645685,5.951823035315912,5.653212513775344,5.359835482339888,5.544068044350276,5.469822015978163,5.676693609624866,5.439332693830263,6.230448921378274,6.3222192947339195,5.537819095073274,5.77451696572855,5.7626785637274365,6.371067862271736,5.611723308007342,5.5910646070264995,5.661812685537261,6.359835482339888,5.469822015978163,5.76715586608218,5.396199347095736,5.359835482339888,5.622214022966295,5.555094448578319,5.694605198933568,5.903089986991944,5.230448921378274,5.503790683057181,5.491361693834273,5.342422680822207,5.423245873936808,5.937016107464814,5.671172842715083,5.298853076409706,5.430558769522757,5.252853030979893,5.47567118832443,5.298853076409706,5.445604203273597,4.949390006644912,5.146128035678238,5.413299764081252,5.544068044350276,5.041392685158225,5.9003671286564705,5.638489256954637,5.361538971269279,5.4623979978989565,5.6674529528899535,5.254064452914338,5.173186268412274,5.652246341003323,5.928907690243952,5.511883360978874,5.565257343420214,5.812913356642856,5.378397900948138,5.77451696572855,5.217483944213907,5.54282542695918,5.413299764081252,5.565257343420214,5.511883360978874,5.694605198933568,5.690196080028514,5.47567118832443,5.544068044350276,5.378397900948138,5.596597095626461,5.69810054562339,5.699751031689514,5.6211762817750355,5.841359470454855,5.445604203273597,5.47567118832443,5.7774268223893115,5.841984804590114,5.562292864456475,5.685741738602264,5.489958479424835,5.652246341003323,5.829303772831025,5.951823035315912,5.396199347095736,5.911157608739977,5.298853076409706,5.578639209968072,5.1303337684950066,5.600972895686748,6.229169702539101,5.640481436970422,5.6006135561423145,6.511883360978874,5.173186268412274,5.7558748556724915,5.326335860928752,5.056904851336473,5.880813592280791,5.671172842715083,5.795880017344075,5.997823080745725,5.585460729508501,5.139879086401237,5.161368002234975,5.977723605288848,5.252853030979893,5.445604203273597,5.357934847000454,5.096910013008056,5.1303337684950066,5.47639682672533,5.652246341003323,5.596597095626461,5.9661417327390325,5.556302500767287,5.658011396657113,5.376576957056512,5.7774268223893115,5.6674529528899535,6.021189299069938,5.926856708949693,5.628388930050312,5.413299764081252,5.676693609624866,5.198657086954422,5.77451696572855,5.652246341003323,5.926856708949693,5.763427993562937,5.296665190261531,5.505149978319906,5.461648568063455,5.623249290397901,5.7160033436347994,5.2552725051033065,5.469822015978163,5.4065401804339555,5.552668216112194,5.8095597146352675,5.477121254719663,5.511883360978874,5.69810054562339,5.889301702506311,5.161368002234975,5.175801632848279,4.949390006644912,5.648360010980932,5.698752802790154,5.653202862679622,5.600972895686748,6.544068044350276,5.949390006644912,5.298853076409706,5.145817714491828,6.146128035678238,5.397938271490635,6.060697840353612,5.075546961392531,5.954242509439325,5.69810054562339,5.225309281725863,5.740362689494244,6.096910013008056,5.7596678446896306,5.872156272748293,5.469822015978163,5.431363764158987,5.600972895686748,5.648360010980932,5.9003671286564705,5.993436230497612,5.447158031342219,5.829303772831025,5.731588765186738,5.8750612633917,6.077367905284157,5.201397124320452,5.2405492482825995,5.562292864456475,5.54282542695918,5.298853076409706,5.359835482339888,5.585460729508501,6.112269768417271,5.652246341003323,5.658011396657113,5.99563519459755,5.396199347095736,5.711807229041191,5.3979400086720375,5.76715586608218,5.394451680826216,6.161068385471174,5.857332496431268,5.845098040014257,5.378397900948138,5.652246341003323,5.739572344450092,5.060697840353612,6.031408464251625,5.8088858673598125,5.929418925714293,5.9164539485499255,5.7363965022766426,5.694605198933568,5.574031267727719,5.389166084364533,5.740362689494244,5.525044807036846,5.096562438374136,5.5301996982030825,5.298853076409706,6.027349607774757,5.352182518111363,5.096910013008056,5.694605198933568,6.229169702539101,6.041392685158225,5.457881896733992,5.556302500767287,5.7160033436347994,5.075546961392531,5.423245873936808,5.731588765186738,5.505828033854836,5.7774268223893115,5.555094448578319,5.544068044350276,5.460897842756548,5.190331698170292,5.928907690243952,5.578639209968072,5.47567118832443,5.8095597146352675,5.352182518111363,5.623249290397901,5.413299764081252,5.227886704613674,5.469822015978163,4.897627091290442,5.874481817699467,5.672097857935717,5.371067862271736,5.685741738602264,5.380211241711606,5.676693609624866,5.060697840353612,5.077367905284157,5.212187604403958,5.041392685158225,5.041392685158225,5.911157608739977,5.290034611362518,5.252853030979893,5.676693609624866,5.389166084364533,5.446381812222442,5.620656479819621,5.190331698170292,6.201397124320452,5.47567118832443,5.203848463746235,5.653212513775344,5.474216264076255,5.740361899867195,5.47567118832443,5.748188027006201,5.469822015978163,5.5910646070264995,5.469822015978163,6.071882007306125,6.201397124320452,5.075546961392531,5.54282542695918,5.361727836017593,5.3222192947339195,5.4048337166199385,5.352182518111363,5.977266212427293,5.919078092376074,5.8444771757456815,4.949390006644912,5.290034611362518,5.7923916894982534,5.638489256954637,5.562292864456475,5.866287339084195,5.77451696572855,5.8061799739838875,5.2552725051033065,5.77451696572855,6.273001272063738,5.69810054562339,5.841984804590114,5.434568904034199,5.812913356642856,5.697229342759718,5.755112266395071,5.175801632848279,6.150756439860309,5.661812685537261,5.389166084364533,5.552668216112194,5.278753600952829,5.320146286111054,5.396199347095736,5.954242509439325,5.243038048686294,5.694605198933568,5.267171728403014,6.295567099962479,5.676693609624866,5.243038048686294,6.173186268412274,5.139879086401237,5.3404441148401185,5.77451696572855,5.298853076409706,5.176091259055681,5.642464520242122,5.3414345245781405,5.7363965022766426,5.600972895686748,5.672097857935717,5.175801632848279,5.652246341003323,5.599883072073688,5.096910013008056,4.903089986991944,5.1303337684950066,5.352182518111363,4.874481817699467,5.601951404133522,6.296665190261531,5.217483944213907,5.294466226161593,5.525044807036846,5.45484486000851,5.854306041801081,5.484299839346786,6.171726453653231,5.600972895686748,5.574031267727719,5.396199347095736,5.298853076409706,5.466867620354109,5.110589710299249,5.812913356642856,5.9003671286564705,5.429752280002408,6.276461804173244,5.611723308007342,5.954242509439325,5.99563519459755,5.359835482339888,5.396199347095736,5.252853030979893,5.6464037262230695,5.6674529528899535,5.57287160220048,5.396199347095736,5.984527313343793,5.748188027006201,5.4623979978989565,5.505149978319906,6.173186268412274,6.174641192660449,5.112269768417271,6.319896858814888,6.266936911159173,5.113943352306837,5.491361693834273,5.676693609624866,5.4065401804339555,5.599883072073688,5.2552725051033065,5.060697840353612,5.599883072073688,5.505149978319906,5.826074802700826,5.45484486000851,5.332438459915605,5.752048447819439,4.949390006644912,5.217483944213907,5.460897842756548,5.694605198933568,5.720159303405957,5.3979400086720375,5.997823080745725,5.423245873936808,6.250420002308894,5.359835482339888,6.254064452914338,5.997823080745725,5.658011396657113,5.7160033436347994,6.544068044350276,5.389166084364533,5.096910013008056,5.567026366159061,6.077367905284157,5.544068044350276,5.7596678446896306,5.578639209968072,6.430558769522757,5.715167357848458,5.599883072073688,5.596597095626461,5.47567118832443,5.616107757092463,6.175801632848279,5.841984804590114,5.632457292184724,5.396199347095736,5.505149978319906,5.469822015978163,5.290034611362518,5.7774268223893115,5.380211241711606,5.7774268223893115,5.550228353055094,6.469822015978163,5.445604203273597,5.812244696800369,5.77451696572855,5.1303337684950066,6.217483944213907,5.652246341003323,5.585460729508501,5.505149978319906,5.396199347095736,5.9164539485499255,5.380211241711606,5.060697840353612,5.6020589055904,5.653212513775344,5.144574207609616,5.54282542695918,5.622214022966295,5.477121254719663,5.290034611362518,5.146128035678238,6.060697840353612,5.829303772831025,5.9003671286564705,5.77451696572855,5.342422680822207,5.707570176097937,5.460897842756548,5.623249290397901,5.173186268412274,5.69810054562339,5.600972895686748,5.623249290397901,5.439332693830263,5.429752280002408,5.52244423350632,5.252853030979893,5.672097857935717,5.650307523131937,5.694605198933568,5.589949601325708,5.585460729508501,5.694605198933568,5.1303337684950066,5.300812794118117,5.795880017344075,5.243038048686294,5.997823080745725,5.600972895686748,5.812913356642856,5.69810054562339,5.694605198933568,5.445604203273597,5.173186268412274,5.158362492095249,5.829303772831025,5.45484486000851,5.252853030979893,5.060697840353612,5.187520720836463,5.4769764657595275,5.600972895686748,5.574031267727719,5.68930885912362,5.785329835010767,5.276461804173244,5.517195897949974,5.680335513414564,5.217483944213907,5.694605198933568,5.556302500767287,5.752240571017397,6.254064452914338,5.439332693830263,6.477121254719663,5.623249290397901,5.628388930050312,5.9003671286564705,5.54282542695918,5.503790683057181,5.445604203273597,5.298853076409706,5.894869656745253,5.352182518111363,4.929418925714293,5.633468455579586,5.8750612633917,5.648360010980932,5.627365856592733,5.69810054562339,5.913813852383717,4.889301702506311,5.835690571492425,5.841984804590114,5.913813852383717,5.643452676486188,5.795880017344075,5.600972895686748,5.146128035678238,5.537819095073274,5.54282542695918,5.694605198933568,6.110589710299249,5.748188027006201,5.919078092376074,5.650793039651931,5.672097857935717,6.1702617153949575,5.942008053022313,5.45484486000851,5.503790683057181,5.8444771757456815,5.812913356642856,5.929418925714293,5.7558748556724915,5.567026366159061,5.298853076409706,5.872156272748293,5.176091259055681,5.770852011642144,5.977723605288848,6.3414345245781405,5.378397900948138,5.243038048686294,5.555094448578319,5.7596678446896306,5.161368002234975,5.9661417327390325,5.835690571492425,5.139879086401237,5.47567118832443,6.290034611362518,5.3222192947339195,6.110589710299249,6.096910013008056,5.5301996982030825,5.799340549453582,5.525044807036846,5.977723605288848,6.079181246047625,5.352182518111363,5.5439439424829065,5.201397124320452,5.648360010980932,5.4623979978989565,5.643452676486188,5.041392685158225,5.445604203273597,5.7596678446896306,5.6127838567197355,5.45484486000851,5.352182518111363,5.276461804173244,5.173186268412274,6.254064452914338,6.3222192947339195,5.841984804590114,6.469822015978163,5.3414345245781405,5.230448921378274,5.267171728403014,5.585460729508501,5.648360010980932,5.110589710299249,5.204119982655925,5.954242509439325,5.505149978319906,5.596597095626461,5.913813852383717,5.201397124320452,6.278753600952829,5.567026366159061,5.477121254719663,5.544068044350276,5.8095597146352675,5.252853030979893,5.143014800254095,5.145817714491828,6.229169702539101,5.460897842756548,5.7363965022766426,5.298853076409706,5.997823080745725,5.724275869600789,6.3404441148401185,6.060697840353612,5.173186268412274,5.311753861055754,5.56466606425209,6.45484486000851,5.311753861055754,5.298853076409706,5.414973347970818,5.770852011642144,5.652246341003323,5.9344984512435675,5.229169702539101,5.69810054562339,5.993436230497612,5.350248018334163,5.511883360978874,5.694605198933568,5.841984804590114,5.623249290397901,5.676693609624866,5.267171728403014,5.596597095626461,5.628388930050312,5.585460729508501,5.740362689494244,5.511883360978874,5.110589710299249,5.739572344450092,5.694605198933568,5.977266212427293,5.54282542695918,5.829303772831025,5.201397124320452,5.585460729508501,5.6180480967120925,5.252853030979893,6.143014800254095,5.525044807036846,5.9164539485499255,5.949390006644912,5.585460729508501,5.9003671286564705,5.1303337684950066,5.1303337684950066,5.469822015978163,5.243038048686294,5.947923619831727,5.378397900948138,5.096910013008056,5.431363764158987,5.740362689494244,5.5938396610812715,5.423245873936808,5.7363965022766426,5.531478917042255,6.76715586608218,5.680335513414564,5.173186268412274,5.4623979978989565,5.267171728403014,5.47567118832443,5.694605198933568,6.143014800254095,5.276461804173244,6.30015944903796,6.017033339298781,5.187520720836463,5.897627091290442,5.332438459915605,5.227886704613674,5.146128035678238,6.229169702539101,5.653212513775344,6.19728055812562,5.2552725051033065,5.54282542695918,5.99563519459755,5.371067862271736,5.662757831681574,5.926856708949693,5.596597095626461,5.173186268412274,5.498310553789601,5.252853030979893,5.3404441148401185,5.77451696572855,5.642464520242122,5.176091259055681,5.574031267727719,6.021189299069938,5.460897842756548,5.574031267727719,5.829303772831025,5.477121254719663,5.503790683057181,5.511883360978874,5.812913356642856,5.498310553789601,5.676693609624866,5.47567118832443,5.252853030979893,5.81888541459401,5.860338006570994,6.574031267727719,5.343408593803857,5.997823080745725,5.359835482339888,5.511214701136388,5.469822015978163,5.276461804173244,5.173186268412274,5.7283537820212285,5.352182518111363,5.445604203273597,5.298853076409706,6.096910013008056,5.6674529528899535,5.176091259055681,5.676693609624866,6.112269768417271,6.1303337684950066,5.544068044350276,5.600972895686748,5.431363764158987,5.841984804590114,6.47639682672533,6.096562438374136,5.439332693830263,5.598790506763115,5.075546961392531,5.929418925714293,6.903089986991944,5.4065401804339555,5.175801632848279,5.110589710299249,5.642464520242122,6.60151678365001,5.653212513775344,5.4065401804339555,5.45484486000851,6.144574207609616,5.795880017344075,5.4623979978989565,5.9003671286564705,5.54282542695918,5.9614210940664485,5.681241237375588,5.110589710299249,5.628388930050312,4.977723605288848,6.077367905284157,5.439332693830263,5.841984804590114,5.173186268412274,5.77451696572855,5.690196080028514,5.889301702506311,5.574031267727719,5.5301996982030825,6.371067862271736,5.298853076409706,5.298853076409706,5.73538888670613,5.7363965022766426,5.568201724066995,6.039414119176137,5.227886704613674,5.69810054562339,5.278753600952829,5.243038048686294,5.332438459915605,5.544068044350276,5.7558748556724915,5.8095597146352675,5.210853365314893,5.359835482339888,5.144574207609616,5.829303772831025,5.694605198933568,5.633468455579586,5.841984804590114,5.505149978319906,5.276461804173244,6.290034611362518,5.9003671286564705,6.277609214304091,5.54282542695918,5.54282542695918,5.332438459915605,5.975431808509263,5.77451696572855,5.517195897949974,5.537819095073274,5.544068044350276,5.8095597146352675,5.544068044350276,5.423245873936808,5.423245873936808,5.389166084364533,5.3979400086720375,6.027349607774757,4.99563519459755,5.894869656745253,5.69810054562339,5.518513939877887,5.977266212427293,6.060697840353612,5.47567118832443,5.838849090737256,5.396199347095736,5.714329759745233,5.469822015978163,5.352182518111363,5.278753600952829,5.600972895686748,5.574031267727719,4.838849090737256,5.301029995663981,5.623249290397901,5.926856708949693,5.720159303405957,5.230448921378274,5.7283537820212285,5.6180480967120925,5.585460729508501,5.429752280002408,5.342422680822207,5.681241237375588,5.430558769522757,5.243038048686294,5.2027606873932,5.431363764158987,5.977266212427293,5.173186268412274,6.3979400086720375,5.1303337684950066,5.204119982655925,5.897627091290442,5.371067862271736,5.685741738602264,5.361727836017593,4.897627091290442,5.628388930050312,6.060697840353612,5.413299764081252,5.676693609624866,5.680335513414564,5.77451696572855,5.423245873936808,5.414973347970818,5.694605198933568,5.342422680822207,5.3979400086720375,5.975431808509263,5.694605198933568,5.531478917042255,6.267171728403014,5.939019776448666,5.359835482339888,5.1303337684950066,5.951823035315912,5.469822015978163,5.378397900948138,5.681241237375588,5.9003671286564705,5.361727836017593,5.598790506763115,5.685741738602264,5.176091259055681,5.599883072073688,5.694605198933568,6.133538908370218,5.662757831681574,5.511883360978874,5.361727836017593,5.252853030979893,5.243038048686294,5.926856708949693,5.320146286111054,5.243038048686294,5.6020589055904,5.39776625612645,5.378397900948138,5.47567118832443,5.252853030979893,5.6674529528899535,5.113943352306837,5.173186268412274,5.829303772831025,6.254064452914338,5.214843848047698,5.975431808509263,6.174641192660449,5.060697840353612,5.8095597146352675,6.110589710299249,6.829303772831025,6.296665190261531,5.45484486000851,5.600972895686748,5.418301291319746,5.517195897949974,5.949390006644912,5.511883360978874,5.332438459915605,6.299942900022767,5.7774268223893115,5.537819095073274,5.599883072073688,5.243038048686294,5.298853076409706,5.7923916894982534,5.841984804590114,6.0,5.623249290397901,5.740362689494244,5.872156272748293,5.781755374652469,5.596597095626461,5.371067862271736,6.439332693830263,5.6950436588212945,5.6127838567197355,6.201397124320452,6.491361693834273,5.648360010980932,5.359835482339888,5.359835482339888,5.146128035678238,5.567026366159061,5.252853030979893,5.7363965022766426,5.567026366159061,5.883661435153617,5.902546779313991,5.378397900948138,5.161068385471174,6.36078268987328,5.47567118832443,5.977723605288848,5.7774268223893115,6.447158031342219,5.378397900948138,5.658011396657113,5.951823035315912,5.7596678446896306,6.380211241711606,5.8095597146352675,5.638489256954637,5.217483944213907,5.037426497940624,6.227886704613674,5.517195897949974,5.739572344450092,5.874481817699467,6.112269768417271,5.812846536967071,4.999565488225982,5.7626785637274365,5.3404441148401185,5.568201724066995,5.350248018334163,5.685293781386784,5.342422680822207,5.243038048686294,5.600972895686748,5.662757831681574,5.975431808509263,5.544068044350276,5.161368002234975,6.653212513775344,5.267171728403014,5.096910013008056,6.112269768417271,5.544068044350276,5.739572344450092,5.7363965022766426,6.342422680822207,5.110589710299249,6.060697840353612,5.812913356642856,5.298853076409706,5.049218022670182,5.948901760970213,5.589949601325708,5.517195897949974,5.505149978319906,4.929418925714293,5.423245873936808,5.201397124320452,5.332438459915605,5.5910646070264995,6.921686475483602,5.1003705451175625,5.744292983122676,5.515634121156461,5.628388930050312,5.3404441148401185,5.359835482339888,5.977723605288848,5.469822015978163,5.544068044350276,5.880813592280791,5.158362492095249,5.9164539485499255,5.68930885912362,5.837588438235511,5.77451696572855,5.096910013008056,6.161368002234975,6.112269768417271,5.517195897949974,5.531478917042255,5.926856708949693,5.429752280002408,5.7283537820212285,5.758911892397974,6.20002926655377,5.642464520242122,6.3414345245781405,5.537819095073274,5.429752280002408,5.672097857935717,5.685741738602264,5.929418925714293,5.550228353055094,5.45484486000851,5.770852011642144,5.443575879750258,5.469822015978163,5.811575005870593,5.694605198933568,5.301029995663981,5.951823035315912,5.3222192947339195,5.217483944213907,5.267171728403014,5.3222192947339195,5.3404441148401185,5.5301996982030825,5.778151250383644,5.5301996982030825,5.600972895686748,5.4281347940287885,5.201397124320452,5.62314587463794,6.176091259055681,5.7619278384205295,5.474216264076255,5.146128035678238,5.531478917042255,6.096910013008056,5.832508912706237,5.968482948553935,5.439332693830263,5.57978359661681,5.469822015978163,5.477121254719663,5.7596678446896306,5.041392685158225,5.600972895686748,5.567026366159061,5.2552725051033065,5.896526217489555,5.724275869600789,5.7596678446896306,6.105510184769974,5.567026366159061,5.08278537031645,5.298853076409706,6.77451696572855,5.276461804173244,5.108903127667313,5.755112266395071,5.447158031342219,5.096910013008056,5.825426117767823,5.628388930050312,5.77451696572855,5.267171728403014,5.491361693834273,5.414806279501013,5.707570176097937,6.060697840353612,5.413299764081252,5.460897842756548,6.298853076409706,5.380211241711606,5.977723605288848,5.949390006644912,6.201397124320452,5.582327042848944,5.544068044350276,5.929418925714293,5.447158031342219,5.45484486000851,5.6148972160331345,5.740362689494244,5.447158031342219,5.7596678446896306,5.096910013008056,5.229169702539101,5.47639682672533,6.2041197112217885,5.190331698170292,5.201397124320452,5.544068044350276,5.146128035678238,5.389166084364533,6.544068044350276,5.784617292632875,5.829303772831025,5.217483944213907,5.841984804590114,5.585460729508501,5.45484486000851,5.243038048686294,5.225309281725863,5.161368002234975,6.039414119176137,5.298853076409706,5.812244696800369,5.143014800254095,5.897627091290442,5.9614210940664485,5.3222192947339195,5.350248018334163,5.951823035315912,5.439332693830263,5.769377326076138,5.812244696800369,5.681241237375588,5.227886704613674,5.77451696572855,5.5918700883362344,5.267171728403014,5.799340549453582,5.423245873936808,6.060697840353612,5.628388930050312,5.396199347095736,5.396199347095736,5.628388930050312,5.6875289612146345,5.694605198933568,5.544068044350276,5.227886704613674,5.311753861055754,5.47567118832443,5.376576957056512,5.096910013008056,5.429752280002408,5.671172842715083,5.161368002234975,5.9003671286564705,5.829303772831025,5.69810054562339,5.47567118832443,6.252853030979893,5.841984804590114,6.041392685158225,5.3404441148401185,5.812913356642856,5.460897842756548,6.290034611362518,5.460897842756548,5.413299764081252,5.6020599913279625,5.926856708949693,5.694605198933568,5.685741738602264,5.6148972160331345,5.498310553789601,6.212187604403958,5.632457292184724,5.627365856592733,5.8055008581584,5.894869656745253,5.585460729508501,6.021189299069938,5.929418925714293,6.041392685158225,5.653212513775344,5.7664128471124,5.6180480967120925,5.252853030979893,5.7596678446896306,5.872156272748293,5.437750562820388,6.105510184769974,5.963787827345556,5.1303337684950066,5.477121254719663,5.371067862271736,5.414973347970818,5.510545010206612,5.511883360978874,5.518513939877887,5.161368002234975,5.413299764081252,5.342422680822207,5.54282542695918,6.276461804173244,5.173186268412274,5.414137362184476,5.439332693830263,5.388988785124714,5.332438459915605,5.243038048686294,6.079181246047625,4.903089986991944,5.110589710299249,5.359835482339888,5.517195897949974,5.423245873936808,5.951823035315912,5.267171728403014,5.7596678446896306,5.69810054562339,5.301029995663981,6.805840548814673,5.252853030979893,5.298853076409706,5.230448921378274,5.57978359661681,5.69810054562339,5.447158031342219,5.770115294787102,5.8444771757456815,5.173186268412274,5.938519725176492,5.8061799739838875,5.511883360978874,5.799340549453582,5.596597095626461,5.6127838567197355,5.45484486000851,5.541579243946581,5.84323277809801,5.204119982655925,5.600972895686748,5.633468455579586,5.648360010980932,5.3979400086720375,5.041392685158225,5.802773725291976,5.267171728403014,5.556302500767287,5.176091259055681,5.320146286111054,5.679427896612119,5.439332693830263,5.997823080745725,5.201397124320452,5.880813592280791,5.574031267727719,5.999995657033466,5.903089986991944,5.531478917042255,5.204119982655925,5.445604203273597,6.607455023214668,5.600972895686748,5.040997692423491,5.5301996982030825,5.676693609624866,6.446381812222442,5.518513939877887,6.0603200286882855,5.352182518111363,5.447158031342219,5.574031267727719,5.69810054562339,6.216165902285993,5.041392685158225,5.161368002234975,5.431363764158987,5.989004615698537,5.413299764081252,6.414137362184476,5.510545010206612,5.697229342759718,5.2405492482825995,5.143014800254095,5.841984804590114,5.217483944213907,5.227886704613674,5.652246341003323,5.489958479424835,5.201397124320452,5.723455672035186,5.652246341003323,5.298853076409706,5.474216264076255,5.600972895686748,6.217483944213907,5.902546779313991,5.921686475483602,5.161368002234975,5.719331286983727,5.638489256954637,5.375663613960885,5.204119982655925,4.991226075692495,6.201397124320452,5.469822015978163,5.913813852383717,5.190331698170292,5.835690571492425,5.5301996982030825,5.8750612633917,5.173186268412274,5.574030109607556,6.210853365314893,4.99563519459755,4.929418925714293,5.371067862271736,5.537819095073274,5.174641192660449,5.6180480967120925,5.243038048686294,5.380211241711606,5.544068044350276,5.146128035678238,6.060697840353612,5.694605198933568,5.275311354541811,5.230448921378274,5.187520720836463,5.1303337684950066,5.396199347095736,5.45484486000851,5.64738297011462,5.903089986991944,5.54282542695918,5.894869656745253,6.153814864344529,6.019116290447073,5.632457292184724,5.517195897949974,5.143014800254095,5.977723605288848,5.204119982655925,5.951823035315912,5.477121254719663,5.544068044350276,5.477121254719663,6.021189299069938,6.105510184769974,5.276461804173244,5.3979400086720375,5.489958479424835,5.54282542695918,5.110589710299249,5.037426497940624,5.332438459915605,5.694605198933568,5.517195897949974,5.217483944213907,6.295567099962479,5.755112266395071,6.089905111439398,5.445604203273597,6.267171728403014,5.389166084364533,5.2552725051033065,5.740362689494244,5.872156272748293,5.342422680822207,5.970811610872518,5.7923916894982534,5.997823080745725,4.982271233039568,5.874481817699467,5.267171728403014,5.8750612633917,5.841984804590114,5.565847818673518,5.173186268412274,5.173186268412274,5.439332693830263,5.332438459915605,5.175801632848279,5.469822015978163,5.423245873936808,5.47639682672533,5.544068044350276,5.845035993513415,5.525044807036846,5.812913356642856,5.628388930050312,5.6512780139981444,5.9003671286564705,5.652246341003323,5.250420002308894,5.5301996982030825,6.161368002234975,5.9003671286564705,5.096910013008056,6.039414119176137,5.600972895686748,5.342422680822207,5.720159303405957,5.3404441148401185,5.7160033436347994,5.217483944213907,5.227886704613674,5.332438459915605,5.8095597146352675,5.7363965022766426,5.929418925714293,5.600972895686748,5.622214022966295,6.1303337684950066,5.931966114728173,4.903089986991944,5.555094448578319,5.8750612633917,5.544068044350276,5.6020599913279625,5.680335513414564,5.57978359661681,5.7774268223893115,5.697229342759718,5.661812685537261,5.662757831681574,6.054995861529141,5.276461804173244,5.77451696572855,5.252853030979893,5.359835482339888,5.298853076409706,5.423245873936808,5.469822015978163,5.3414345245781405,5.396199347095736,6.176091259055681,5.866287339084195,5.447158031342219,5.672005445022952,5.515634121156461,5.951823035315912,5.54282542695918,5.326335860928752,5.469822015978163,5.54282542695918,5.989004615698537,5.795880017344075,5.7160033436347994,5.190331698170292,6.054995861529141,5.658011396657113,5.47567118832443,5.857332496431268,6.267171728403014,5.45484486000851,5.447158031342219,5.021189299069938,5.173186268412274,5.041392685158225,5.562292864456475,5.113609151073028,5.928907690243952,5.54282542695918,5.389166084364533,5.518513939877887,5.653212513775344,5.574031267727719,5.428944290035575,5.9003671286564705,5.161368002234975,4.929418925714293,5.298853076409706,5.47567118832443,6.778151250383644,5.429752280002408,5.652246341003323,5.720159303405957,5.953759691733229,6.174641192660449,6.077367905284157,5.600972895686748,5.45484486000851,5.176091259055681,5.143014800254095,5.472756449317212,5.6674529528899535,5.680335513414564,5.628388930050312,5.332438459915605,5.567026366159061,5.498310553789601,5.396199347095736,5.176091259055681,5.600972895686748,5.600972895686748,5.600972895686748,5.795880017344075,5.267171728403014,5.662757831681574,6.36078268987328,5.829303772831025,5.143014800254095,5.860338006570994,6.45484486000851,5.6180480967120925,5.250420002308894,5.445604203273597,5.365487984890899,5.829303772831025,6.1126050015345745,5.3222192947339195,5.474216264076255,5.525044807036846,6.469822015978163,5.997823080745725,5.755112266395071,5.517195897949974,5.7774268223893115,6.102090525511836,5.36078268987328,5.567026366159061,5.45484486000851,5.371067862271736,5.8444771757456815,4.8750612633917,6.482873583608754,5.562292864456475,5.833784374656479,5.942008053022313,5.201397124320452,5.474216264076255,5.469822015978163,5.143014800254095,5.951823035315912,5.277609214304091,5.611723308007342,5.267171728403014,5.652246341003323,6.469822015978163,5.8750612633917,5.770852011642144,5.143014800254095,5.585460729508501,5.590507462008583,6.077367905284157,5.505149978319906,6.096910013008056,5.389166084364533,5.6020599913279625,5.352182518111363,5.173186268412274,5.267171728403014,6.342422680822207,6.1003705451175625,5.47567118832443,5.301029995663981,5.429752280002408,5.829303772831025,5.54282542695918,5.720159303405957,5.173186268412274,5.653212513775344,5.638489256954637,5.445604203273597,5.175801632848279,5.653212513775344,5.68930885912362,5.937016107464814,6.220108088040055,6.628388930050312,5.617000341120899,5.161368002234975,5.267171728403014,6.096910013008056,5.342422680822207,5.7923916894982534,6.230448921378274,5.267171728403014,5.9003671286564705,5.795880017344075,5.217483944213907,5.69810054562339,5.623249290397901,5.770852011642144,5.3979400086720375,5.662757831681574,5.661812685537261,5.518513939877887,5.628388930050312,5.47567118832443,5.413299764081252,5.630427875025024,5.788875115775417,5.883661435153617,5.77451696572855,5.739572344450092,5.359835482339888,5.740362689494244,5.276461804173244,5.568201724066995,5.541579243946581,5.841984804590114,5.414973347970818,5.190331698170292,5.4623979978989565,5.320146286111054,5.54282542695918,5.3222192947339195,5.600972895686748,5.6674529528899535,5.474216264076255,5.589949601325708,5.8750612633917,5.544068044350276,5.47567118832443,6.431363764158987,5.676693609624866,5.54282542695918,5.977723605288848,6.190331698170292,5.301029995663981,5.1303337684950066,5.361727836017593,5.585460729508501,6.079181246047625,5.707570176097937,5.276461804173244,5.544068044350276,5.77451696572855,5.7923916894982534,5.989004615698537,5.676693609624866,5.173186268412274,5.874481817699467,5.176091259055681,5.47567118832443,5.685741738602264,5.574031267727719,5.719331286983727,5.841984804590114,5.953759691733229,5.298853076409706,5.252853030979893,5.652246341003323,5.39776625612645,6.144574207609616,5.77451696572855,5.596597095626461,5.628388930050312,5.252853030979893,5.69810054562339,5.060697840353612,5.0,5.460897842756548,5.8444771757456815,4.99563519459755,5.5301996982030825,5.47567118832443,5.7774268223893115,5.201397124320452,5.578639209968072,5.69810054562339,5.872156272748293,6.278753600952829,5.596597095626461,5.161368002234975,5.4623979978989565,5.517195897949974,5.991226075692495,5.812913356642856,5.69810054562339,5.060697840353612,5.429752280002408,5.77451696572855,5.600972895686748,5.3979400086720375,5.993436230497612,5.638489256954637,5.378397900948138,5.396199347095736,5.531478917042255,5.47567118832443,5.860338006570994,5.816241299991783,5.889301702506311,6.439332693830263,5.681241237375588,6.077367905284157,5.3404441148401185,5.8750612633917,5.590953235187985,5.556302500767287,5.99563519459755,5.525044807036846,5.396199347095736,5.732480610034617,5.578639209968072,5.2027606873932,5.574031267727719,6.371067862271736,5.271841606536499,6.469822015978163,5.7283537820212285,5.90200289135073,5.928907690243952,5.3404441148401185,4.897627091290442,5.602005701124516,5.77451696572855,5.926856708949693,5.7160033436347994,5.460897842756548,5.9237619608287,5.739572344450092,5.267171728403014,6.168792020314182,5.763427993562937,5.47567118832443,6.290034611362518,5.218797998111738,5.278753600952829,5.159867847092567,5.230193378869045,5.530839778616521,5.841984804590114,5.628388930050312,5.574031267727719,5.352182518111363,6.73996769675951,5.954242509439325,5.617157665694944,6.095169351431755,5.3404441148401185,5.642464520242122,6.112269768417271,5.632457292184724,5.73996769675951,5.469822015978163,5.264817823009537,5.676693609624866,5.567026366159061,5.350248018334163,5.88309335857569,5.361727836017593,5.204119982655925,5.3979400086720375,5.290034611362518,5.446847710155809,5.439332693830263,5.638489256954637,5.371067862271736,5.959041392321094,5.57978359661681,5.439332693830263,5.511883360978874,5.47639682672533,5.491361693834273,5.460897842756548,5.075546961392531,5.649334858712142,5.173186268412274,5.54282542695918,5.6674529528899535,5.574031267727719,5.953759691733229,5.321184027302314,5.2405492482825995,6.243038048686294,5.204119982655925,5.290034611362518,5.902546779313991,5.719289844693328,5.477121254719663,5.371067862271736,4.8750612633917,5.439332693830263,6.112269768417271,5.578639209968072,5.841984804590114,5.770115294787102,5.889301702506311,5.653212513775344,6.2552725051033065,5.298853076409706,5.217483944213907,5.511883360978874,5.267171728403014,5.7774268223893115,5.503790683057181,5.54282542695918,5.567026366159061,5.6127838567197355,5.371067862271736,5.352182518111363,5.146128035678238,5.559308010907013,5.694605198933568,5.176091259055681,5.880813592280791,5.648360010980932,5.8750612633917,6.039414119176137,6.505149978319906,5.161368002234975,5.926856708949693,5.7558748556724915,5.517195897949974,5.8512583487190755,6.273001272063738,5.977266212427293,5.77451696572855,5.041392685158225,5.568201724066995,5.332438459915605,5.671172842715083,5.552668216112194,5.146128035678238,5.662757831681574,6.174641192660449,5.589949601325708,5.977723605288848,5.589949601325708,5.517195897949974,5.902546779313991,5.6127838567197355,5.537819095073274,4.951823035315912,5.991226075692495,5.841984804590114,5.812913356642856,5.631443769013172,5.298853076409706,5.6527296960692475,5.469822015978163,5.332438459915605,5.644241585843728,5.342422680822207,5.498310553789601,5.652246341003323,5.857332496431268,6.47639682672533,5.544068044350276,5.715167357848458,5.698970004336019,5.252853030979893,5.47567118832443,5.671172842715083,5.389166084364533,5.951823035315912,5.096910013008056,5.176091259055681,5.77451696572855,5.190331698170292,5.578639209968072,5.173186268412274,5.7774268223893115,5.413299764081252,5.469822015978163,5.05307844348342,5.69810054562339,5.352182518111363,5.690196080028514,5.68930885912362,5.7596678446896306,5.589949601325708,5.4623979978989565,5.711807229041191,5.378397900948138,5.224014811372864,5.6180480967120925,5.255031163345551,5.056904851336473,5.361727836017593,5.517195897949974,5.841984804590114,5.623249290397901,5.77451696572855,5.720159303405957,5.841984804590114,5.835690571492425,5.596597095626461,6.439332693830263,5.574031267727719,6.299942900022767,6.6429588794097905,5.841984804590114,5.661812685537261,5.596597095626461,5.45484486000851,5.375663613960885,5.685741738602264,6.276461804173244,5.252853030979893,5.9003671286564705,5.252853030979893,5.989004615698537,5.975431808509263,5.544068044350276,5.724275869600789,5.361727836017593,5.174641192660449,5.3222192947339195,5.429752280002408,5.739572344450092,5.6020599913279625,5.652246341003323,5.590199611519773,5.825426117767823,6.0,5.447158031342219,5.3979400086720375,5.496929648073215,5.557507201905658,5.3404441148401185,5.959041392321094,5.671172842715083,5.290034611362518,5.491361693834273,5.825426117767823,5.444044795918076,6.173186268412274,5.378397900948138,5.9003671286564705,4.812913356642856,5.672097857935717,5.653212513775344,5.7923916894982534,5.113943352306837,5.690196080028514,5.929418925714293,5.596597095626461,5.056904851336473,5.378397900948138,5.607455023214668,5.628388930050312,5.298853076409706,5.278753600952829,6.292256071356476,5.676693609624866,5.298853076409706,6.290034611362518,5.201397124320452,5.489958479424835,5.568201724066995,5.201397124320452,5.892094602690481,5.989004615698537,5.110589710299249,4.949390006644912,6.707570176097937,5.628388930050312,5.517195897949974,4.99563519459755,5.672559627763276,5.060697840353612,5.568201724066995,5.694605198933568,5.740362689494244,5.770852011642144,5.113609151073028,5.217483944213907,5.6020599913279625,5.313867220369153,5.146128035678238,5.685741738602264,5.203848463746235,6.292256071356476,5.903089986991944,5.505149978319906,5.841984804590114,5.47567118832443,5.227886704613674,5.812913356642856,5.47567118832443,5.113943352306837,5.460897842756548,5.628388930050312,6.012837224705172,5.5434471800817,5.720159303405957,4.977723605288848,5.951823035315912,5.413299764081252,5.926856708949693,5.429752280002408,5.76715586608218,5.929418925714293,5.45484486000851,5.903089986991944,5.62314587463794,5.653212513775344,5.889301702506311,5.252853030979893,5.096910013008056,5.544068044350276,5.570542939881897,5.161368002234975,6.389166084364533,5.250420002308894,5.69810054562339,6.0,5.7774268223893115,5.6523430550627145,6.096910013008056,5.57978359661681,5.628388930050312,5.352182518111363,5.1303337684950066,5.447158031342219,5.929418925714293,5.54282542695918,5.396199347095736,6.299942900022767,5.970811610872518,5.854306041801081,5.359835482339888,5.45484486000851,5.5843312243675305,5.600972895686748,5.54282542695918,6.037426497940624,5.841984804590114,6.173186268412274,5.57287160220048,5.544068044350276,5.550228353055094,5.57978359661681,5.1003705451175625,5.359835482339888,5.977723605288848,5.77706415474243,5.423245873936808,5.600972895686748,5.45484486000851,5.204119982655925,5.812913356642856,5.6674529528899535,5.298853076409706,5.850190875527597,5.555094448578319,6.190331698170292,5.77451696572855,5.517195897949974,5.276461804173244,5.537819095073274,6.060697840353612,5.342422680822207,5.8444771757456815,4.944482672150168,5.5301996982030825,5.638489256954637,5.555094448578319,5.924279286061882,5.8095597146352675,5.469822015978163,5.518513939877887,5.9164539485499255,6.041390711087912,5.7774268223893115,5.550228353055094,5.396199347095736,5.389166084364533,5.517195897949974,5.685741738602264,5.469822015978163,5.845098040014257,5.638489256954637,5.9003671286564705,6.168792020314182,5.359835482339888,5.7596678446896306,5.681241237375588,5.461648568063455,6.077367905284157,5.204119982655925,5.596597095626461,5.413299764081252,5.676693609624866,5.8061799739838875,5.45484486000851,5.778151250383644,5.77451696572855,5.290034611362518,5.568201724066995,5.45484486000851,5.5301996982030825,5.361727836017593,5.770852011642144,5.371067862271736,5.47567118832443,5.5301996982030825,5.723455672035186,5.578639209968072,5.429752280002408,5.991226075692495,5.567026366159061,5.540329474790874,6.254064452914338,5.977723605288848,5.47567118832443,5.891537457672564,5.600972895686748,5.652246341003323,5.414973347970818,5.2027606873932,5.951823035315912,5.389166084364533,5.511883360978874,5.230448921378274,5.173186268412274,5.795880017344075,6.77451696572855,5.653212513775344,5.505149978319906,5.562292864456475,5.720159303405957,5.380030247967831,6.112269768417271,5.3414345245781405,5.928907690243952,5.230448921378274,5.7283537820212285,5.298853076409706,5.45484486000851,5.445604203273597,5.176091259055681,5.7363965022766426,5.740362689494244,5.332438459915605,5.643452676486188,6.174641192660449,5.795184589682424,5.445604203273597,5.596597095626461,6.041392685158225,5.243038048686294,5.396199347095736,6.8750612633917,5.503790683057181,5.561485397401995,5.596597095626461,5.661812685537261,5.568201724066995,5.926856708949693,5.378397900948138,5.380211241711606,5.812913356642856,5.9003671286564705,5.987666264926275,5.278753600952829,5.812913356642856,5.277609214304091,5.445604203273597,5.276461804173244,6.112269768417271,5.9003671286564705,5.600972895686748,5.552668216112194,5.755112266395071,5.8095597146352675,5.429752280002408,5.989004615698537,5.628388930050312,5.511214701136388,5.203848463746235,5.951823035315912,5.396199347095736,5.2027606873932,5.770852011642144,5.173186268412274,5.653212513775344,5.885926339801431,5.748188027006201,5.632457292184724,5.977723605288848,5.413299764081252,5.600972895686748,5.3222192947339195,5.510545010206612,5.301029995663981,5.437750562820388,5.812913356642856,5.47567118832443,5.896526217489555,5.359835482339888,5.8750612633917,5.243038048686294,5.4769764657595275,5.54282542695918,5.217483944213907,5.503790683057181,5.555094448578319,5.469822015978163,5.173186268412274,5.096910013008056,5.694605198933568,5.596597095626461,5.252853030979893,5.469822015978163,5.2552725051033065,6.2552725051033065,5.414973347970818,5.352182518111363,5.460897842756548,5.371067862271736,4.949390006644912,5.894869656745253,5.653212513775344,5.429752280002408,6.105510184769974,5.380211241711606,5.690196080028514,5.720159303405957,5.47639682672533,5.633468455579586,5.694605198933568,5.611723308007342,5.252853030979893,5.739572344450092,5.320146286111054,5.352182518111363,5.8444771757456815,5.690196080028514,6.60151678365001,5.778151250383644,5.7596678446896306,5.911157608739977,5.396199347095736,5.578639209968072,5.648360010980932,5.201397124320452,5.628388930050312,5.578639209968072,5.854306041801081,5.1303337684950066,5.173186268412274,5.531478917042255,5.57978359661681,5.243038048686294,5.389166084364533,6.73996769675951,4.99563519459755,6.146128035678238,5.880813592280791,5.977266212427293,5.352182518111363,5.201397124320452,4.903089986991944,5.628388930050312,5.47567118832443,5.2552725051033065,5.862727528317975,5.298853076409706,5.47567118832443,5.079181246047625,5.676693609624866,5.892094602690481,5.9003671286564705,5.748188027006201,5.894869656745253,5.537819095073274,5.47567118832443,5.267171728403014,5.361727836017593,5.460897842756548,5.5301996982030825,5.301029995663981,5.342422680822207,6.190331698170292,5.685741738602264,5.175801632848279,5.7363965022766426,5.389166084364533,6.6429588794097905,7.041392685158225,5.350248018334163,5.227886704613674,5.484299839346786,5.474216264076255,5.075546961392531,5.874481817699467,5.8061799739838875,5.77451696572855,5.385606273598312,5.567026366159061,5.740362689494244,5.469822015978163,5.298853076409706,5.276461804173244,5.161368002234975,5.6127838567197355,5.652246341003323,5.740362689494244,5.079181246047625,5.204119982655925,5.431202884556517,5.63748972951251,5.518513939877887,5.578639209968072,5.431202884556517,5.970811610872518,5.230193378869045,5.997823080745725,5.652246341003323,5.380211241711606,5.439332693830263,5.110589710299249,5.352182518111363,5.5044708624944185,6.201123897207379,5.278753600952829,5.7596678446896306,5.643452676486188,5.556302500767287,5.585460729508501,5.578639209968072,5.254064452914338,5.547774705387822,5.723455672035186,5.451018452155457,5.47567118832443,5.383815365980431,5.544068044350276,5.173186268412274,5.585460729508501,5.267171728403014,5.938519725176492,5.574031267727719,5.676693609624866,5.829303772831025,5.7923916894982534,5.5910646070264995,5.143014800254095,5.69810054562339,5.601951404133522,5.173186268412274,5.113943352306837,5.537819095073274,5.342422680822207,5.447158031342219,5.874481817699467,5.997823080745725,5.951823035315912,5.585460729508501,4.954242509439325,5.146128035678238,5.505149978319906,5.227886704613674,5.525044807036846,6.138302698166282,5.173186268412274,5.332438459915605,6.079181246047625,5.585460729508501,5.2552725051033065,4.949390006644912,5.217483944213907,5.439332693830263,5.359835482339888,5.267171728403014,5.352182518111363,5.5910646070264995,6.190331698170292,5.3404441148401185,5.57978359661681,5.623249290397901,5.929418925714293,5.770115294787102,5.332438459915605,5.361727836017593,5.469822015978163,5.653212513775344,5.556302500767287,5.544068044350276,5.7363965022766426,5.671172842715083,5.894869656745253,5.252853030979893,6.19728055812562,5.544068044350276,5.230448921378274,5.841984804590114,5.173186268412274,5.45484486000851,5.299942900022767,5.525044807036846,5.997823080745725,5.921686475483602,5.136720567156407,5.300812794118117,5.252853030979893,6.544068044350276,5.439332693830263,5.739572344450092,5.173186268412274,5.350248018334163,5.396199347095736,5.8750612633917,5.6180480967120925,5.260071387985075,5.694605198933568,5.652246341003323,5.642464520242122,5.567026366159061,5.491361693834273,5.841984804590114,5.505149978319906,5.1303337684950066,5.514547752660286,5.951823035315912,6.4734869700645685,5.556302500767287,5.763427993562937,5.57978359661681,5.676693609624866,5.929418925714293,5.1303337684950066,5.6180480967120925,5.489958479424835,5.8444771757456815,5.739572344450092,5.874481817699467,5.724275869600789,5.7596678446896306,5.531478917042255,5.76715586608218,5.531478917042255,5.632457292184724,5.567026366159061,5.549003262025788,5.474216264076255,5.68930885912362,5.720159303405957,5.45484486000851,6.079181246047625,5.265996370495079,5.949390006644912,5.469822015978163,5.812913356642856,5.378397900948138,5.929418925714293,5.096910013008056,6.292256071356476,5.6180480967120925,5.537819095073274,5.204119982655925,5.724275869600789,5.176091259055681,5.555094448578319,6.4623979978989565,5.3979400086720375,5.227886704613674,5.359835482339888,5.720159303405957,5.38738982633873,5.371067862271736,5.556302500767287,5.601951404133522,5.99563519459755,6.171726453653231,5.942008053022313,6.077367905284157,5.642464520242122,5.54282542695918,5.445604203273597,5.431363764158987,5.359835482339888,5.525044807036846,5.723455672035186,4.929418925714293,5.989004615698537,5.332438459915605,5.697229342759718,5.445604203273597,5.505149978319906,5.596597095626461,6.290034611362518,5.380211241711606,5.469822015978163,5.079181246047625,5.517195897949974,5.829303772831025,5.672097857935717,5.628388930050312,5.5301996982030825,5.176091259055681,5.76715586608218,5.217483944213907,5.812913356642856,5.423245873936808,5.676693609624866,5.396199347095736,5.903089986991944,5.585460729508501,5.511883360978874,5.841984804590114,5.378397900948138,6.201397124320452,5.060697840353612,5.423245873936808,6.021189299069938,5.623249290397901,5.1303337684950066,5.218797998111738,5.795880017344075,5.204119982655925,5.720159303405957,5.628388930050312,5.544068044350276,6.105510184769974,5.7774268223893115,5.744292983122676,5.243038048686294,5.3404441148401185,5.763427993562937,5.981818607170664,5.332438459915605,5.298853076409706,5.596597095626461,5.505149978319906,5.755112266395071,5.143014800254095,5.525044807036846,5.585460729508501,6.095169351431755,5.874481817699467,5.562292864456475,5.5301996982030825,5.110589710299249,5.190331698170292,5.54282542695918,5.531478917042255,5.190331698170292,5.298853076409706,5.201397124320452,5.653212513775344,5.600972895686748,5.632457292184724,5.872156272748293,5.562292864456475,6.243038048686294,5.037426497940624,5.47567118832443,5.812913356642856,5.574031267727719,5.642464520242122,5.187520720836463,5.567026366159061,6.439332693830263,5.243038048686294,5.623249290397901,5.77451696572855,5.9003671286564705,6.299942900022767,5.902546779313991,5.648360010980932,6.110589710299249,5.951823035315912,5.396199347095736,5.77451696572855,5.681241237375588,5.217483944213907,5.517195897949974,5.661812685537261,5.5439439424829065,5.361727836017593,6.342422680822207,5.763427993562937,5.738780558484369,5.628388930050312,5.429752280002408,5.977723605288848,5.648360010980932,5.217483944213907,5.517195897949974,5.9003671286564705,5.7363965022766426,5.3404441148401185,5.7160033436347994,5.3414345245781405,5.505149978319906,5.662757831681574,5.838219221907626,5.227886704613674,5.694605198933568,5.565696733446075,5.54282542695918,5.267171728403014,5.671172842715083,5.385606273598312,4.99563519459755,5.474216264076255,5.224014811372864,4.897627091290442,5.623249290397901,5.426511261364575,5.724275869600789,5.937016107464814,5.596597095626461,5.252853030979893,5.525044807036846,5.556302500767287,5.298853076409706,5.937016107464814,5.301029995663981,5.423245873936808,5.643452676486188,5.396199347095736,6.883661435153617,5.439332693830263,6.039414119176137,6.217483944213907,5.99563519459755,5.642464520242122,5.970811610872518,5.776701183988411,5.460897842756548,5.4623979978989565,5.672097857935717,6.144574207609616,5.589949601325708,5.600972895686748,5.578639209968072,5.537819095073274,6.73996769675951,5.596597095626461,5.874481817699467,5.190331698170292,5.060697840353612,5.3404441148401185,5.841984804590114,5.511883360978874,5.47567118832443,6.230448921378274,5.423245873936808,5.276461804173244,5.3979400086720375,5.176091259055681,5.555094448578319,5.278753600952829,5.7923916894982534,5.989004615698537,5.911157608739977,6.414137362184476,5.544068044350276,5.556302500767287,5.831229693867063,5.537819095073274,5.648360010980932,5.574031267727719,5.143014800254095,5.812244696800369,5.638489256954637,5.515873843711679,5.720159303405957,6.439332693830263,5.544068044350276,4.949390006644912,5.122215878272827,6.217483944213907,5.731588765186738,5.57978359661681,5.230448921378274,5.254064452914338,5.396199347095736,5.942008053022313,5.720159303405957,5.173186268412274,5.739572344450092,5.396199347095736,5.469822015978163,5.544068044350276,5.562292864456475,5.389166084364533,5.510545010206612,5.770115294787102,5.511883360978874,5.841984804590114,5.217483944213907,5.190331698170292,5.173186268412274,5.503790683057181,5.648360010980932,5.600972895686748,5.243038048686294,5.110589710299249,5.596597095626461,5.951823035315912,5.53135116458306,5.951823035315912,5.928907690243952,5.378397900948138,5.8095597146352675,5.460897842756548,5.872156272748293,5.8095597146352675,5.190331698170292,5.217483944213907,5.346352974450639,5.685741738602264,5.974050902792877,6.146128035678238,5.143014800254095,5.740362689494244,5.628388930050312,6.146128035678238,5.681241237375588,5.371067862271736,5.989004615698537,5.559308010907013,5.176091259055681,5.7363965022766426,5.54282542695918,5.596597095626461,5.537819095073274,5.1303337684950066,5.599883072073688,5.380211241711606,5.590507462008583,5.217483944213907,5.474216264076255,5.652246341003323,5.413299764081252,6.469822015978163,5.56643749219507,5.47567118832443,6.174641192660449,5.278753600952829,5.841984804590114,5.396199347095736,5.628388930050312,5.243038048686294,5.2552725051033065,5.720159303405957,6.021189299069938,5.8512583487190755,5.795880017344075,5.739572344450092,5.799340549453582,5.204119982655925,5.652246341003323,5.47567118832443,5.648360010980932,5.243038048686294,5.748188027006201,5.352182518111363,5.707570176097937,5.190331698170292,5.875032309461098,5.2552725051033065,5.567026366159061,5.361727836017593,5.829303772831025,5.99563519459755,5.230448921378274,5.267171728403014,5.414973347970818,5.715167357848458,5.929418925714293,5.252853030979893,5.567026366159061,5.47567118832443,5.505149978319906,5.77451696572855,5.9003671286564705,5.681241237375588,5.929418925714293,5.439332693830263,5.544068044350276,5.874481817699467,5.643452676486188,5.3404441148401185,5.371067862271736,5.638489256954637,5.352182518111363,5.517195897949974,5.740362689494244,5.491361693834273,5.739572344450092,5.841984804590114,5.525044807036846,5.6674529528899535,5.720159303405957,5.217483944213907,5.230448921378274,5.556302500767287,5.5532760461371,5.69888313675259,5.697229342759718,5.47567118832443,6.144574207609616,5.997823080745725,5.929418925714293,5.653212513775344,5.379305517750582,5.653212513775344,5.468716471515473,5.633468455579586,5.951823035315912,5.477121254719663,5.267171728403014,5.60151678365001,5.556302500767287,5.690196080028514,5.748188027006201,5.739572344450092,5.113943352306837,5.841984804590114,5.740362689494244,5.690196080028514,6.071882007306125,5.54282542695918,6.589949601325708,5.928907690243952,6.447158031342219]
},
"mapping":{
"x":"cadastral_income",
"y":"living_area",
"fill":"price",
"size":"price"
},
"data_meta":{
"series_annotations":[{
"type":"float",
"column":"bedrooms"
},{
"type":"str",
"column":"state"
},{
"type":"str",
"column":"kitchen_type"
},{
"type":"float",
"column":"number_of_frontages"
},{
"type":"float",
"column":"toilets"
},{
"type":"str",
"column":"street"
},{
"type":"float",
"column":"lng"
},{
"type":"float",
"column":"primary_energy_consumption"
},{
"type":"float",
"column":"bathrooms"
},{
"type":"float",
"column":"yearly_theoretical_total_energy_consumption"
},{
"type":"float",
"column":"surface_of_the_plot"
},{
"type":"str",
"column":"building_condition"
},{
"type":"str",
"column":"city"
},{
"type":"float",
"column":"lat"
},{
"type":"float",
"column":"cadastral_income"
},{
"type":"float",
"column":"living_area"
},{
"type":"float",
"column":"price"
}]
},
"ggtitle":{
"text":"Assessing Potential Outliers",
"subtitle":" Outliers pose a challenge for gradient boosting methods since boosting constructs each tree based on the errors of the previous trees. \n        Outliers, having significantly larger errors than non-outliers, can excessively divert the model's attention toward these data points.\n            "
},
"guides":{
"x":{
"title":"Cadastral income (EUR)"
},
"y":{
"title":"Living area (m2)"
}
},
"theme":{
"plot_title":{
"face":"bold",
"size":15.0,
"blank":false
},
"plot_subtitle":{
"face":"italic",
"size":12.0,
"blank":false
}
},
"ggsize":{
"width":800.0,
"height":600.0
},
"kind":"plot",
"scales":[{
"aesthetic":"fill",
"scale_mapper_kind":"color_gradient",
"low":"#1a9641",
"high":"#d7191c"
}],
"layers":[{
"geom":"point",
"mapping":{
},
"show_legend":false,
"data_meta":{
},
"alpha":0.5,
"shape":21.0,
"stroke":0.5,
"data":{
}
}],
"metainfo_list":[],
"spec_id":"1"
};
               window.letsPlotCall(function() {
       
               var toolbar = null;
               var plotContainer = containerDiv;               
               
                   var options = {
                       sizing: {
                           width_mode: "min",
                           height_mode: "scaled",
                           width: width
                       }
                   };
                   var fig = LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer, options);
                   if (toolbar) {
                     toolbar.bind(fig);
                   }
               });
               
               break;
           }
       }
   });
   
   observer.observe(containerDiv);
   
   // ----------
   })();
   
   </script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fig1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Assessing Feature Cardinality: Percentage of Unique Values per Feature
</figcaption>
</figure>
</div>
</div>
<p>For identifying potential outliers within our data, we can employ <code>Scikit-learn</code>’s <code>LocalOutlierFactor</code>. This algorithm, known as the Local Outlier Factor (LOF), is an unsupervised technique for anomaly detection. It assesses the local density deviation of a data point relative to its neighboring points. LOF identifies outliers as those data points demonstrating notably lower density in comparison to their neighbors.</p>
<p>In the provided code, we’ve created a function called <code>identify_outliers</code>. This function generates a mask that we can use to filter out data points potentially flagged as outliers.</p>
<div id="534508f1-c5ce-4abc-a773-ca2026379705" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> identify_outliers(df: pd.DataFrame) <span class="op">-&gt;</span> pd.Series:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Identify outliers in a DataFrame.</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function uses a Local Outlier Factor (LOF) algorithm to identify outliers in a given</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame. It operates on both numerical and categorical features, and it returns a binary</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Series where `True` represents an outlier and `False` represents a non-outlier.</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - df (pd.DataFrame): The input DataFrame containing features for outlier identification.</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - pd.Series: A Boolean Series indicating outliers (True) and non-outliers (False).</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your DataFrame with features (df)</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">    df = load_data()</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">    # Identify outliers using the function</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">    outlier_mask = identify_outliers(df)</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co">    # Use the outlier mask to filter your DataFrame</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">    filtered_df = df[~outlier_mask]  # Keep non-outliers</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">    Notes:</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co">    - The function uses Local Outlier Factor (LOF) with default parameters for identifying outliers.</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="co">    - Numerical features are imputed using median values, and categorical features are one-hot encoded</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co">      and imputed with median values.</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="co">    - The resulting Boolean Series is `True` for outliers and `False` for non-outliers.</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract numerical and categorical feature names</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    NUMERICAL_FEATURES <span class="op">=</span> df.select_dtypes(<span class="st">"number"</span>).columns.tolist()</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    CATEGORICAL_FEATURES <span class="op">=</span> df.select_dtypes(<span class="st">"object"</span>).columns.tolist()</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define transformers for preprocessing</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    numeric_transformer <span class="op">=</span> pipeline.Pipeline(</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        steps<span class="op">=</span>[(<span class="st">"imputer"</span>, impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"median"</span>))]</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    categorical_transformer <span class="op">=</span> pipeline.Pipeline(</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        steps<span class="op">=</span>[</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"encoder"</span>, preprocessing.OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">"ignore"</span>)),</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"imputer"</span>, impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"median"</span>)),</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a ColumnTransformer to handle both numerical and categorical features</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>    preprocessor <span class="op">=</span> compose.ColumnTransformer(</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>        transformers<span class="op">=</span>[</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"num"</span>, numeric_transformer, NUMERICAL_FEATURES),</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"cat"</span>, categorical_transformer, CATEGORICAL_FEATURES),</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the LocalOutlierFactor model</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> neighbors.LocalOutlierFactor()</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit LOF to preprocessed data and make predictions</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.fit_predict(preprocessor.fit_transform(df))</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust LOF predictions to create a binary outlier mask</span></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>    y_pred_adjusted <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> x <span class="kw">in</span> y_pred]</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>    outlier_mask <span class="op">=</span> pd.Series(y_pred_adjusted) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> outlier_mask</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As a comparison, here’s the scatter plot after removing outliers. It appears that the LocalOutlierFactor method was effective in addressing the outlier data points.</p>
<div id="0aa55936-a3e4-4651-b445-176136506d11" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>outlier_mask <span class="op">=</span> pre_process.identify_outliers(X)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>X_wo_outliers <span class="op">=</span> X.loc[outlier_mask, :].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>y_wo_outliers <span class="op">=</span> y.loc[outlier_mask].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    pd.concat([X_wo_outliers, y_wo_outliers], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># .loc[lambda df: pre_process.identify_outliers(df.loc[:, :"living_area"])]</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    .pipe(</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span> df: ggplot(</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>            df, aes(<span class="st">"cadastral_income"</span>, <span class="st">"living_area"</span>, fill<span class="op">=</span><span class="st">"price"</span>, size<span class="op">=</span><span class="st">"price"</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> geom_point(alpha<span class="op">=</span><span class="fl">0.5</span>, shape<span class="op">=</span><span class="dv">21</span>, stroke<span class="op">=</span><span class="fl">0.5</span>, show_legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> scale_fill_continuous(low<span class="op">=</span><span class="st">"#1a9641"</span>, high<span class="op">=</span><span class="st">"#d7191c"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> labs(</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>            title<span class="op">=</span><span class="st">"Assessing Potential Outliers"</span>,</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>            subtitle<span class="op">=</span><span class="st">""" By employing the default parameters of LocalOutlierFactor, we've reduced our training set from 3660 instances to 3427.</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="st">            This is expected to enhance our model's performance and its ability to generalize well to new data.</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="st">            """</span>,</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>            x<span class="op">=</span><span class="st">"Cadastral income (EUR)"</span>,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>            y<span class="op">=</span><span class="st">"Living area (m2)"</span>,</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> theme(</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>            plot_subtitle<span class="op">=</span>element_text(</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">12</span>, face<span class="op">=</span><span class="st">"italic"</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            ),  <span class="co"># Customize subtitle appearance</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>            plot_title<span class="op">=</span>element_text(size<span class="op">=</span><span class="dv">15</span>, face<span class="op">=</span><span class="st">"bold"</span>),  <span class="co"># Customize title appearance</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> ggsize(<span class="dv">800</span>, <span class="dv">600</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="10">
   <div id="Ds11CA"></div>
   <script type="text/javascript" data-lets-plot-script="plot">
   
   (function() {
   // ----------
   
   var containerDiv = document.getElementById("Ds11CA");
   var observer = new ResizeObserver(function(entries) {
       for (let entry of entries) {
           var width = containerDiv.clientWidth
           if (entry.contentBoxSize && width > 0) {
           
               // Render plot
               if (observer) {
                   observer.disconnect();
                   observer = null;
               }

               var plotSpec={
"data":{
"cadastral_income":[565.0,3544.0,1725.0,966.0,1690.0,2102.0,2382.0,577.0,3661.0,1221.0,409.0,396.0,null,1036.0,560.0,null,552.0,503.0,671.0,null,485.0,1251.0,594.0,null,329.0,867.0,373.0,null,4318.0,null,964.0,342.0,null,2150.0,null,3973.0,null,1095.0,523.0,768.0,1891.0,null,632.0,580.0,1857.0,262.0,null,275.0,null,743.0,677.0,2875.0,null,863.0,1378.0,384.0,1155.0,null,1383.0,null,1417.0,1232.0,917.0,1068.0,359.0,393.0,537.0,1670.0,545.0,720.0,2530.0,257.0,733.0,1641.0,991.0,446.0,4568.0,528.0,1289.0,4619.0,1265.0,1960.0,2170.0,1831.0,906.0,null,399.0,1460.0,1368.0,null,1442.0,null,594.0,743.0,null,null,1243.0,4191.0,994.0,1088.0,505.0,454.0,1077.0,3408.0,1100.0,1048.0,null,1152.0,875.0,1462.0,null,940.0,745.0,1351.0,359.0,null,4972.0,null,745.0,748.0,null,1730.0,260.0,297.0,4241.0,null,1115.0,null,314.0,null,178.0,417.0,null,2159.0,567.0,669.0,1078.0,1203.0,4102.0,384.0,400.0,364.0,1668.0,3205.0,451.0,1911.0,8205.0,354.0,825.0,1579.0,705.0,null,1384.0,748.0,3569.0,844.0,1489.0,411.0,null,null,5662.0,null,null,478.0,null,2243.0,1725.0,1641.0,1867.0,384.0,332.0,1921.0,1705.0,1221.0,2010.0,704.0,9073.0,941.0,644.0,909.0,307.0,456.0,428.0,968.0,2031.0,null,843.0,1829.0,356.0,10299.0,470.0,537.0,null,null,1534.0,386.0,3329.0,924.0,null,null,956.0,2452.0,null,411.0,453.0,300.0,468.0,842.0,3535.0,null,2426.0,736.0,485.0,null,475.0,708.0,421.0,498.0,1057.0,666.0,3658.0,733.0,1075.0,324.0,1077.0,1336.0,null,627.0,446.0,1448.0,null,369.0,399.0,427.0,835.0,803.0,2425.0,null,2602.0,959.0,1410.0,3354.0,1314.0,null,479.0,2667.0,9258.0,584.0,964.0,5764.0,2357.0,null,555.0,461.0,1472.0,456.0,1570.0,672.0,null,2969.0,1462.0,371.0,703.0,413.0,389.0,3235.0,null,413.0,1137.0,null,1051.0,null,711.0,798.0,979.0,357.0,356.0,null,889.0,745.0,401.0,480.0,null,1043.0,1095.0,1098.0,577.0,1169.0,795.0,580.0,2511.0,537.0,null,970.0,745.0,2381.0,8934.0,1487.0,391.0,null,3057.0,661.0,456.0,1368.0,774.0,3758.0,3479.0,964.0,2037.0,794.0,694.0,354.0,11514.0,1707.0,null,1095.0,1115.0,337.0,1177.0,747.0,null,797.0,193.0,808.0,641.0,4348.0,619.0,607.0,7615.0,1229.0,245.0,null,166.0,1031.0,1797.0,1105.0,396.0,738.0,1643.0,985.0,null,946.0,886.0,485.0,262.0,2664.0,null,null,369.0,2362.0,null,null,934.0,423.0,818.0,324.0,2388.0,1497.0,null,493.0,310.0,439.0,533.0,3755.0,440.0,null,2027.0,2397.0,745.0,2018.0,1233.0,468.0,672.0,1083.0,951.0,null,1.0,1170.0,null,637.0,609.0,661.0,701.0,1707.0,533.0,934.0,2766.0,1400.0,null,null,978.0,1032.0,594.0,null,2474.0,1177.0,426.0,1155.0,1220.0,513.0,661.0,1205.0,null,null,1.0,646.0,null,991.0,594.0,2816.0,594.0,426.0,1234.0,385.0,752.0,1447.0,null,null,3512.0,3656.0,946.0,319.0,3378.0,null,369.0,1013.0,null,null,4930.0,934.0,1125.0,255.0,977.0,null,1683.0,436.0,9226.0,1373.0,911.0,3277.0,726.0,null,2164.0,790.0,null,654.0,1098.0,null,null,7454.0,141.0,1928.0,1400.0,2000.0,446.0,409.0,1333.0,726.0,null,1536.0,904.0,2540.0,1928.0,1229.0,131.0,659.0,2789.0,572.0,751.0,929.0,904.0,1643.0,1260.0,354.0,null,780.0,null,null,1563.0,null,860.0,756.0,null,1719.0,1621.0,1207.0,422.0,1499.0,1626.0,867.0,null,null,1507.0,2678.0,null,null,661.0,null,280.0,null,2493.0,2895.0,532.0,411.0,1127.0,null,726.0,7545.0,428.0,230.0,624.0,null,257.0,557.0,null,null,1665.0,510.0,684.0,950.0,892.0,989.0,2897.0,286.0,1932.0,426.0,884.0,428.0,2223.0,887.0,951.0,1065.0,2654.0,null,1483.0,1070.0,2927.0,1999.0,1134.0,906.0,743.0,483.0,1112.0,637.0,609.0,421.0,3772.0,595.0,757.0,1876.0,460.0,null,748.0,1593.0,4459.0,311.0,1666.0,3341.0,5141.0,379.0,562.0,2412.0,1585.0,964.0,null,887.0,1083.0,381.0,1930.0,991.0,1395.0,null,590.0,453.0,1249.0,1253.0,null,1305.0,null,976.0,null,null,1722.0,null,520.0,2253.0,null,488.0,null,1075.0,null,null,2744.0,294.0,240.0,562.0,1054.0,376.0,null,587.0,830.0,829.0,null,null,2723.0,null,null,960.0,1137.0,null,347.0,null,748.0,null,299.0,435.0,null,7969.0,null,404.0,307.0,1172.0,389.0,1269.0,741.0,1651.0,444.0,null,438.0,650.0,null,1000.0,594.0,null,2379.0,413.0,1411.0,711.0,1075.0,704.0,716.0,1712.0,1212.0,857.0,1498.0,262.0,2436.0,374.0,1274.0,1224.0,1353.0,null,971.0,1184.0,483.0,2518.0,3368.0,null,713.0,188.0,643.0,null,518.0,1318.0,941.0,344.0,431.0,685.0,545.0,167.0,1729.0,389.0,null,null,null,5902.0,654.0,null,1108.0,null,null,560.0,681.0,1219.0,null,775.0,743.0,356.0,723.0,4154.0,null,5433.0,null,230.0,1368.0,1732.0,null,null,null,null,356.0,379.0,3423.0,833.0,null,1491.0,2305.0,1029.0,334.0,285.0,505.0,844.0,null,null,775.0,1079.0,302.0,309.0,1368.0,644.0,1125.0,327.0,733.0,857.0,761.0,713.0,428.0,810.0,723.0,null,989.0,null,647.0,699.0,832.0,null,1139.0,null,1308.0,334.0,334.0,178.0,381.0,null,490.0,null,203.0,409.0,null,450.0,null,438.0,2200.0,609.0,null,1192.0,1017.0,649.0,3344.0,949.0,391.0,654.0,914.0,1525.0,null,141.0,null,652.0,356.0,741.0,505.0,955.0,414.0,2258.0,null,927.0,928.0,null,647.0,4395.0,1519.0,594.0,1179.0,null,681.0,6219.0,773.0,null,1740.0,4438.0,null,null,1556.0,4923.0,2161.0,745.0,null,1336.0,null,2699.0,827.0,855.0,546.0,1170.0,1623.0,1588.0,328.0,441.0,155.0,483.0,375.0,550.0,null,594.0,391.0,602.0,250.0,1555.0,941.0,483.0,327.0,1467.0,299.0,null,null,1771.0,1.0,627.0,411.0,null,535.0,484.0,416.0,1.0,912.0,1308.0,1447.0,627.0,1274.0,696.0,1351.0,1953.0,null,1231.0,2278.0,528.0,null,874.0,3353.0,1243.0,891.0,427.0,null,null,1477.0,994.0,3487.0,352.0,689.0,null,null,1330.0,null,748.0,450.0,null,527.0,329.0,null,993.0,null,1382.0,270.0,404.0,1767.0,null,188.0,540.0,485.0,480.0,399.0,1219.0,203.0,1279.0,null,null,1740.0,3249.0,null,1318.0,null,756.0,490.0,null,null,null,null,1200.0,993.0,null,1370.0,892.0,241.0,763.0,731.0,720.0,null,1395.0,792.0,1901.0,708.0,540.0,661.0,599.0,1083.0,null,408.0,null,null,359.0,438.0,2098.0,null,302.0,null,1328.0,404.0,null,4632.0,1866.0,3455.0,582.0,1100.0,736.0,567.0,2968.0,1333.0,615.0,null,1121.0,null,616.0,null,1080.0,713.0,699.0,733.0,null,604.0,null,3155.0,null,null,1333.0,1090.0,1861.0,2404.0,1202.0,423.0,642.0,1103.0,381.0,null,1416.0,null,1277.0,1653.0,1492.0,446.0,495.0,550.0,729.0,451.0,850.0,null,233.0,1984.0,null,null,552.0,null,null,null,307.0,1250.0,null,null,null,525.0,1229.0,235.0,null,1402.0,null,1058.0,924.0,null,354.0,706.0,575.0,283.0,1734.0,743.0,805.0,1300.0,null,null,354.0,272.0,721.0,218.0,470.0,1590.0,1227.0,451.0,1651.0,446.0,846.0,745.0,190.0,null,540.0,267.0,null,519.0,1162.0,500.0,null,1026.0,895.0,639.0,null,3339.0,609.0,770.0,761.0,null,null,314.0,1260.0,4437.0,541.0,302.0,1683.0,1417.0,1232.0,619.0,674.0,null,3480.0,1313.0,2344.0,898.0,2031.0,4135.0,null,1249.0,676.0,1147.0,572.0,334.0,451.0,3650.0,1244.0,null,6145.0,null,288.0,5000.0,485.0,302.0,1891.0,1051.0,560.0,428.0,null,null,723.0,580.0,1849.0,691.0,218.0,470.0,701.0,850.0,282.0,1298.0,null,280.0,null,800.0,1830.0,1150.0,null,1463.0,991.0,689.0,751.0,446.0,null,252.0,null,1387.0,1028.0,8205.0,979.0,2313.0,null,null,666.0,255.0,1898.0,null,3472.0,1077.0,409.0,null,3356.0,2881.0,865.0,null,null,575.0,null,850.0,736.0,822.0,223.0,654.0,1224.0,793.0,null,478.0,848.0,2203.0,294.0,711.0,1532.0,1742.0,1238.0,5966.0,null,null,566.0,4640.0,2811.0,1249.0,1782.0,null,270.0,726.0,1202.0,860.0,2012.0,1317.0,775.0,null,1510.0,861.0,601.0,678.0,null,null,null,1740.0,602.0,669.0,1308.0,681.0,1115.0,null,null,null,15311.0,null,1435.0,null,399.0,2583.0,null,285.0,861.0,669.0,2029.0,418.0,609.0,1325.0,null,null,865.0,743.0,912.0,346.0,6336.0,null,644.0,null,null,null,null,1197.0,510.0,1078.0,1197.0,745.0,651.0,1534.0,277.0,2072.0,null,1641.0,984.0,1177.0,623.0,342.0,null,937.0,624.0,1115.0,761.0,1028.0,859.0,740.0,939.0,867.0,255.0,null,562.0,488.0,272.0,438.0,200.0,733.0,1070.0,832.0,null,1.0,671.0,null,458.0,1083.0,1060.0,924.0,7578.0,520.0,null,1095.0,null,null,716.0,841.0,369.0,null,542.0,404.0,1016.0,2623.0,813.0,2223.0,2402.0,523.0,null,3200.0,1839.0,1546.0,2773.0,495.0,null,2580.0,2949.0,1363.0,null,null,1665.0,4151.0,1936.0,444.0,666.0,null,1526.0,null,1889.0,748.0,299.0,1001.0,461.0,1078.0,1683.0,null,1132.0,319.0,450.0,505.0,null,729.0,356.0,624.0,4638.0,322.0,null,917.0,null,922.0,null,644.0,1859.0,592.0,302.0,null,535.0,339.0,592.0,436.0,847.0,297.0,448.0,7578.0,7858.0,1629.0,null,711.0,418.0,513.0,1021.0,612.0,332.0,681.0,3021.0,651.0,1251.0,null,461.0,10440.0,null,809.0,2230.0,1888.0,334.0,344.0,374.0,null,438.0,416.0,null,1395.0,null,7636.0,334.0,null,825.0,4449.0,712.0,1200.0,null,1078.0,null,446.0,null,null,371.0,1606.0,1108.0,577.0,1648.0,483.0,null,1105.0,964.0,1569.0,680.0,376.0,null,1984.0,2648.0,null,null,637.0,1140.0,2154.0,601.0,2430.0,1179.0,2558.0,3155.0,1494.0,1424.0,547.0,401.0,null,411.0,3055.0,701.0,274.0,null,null,null,899.0,1065.0,null,null,1068.0,540.0,974.0,745.0,1372.0,488.0,1234.0,3024.0,503.0,866.0,837.0,1023.0,203.0,5583.0,null,null,252.0,1135.0,null,889.0,748.0,2459.0,null,410.0,834.0,607.0,285.0,4375.0,799.0,2952.0,498.0,null,347.0,559.0,null,936.0,342.0,null,null,null,622.0,520.0,1650.0,1417.0,671.0,1614.0,260.0,713.0,424.0,null,718.0,1432.0,535.0,1306.0,359.0,3896.0,1740.0,632.0,897.0,594.0,null,951.0,2508.0,748.0,1705.0,2368.0,2699.0,485.0,null,null,3805.0,null,768.0,421.0,1649.0,1908.0,1448.0,null,null,null,null,937.0,null,1280.0,3145.0,704.0,324.0,1417.0,421.0,1489.0,759.0,907.0,651.0,523.0,1274.0,1859.0,676.0,1008.0,null,369.0,null,null,929.0,1001.0,4105.0,827.0,927.0,726.0,2181.0,null,1463.0,null,null,310.0,409.0,374.0,1365.0,832.0,1266.0,741.0,null,743.0,null,1720.0,1876.0,1021.0,743.0,2658.0,1125.0,1003.0,696.0,null,337.0,768.0,857.0,550.0,2451.0,418.0,null,930.0,null,503.0,2791.0,531.0,2691.0,347.0,null,996.0,713.0,824.0,1730.0,190.0,255.0,1083.0,3477.0,892.0,317.0,null,null,679.0,314.0,null,2092.0,812.0,480.0,228.0,1008.0,642.0,null,null,949.0,null,2104.0,746.0,null,955.0,374.0,1973.0,null,1070.0,753.0,1467.0,null,949.0,676.0,743.0,696.0,null,1298.0,847.0,null,1063.0,342.0,3368.0,560.0,null,null,null,366.0,1.0,null,416.0,1981.0,489.0,6216.0,null,493.0,463.0,870.0,374.0,640.0,793.0,null,535.0,520.0,552.0,713.0,353.0,270.0,1131.0,null,384.0,2678.0,2643.0,3118.0,2850.0,624.0,1303.0,314.0,572.0,3542.0,1065.0,1218.0,2607.0,1169.0,490.0,1408.0,352.0,518.0,1983.0,null,669.0,null,3455.0,534.0,669.0,926.0,null,null,null,3339.0,9792.0,null,860.0,360.0,649.0,null,413.0,1140.0,2557.0,2669.0,1063.0,361.0,3785.0,1117.0,2552.0,1157.0,941.0,1202.0,1209.0,6392.0,null,778.0,225.0,null,null,545.0,513.0,2751.0,null,3222.0,683.0,725.0,530.0,726.0,null,2343.0,719.0,210.0,1093.0,1031.0,2678.0,604.0,209.0,2020.0,699.0,927.0,5379.0,1249.0,980.0,null,257.0,null,1083.0,309.0,365.0,867.0,691.0,1088.0,384.0,242.0,394.0,null,290.0,1137.0,null,242.0,1757.0,null,808.0,950.0,503.0,705.0,1110.0,3337.0,302.0,3570.0,null,3579.0,null,560.0,7578.0,7662.0,520.0,482.0,1405.0,1041.0,null,1649.0,1043.0,698.0,1606.0,701.0,null,1221.0,null,2156.0,980.0,null,654.0,2508.0,1742.0,736.0,535.0,364.0,859.0,565.0,555.0,1147.0,null,1065.0,1236.0,null,null,2216.0,3200.0,1135.0,718.0,461.0,1224.0,null,null,2545.0,null,1341.0,485.0,985.0,2530.0,267.0,718.0,1272.0,850.0,null,1236.0,1550.0,2451.0,null,475.0,262.0,297.0,539.0,null,1348.0,431.0,null,null,null,483.0,743.0,674.0,3106.0,null,523.0,4819.0,716.0,4045.0,3000.0,3428.0,null,1150.0,808.0,null,1214.0,1601.0,280.0,277.0,391.0,870.0,6794.0,803.0,535.0,337.0,473.0,null,null,null,664.0,null,428.0,562.0,398.0,550.0,null,1090.0,1722.0,287.0,866.0,1681.0,403.0,916.0,1878.0,760.0,1725.0,1370.0,401.0,1298.0,null,359.0,1085.0,1068.0,2456.0,524.0,694.0,892.0,663.0,1928.0,651.0,672.0,902.0,1040.0,463.0,447.0,312.0,null,null,null,1631.0,974.0,743.0,6639.0,2568.0,592.0,1070.0,810.0,2969.0,366.0,436.0,745.0,3242.0,1325.0,1752.0,1140.0,null,595.0,1211.0,1166.0,null,609.0,2667.0,null,1085.0,null,892.0,946.0,1165.0,null,436.0,1331.0,1564.0,292.0,431.0,658.0,448.0,1387.0,550.0,302.0,400.0,1025.0,339.0,1078.0,null,525.0,810.0,1600.0,431.0,463.0,null,3184.0,284.0,69.0,639.0,null,683.0,null,null,1864.0,499.0,null,416.0,1527.0,620.0,964.0,1199.0,956.0,1720.0,1103.0,null,1088.0,null,485.0,542.0,889.0,686.0,691.0,2345.0,619.0,null,null,null,674.0,447.0,1338.0,1275.0,831.0,689.0,473.0,844.0,416.0,2300.0,411.0,null,1246.0,389.0,569.0,815.0,null,728.0,null,null,null,685.0,null,440.0,null,1070.0,2927.0,436.0,404.0,476.0,1990.0,412.0,null,912.0,1083.0,290.0,334.0,1563.0,371.0,498.0,null,964.0,485.0,null,2942.0,null,956.0,609.0,null,null,2052.0,421.0,871.0,1175.0,651.0,223.0,654.0,2863.0,null,3344.0,488.0,null,1070.0,null,208.0,null,4614.0,418.0,464.0,null,490.0,791.0,1011.0,669.0,1365.0,922.0,864.0,null,1051.0,359.0,947.0,327.0,426.0,1075.0,444.0,null,null,654.0,null,5069.0,4700.0,813.0,null,282.0,6556.0,652.0,1336.0,778.0,1148.0,932.0,2949.0,null,241.0,845.0,700.0,513.0,270.0,663.0,null,550.0,6145.0,1385.0,1115.0,720.0,537.0,349.0,1412.0,426.0,730.0,705.0,2107.0,3544.0,423.0,1831.0,520.0,970.0,2263.0,null,500.0,510.0,567.0,294.0,1492.0,714.0,1313.0,null,710.0,null,null,976.0,978.0,399.0,null,null,396.0,1078.0,1947.0,925.0,270.0,5111.0,518.0,332.0,536.0,540.0,1241.0,418.0,726.0,null,2397.0,null,null,null,602.0,null,356.0,null,null,868.0,null,971.0,669.0,1046.0,825.0,null,null,451.0,null,324.0,null,745.0,607.0,588.0,301.0,587.0,2374.0,2317.0,1073.0,1953.0,null,1556.0,757.0,521.0,981.0,814.0,null,1955.0,null,270.0,1653.0,null,607.0,735.0,6755.0,1053.0,1189.0,391.0,1085.0,249.0,604.0,684.0,3170.0,null,null,937.0,892.0,1182.0,686.0,1874.0,332.0,198.0,860.0,478.0,877.0,666.0,1140.0,1300.0,528.0,260.0,338.0,475.0,1279.0,null,1100.0,369.0,1359.0,409.0,892.0,null,745.0,741.0,223.0,483.0,1725.0,null,null,469.0,null,1088.0,299.0,996.0,null,null,4141.0,592.0,743.0,null,5666.0,null,1529.0,572.0,null,3631.0,745.0,892.0,421.0,356.0,1103.0,280.0,1243.0,1833.0,5550.0,887.0,349.0,996.0,272.0,495.0,1303.0,421.0,895.0,null,null,null,253.0,1207.0,1.0,null,1236.0,3857.0,1327.0,1083.0,585.0,401.0,8390.0,4328.0,null,null,1390.0,null,2654.0,1584.0,855.0,1020.0,540.0,1003.0,327.0,2314.0,832.0,1140.0,6279.0,null,1135.0,832.0,485.0,1621.0,453.0,null,5589.0,557.0,null,902.0,510.0,1145.0,669.0,null,891.0,810.0,1017.0,528.0,2010.0,1479.0,1358.0,319.0,619.0,null,299.0,1232.0,1088.0,1479.0,2027.0,466.0,743.0,null,1217.0,785.0,964.0,null,726.0,null,1558.0,946.0,532.0,null,1105.0,null,4459.0,null,267.0,563.0,745.0,2424.0,3106.0,505.0,985.0,2027.0,569.0,656.0,2392.0,329.0,1200.0,334.0,1534.0,2667.0,671.0,null,1645.0,920.0,497.0,1125.0,585.0,null,1873.0,1313.0,1033.0,592.0,1636.0,349.0,1532.0,null,373.0,917.0,1321.0,1558.0,404.0,780.0,2992.0,2668.0,855.0,369.0,327.0,857.0,null,1070.0,1194.0,318.0,618.0,null,672.0,3371.0,null,384.0,500.0,null,null,1579.0,null,1859.0,5862.0,1747.0,2813.0,592.0,null,null,944.0,null,537.0,null,1.0,220.0,null,2092.0,490.0,null,1036.0,1626.0,1623.0,277.0,null,null,null,null,1048.0,1966.0,547.0,null,946.0,609.0,5210.0,687.0,728.0,null,597.0,656.0,1616.0,1147.0,592.0,null,null,null,1850.0,null,1256.0,7662.0,770.0,1437.0,1103.0,850.0,1179.0,795.0,733.0,null,530.0,178.0,684.0,310.0,485.0,null,1135.0,907.0,2002.0,1436.0,508.0,626.0,989.0,428.0,1197.0,312.0,null,461.0,null,1782.0,null,267.0,575.0,null,743.0,394.0,null,null,1013.0,null,null,857.0,null,1083.0,2568.0,1147.0,null,1116.0,4962.0,1023.0,213.0,825.0,438.0,1525.0,null,976.0,585.0,803.0,null,423.0,null,1.0,1641.0,448.0,null,708.0,null,1794.0,null,null,1638.0,null,1068.0,3480.0,2528.0,1314.0,560.0,651.0,676.0,572.0,706.0,null,1289.0,2053.0,603.0,2426.0,null,1001.0,2379.0,704.0,991.0,1754.0,2493.0,2537.0,null,608.0,1290.0,1023.0,null,null,null,1162.0,1460.0,2368.0,369.0,1510.0,1422.0,697.0,721.0,1115.0,872.0,3948.0,313.0,505.0,null,233.0,998.0,773.0,983.0,null,1207.0,478.0,994.0,713.0,453.0,null,2247.0,830.0,1477.0,null,1611.0,449.0,794.0,null,1566.0,884.0,893.0,1368.0,null,1839.0,1239.0,1690.0,null,1162.0,null,699.0,1274.0,2679.0,2568.0,1016.0,547.0,780.0,738.0,null,376.0,null,347.0,null,null,1463.0,null,228.0,694.0,547.0,746.0,374.0,1950.0,null,null,null,505.0,null,894.0,1.0,500.0,2002.0,1115.0,650.0,2010.0,532.0,272.0,null,327.0,null,426.0,2653.0,1762.0,1105.0,376.0,594.0,1591.0,1115.0,299.0,null,null,1807.0,298.0,null,433.0,769.0,2233.0,761.0,null,6315.0,666.0,218.0,null,1301.0,840.0,321.0,null,359.0,892.0,null,1427.0,1938.0,312.0,413.0,401.0,290.0,1173.0,371.0,4561.0,null,1276.0,2330.0,966.0,976.0,731.0,857.0,1167.0,3973.0,728.0,null,193.0,null,null,null,376.0,1963.0,6355.0,260.0,null,679.0,1865.0,1817.0,null,470.0,716.0,949.0,7532.0,523.0,null,null,null,null,1489.0,1279.0,null,490.0,523.0,1500.0,1993.0,1038.0,280.0,705.0,1150.0,1080.0,null,1080.0,1130.0,3408.0,1001.0,5193.0,1162.0,1135.0,1799.0,1665.0,443.0,977.0,1576.0,1130.0,null,914.0,520.0,425.0,426.0,null,1355.0,null,null,null,319.0,775.0,null,909.0,366.0,575.0,1370.0,1130.0,null,1056.0,785.0,651.0,2174.0,null,null,892.0,936.0,421.0,null,1730.0,1421.0,null,1368.0,1660.0,5091.0,763.0,722.0,null,null,973.0,880.0,930.0,1137.0,1.0,null,166.0,493.0,294.0,null,805.0,1243.0,573.0,null,917.0,1259.0,927.0,3272.0,1341.0,547.0,null,1202.0,1088.0,1861.0,572.0,1031.0,778.0,228.0,1836.0,810.0,562.0,1208.0,882.0,892.0,1174.0,null,482.0,1482.0,740.0,7662.0,649.0,null,396.0,null,743.0,704.0,585.0,1320.0,null,null,null,2881.0,null,389.0,680.0,null,413.0,582.0,null,null,674.0,1308.0,603.0,null,1021.0,null,null,null,1212.0,322.0,1070.0,810.0,600.0,1353.0,1011.0,805.0,null,1186.0,2350.0,158.0,null,null,713.0,343.0,null,1201.0,280.0,1078.0,367.0,1220.0,1363.0,443.0,557.0,1794.0,694.0,488.0,1011.0,463.0,1854.0,885.0,null,1249.0,null,372.0,1080.0,800.0,344.0,1240.0,1355.0,731.0,null,726.0,1199.0,null,619.0,548.0,535.0,null,463.0,null,null,565.0,272.0,null,1451.0,696.0,null,811.0,1779.0,624.0,389.0,783.0,null,null,753.0,594.0,461.0,842.0,1175.0,1427.0,null,2322.0,1209.0,3487.0,788.0,708.0,738.0,815.0,null,1192.0,1150.0,914.0,1167.0,1013.0,664.0,384.0,443.0,null,294.0,null,1808.0,null,669.0,337.0,297.0,349.0,122.0,409.0,1612.0,924.0,218.0,681.0,null,1631.0,842.0,1100.0,743.0,null,656.0,716.0,446.0,458.0,null,1730.0,352.0,2000.0,1623.0,null,null,468.0,808.0,null,614.0,304.0,1703.0,null,null,1462.0,892.0,null,674.0,327.0,433.0,237.0,998.0,null,2546.0,713.0,669.0,414.0,3048.0,911.0,1239.0,505.0,705.0,347.0,1016.0,1048.0,580.0,645.0,1023.0,813.0,647.0,null,644.0,2530.0,505.0,1067.0,null,398.0,null,null,971.0,null,342.0,2231.0,557.0,null,508.0,1088.0,1.0,753.0,1021.0,282.0,2166.0,null,773.0,562.0,null,null,null,null,3544.0,897.0,706.0,200.0,609.0,745.0,505.0,800.0,null,542.0,null,1053.0,null,596.0,307.0,247.0,884.0,null,535.0,513.0,837.0,701.0,661.0,2604.0,2654.0,null,607.0,1232.0,null,null,null,617.0,968.0,993.0,null,415.0,7441.0,466.0,null,null,877.0,240.0,894.0,1614.0,null,592.0,342.0,null,null,597.0,1285.0,788.0,882.0,265.0,1606.0,1227.0,366.0,1366.0,null,959.0,577.0,743.0,1065.0,635.0,322.0,null,2728.0,4395.0,1623.0,1859.0,661.0,1588.0,2421.0,421.0,733.0,1018.0,2066.0,2599.0,1395.0,null,null,790.0,617.0,1074.0,651.0,736.0,1571.0,979.0,855.0,3585.0,545.0,1794.0,null,837.0,3170.0,312.0,2932.0,1052.0,560.0,316.0,1395.0,700.0,null,8085.0,null,413.0,391.0,null,null,396.0,451.0,null,null,5550.0,null,null,2654.0,426.0,917.0,518.0,946.0,null,null,null,1460.0,743.0,null,827.0,2880.0,374.0,428.0,null,1636.0,1187.0,1164.0,738.0,2511.0,290.0,null,619.0,null,537.0,null,869.0,685.0,2565.0,788.0,3428.0,373.0,877.0,840.0,929.0,416.0,687.0,null,364.0,979.0,null,null,1117.0,1276.0,391.0,465.0,1477.0,927.0,361.0,252.0,null,412.0,1370.0,617.0,845.0,689.0,1139.0,3354.0,null,1005.0,302.0,438.0,971.0,354.0,495.0,null,2140.0,654.0,1060.0,null,659.0,null,339.0,null,2211.0,1400.0,null,696.0,696.0,5406.0,617.0,3066.0,null,null,null,3116.0,1878.0,697.0,2089.0,609.0,null,null,656.0,686.0,544.0,3161.0,2620.0,954.0,1393.0,2135.0,1767.0,225.0,714.0,null,611.0,711.0,2226.0,485.0,364.0,null,1265.0,null,null,495.0,1717.0,795.0,604.0,null,617.0,null,1448.0,644.0,null,2859.0,1202.0,null,614.0,706.0,null,4040.0,674.0,null,2164.0,976.0,null,319.0,2317.0,null,null,874.0,705.0,297.0,808.0,null,2789.0,1234.0,1184.0,1284.0,null,null,1251.0,659.0,557.0,542.0,423.0,null,720.0,290.0,1024.0,473.0,332.0,453.0,null,656.0,1983.0,9226.0,null,1388.0,956.0,488.0,882.0,null,374.0,1536.0,472.0,505.0,782.0,5862.0,810.0,null,296.0,1613.0,1615.0,480.0,497.0,624.0,565.0,null,590.0,794.0,1003.0,1417.0,914.0,1222.0,716.0,null,1319.0,1298.0,513.0,1112.0,230.0,587.0,475.0,562.0,312.0,575.0,478.0,2317.0,411.0,1638.0,null,565.0,865.0,991.0,711.0,3572.0,54.0,862.0,1415.0,815.0,2248.0,386.0,2216.0,1519.0,null,578.0,1826.0,1.0,null,null,1242.0,706.0,855.0,351.0,1140.0,521.0,1.0,339.0,1122.0,null,459.0,null,1.0,721.0,1756.0,535.0,3353.0,null,2170.0,614.0,406.0,1412.0,1068.0,1779.0,1241.0,1224.0,359.0,1077.0,560.0,1048.0,391.0,1363.0,1028.0,2597.0,803.0,2119.0,311.0,488.0,null,null,null,401.0,1095.0,418.0,1165.0,null,178.0,788.0,810.0,1095.0,1207.0,null,2092.0,3210.0,null,1389.0,null,1546.0,650.0,475.0,892.0,null,null,null,null,null,null,1127.0,null,379.0,525.0,629.0,1.0,1462.0,null,null,null,1952.0,2421.0,null,619.0,1399.0,null,null,1544.0,406.0,594.0,1299.0,780.0,null,1077.0,null,461.0,1266.0,null,821.0,null,null],
"living_area":[67.0,285.0,170.0,282.0,150.0,209.0,160.0,140.0,343.0,120.0,195.0,123.0,100.0,150.0,168.0,250.0,173.0,205.0,167.0,260.0,110.0,144.0,200.0,102.0,106.0,90.0,60.0,180.0,450.0,103.0,208.0,76.0,265.0,399.0,583.0,327.0,300.0,214.0,190.0,130.0,320.0,203.0,174.0,135.0,160.0,81.0,null,119.0,184.0,160.0,167.0,145.0,376.0,165.0,185.0,140.0,180.0,256.0,255.0,167.0,133.0,168.0,190.0,275.0,150.0,252.0,161.0,205.0,205.0,171.0,250.0,45.0,184.0,384.0,null,200.0,300.0,228.0,377.0,185.0,287.0,135.0,460.0,206.0,94.0,235.0,62.0,253.0,217.0,230.0,206.0,144.0,200.0,284.0,240.0,312.0,null,220.0,156.0,170.0,215.0,254.0,370.0,230.0,227.0,120.0,194.0,180.0,130.0,110.0,664.0,200.0,180.0,501.0,90.0,103.0,448.0,284.0,130.0,297.0,170.0,154.0,85.0,40.0,535.0,126.0,388.0,180.0,195.0,225.0,90.0,112.0,176.0,277.0,130.0,135.0,215.0,160.0,421.0,100.0,210.0,130.0,160.0,null,185.0,422.0,null,180.0,141.0,225.0,232.0,222.0,213.0,140.0,700.0,155.0,171.0,168.0,450.0,165.0,264.0,145.0,131.0,127.0,405.0,null,415.0,280.0,243.0,158.0,94.0,260.0,263.0,120.0,375.0,150.0,438.0,217.0,125.0,167.0,124.0,null,96.0,199.0,210.0,233.0,206.0,321.0,75.0,650.0,136.0,140.0,350.0,230.0,280.0,156.0,150.0,142.0,300.0,225.0,100.0,283.0,173.0,133.0,110.0,80.0,155.0,129.0,260.0,218.0,325.0,160.0,125.0,200.0,145.0,134.0,135.0,149.0,166.0,255.0,450.0,128.0,290.0,220.0,370.0,157.0,null,166.0,122.0,160.0,212.0,140.0,110.0,107.0,115.0,273.0,385.0,205.0,195.0,109.0,132.0,320.0,220.0,270.0,120.0,308.0,594.0,135.0,160.0,890.0,400.0,225.0,122.0,120.0,285.0,105.0,300.0,196.0,180.0,1165.0,285.0,118.0,168.0,163.0,115.0,493.0,373.0,122.0,737.0,326.0,208.0,314.0,130.0,185.0,150.0,138.0,130.0,174.0,414.0,160.0,138.0,114.0,191.0,137.0,195.0,83.0,200.0,458.0,139.0,100.0,390.0,212.0,315.0,240.0,171.0,421.0,520.0,127.0,210.0,75.0,557.0,175.0,267.0,345.0,193.0,270.0,220.0,124.0,300.0,180.0,160.0,120.0,773.0,200.0,182.0,123.0,224.0,78.0,136.0,178.0,122.0,296.0,238.0,214.0,200.0,200.0,150.0,203.0,420.0,null,140.0,251.0,72.0,240.0,null,326.0,160.0,198.0,242.0,250.0,229.0,170.0,90.0,137.0,140.0,225.0,150.0,270.0,120.0,300.0,371.0,267.0,222.0,146.0,126.0,122.0,400.0,469.0,220.0,93.0,75.0,215.0,145.0,184.0,145.0,341.0,150.0,190.0,171.0,225.0,234.0,172.0,175.0,200.0,266.0,210.0,171.0,135.0,300.0,185.0,260.0,103.0,117.0,159.0,145.0,284.0,550.0,318.0,300.0,550.0,160.0,410.0,150.0,217.0,268.0,232.0,136.0,234.0,280.0,92.0,120.0,220.0,null,200.0,174.0,137.0,177.0,165.0,143.0,165.0,75.0,153.0,229.0,130.0,260.0,260.0,540.0,320.0,763.0,264.0,183.0,162.0,329.0,138.0,123.0,230.0,129.0,130.0,240.0,200.0,210.0,110.0,490.0,286.0,344.0,155.0,500.0,297.0,178.0,304.0,298.0,177.0,190.0,157.0,720.0,150.0,286.0,126.0,385.0,719.0,55.0,185.0,280.0,307.0,105.0,124.0,160.0,186.0,175.0,286.0,null,250.0,185.0,281.0,52.0,172.0,380.0,180.0,216.0,224.0,256.0,285.0,408.0,177.0,160.0,237.0,332.0,250.0,530.0,167.0,190.0,40.0,150.0,190.0,360.0,132.0,270.0,244.0,125.0,236.0,86.0,420.0,120.0,322.0,563.0,140.0,297.0,310.0,100.0,null,140.0,220.0,160.0,110.0,264.0,160.0,115.0,350.0,173.0,67.0,112.0,728.0,70.0,217.0,263.0,396.0,219.0,123.0,176.0,175.0,182.0,160.0,175.0,110.0,166.0,180.0,118.0,99.0,218.0,185.0,250.0,260.0,415.0,130.0,237.0,174.0,200.0,222.0,145.0,146.0,181.0,207.0,187.0,112.0,151.0,141.0,530.0,150.0,178.0,550.0,100.0,130.0,120.0,197.0,380.0,130.0,200.0,250.0,281.0,160.0,103.0,191.0,183.0,175.0,260.0,145.0,288.0,180.0,175.0,146.0,262.0,122.0,284.0,120.0,130.0,160.0,310.0,137.0,164.0,184.0,120.0,353.0,415.0,200.0,250.0,189.0,190.0,156.0,300.0,150.0,120.0,270.0,205.0,55.0,110.0,170.0,285.0,130.0,null,152.0,134.0,null,326.0,162.0,689.0,217.0,148.0,148.0,192.0,250.0,165.0,230.0,190.0,220.0,102.0,120.0,156.0,400.0,250.0,193.0,61.0,115.0,128.0,200.0,178.0,340.0,103.0,275.0,142.0,114.0,280.0,160.0,null,165.0,360.0,132.0,180.0,178.0,130.0,241.0,124.0,300.0,205.0,275.0,83.0,90.0,240.0,194.0,165.0,234.0,196.0,null,330.0,100.0,139.0,180.0,390.0,218.0,168.0,90.0,137.0,135.0,128.0,229.0,136.0,115.0,115.0,125.0,104.0,63.0,220.0,161.0,126.0,140.0,250.0,350.0,158.0,176.0,195.0,428.0,167.0,100.0,150.0,267.0,95.0,163.0,155.0,110.0,138.0,280.0,370.0,458.0,232.0,95.0,217.0,224.0,174.0,null,180.0,285.0,155.0,150.0,230.0,145.0,139.0,600.0,224.0,150.0,127.0,220.0,115.0,221.0,250.0,340.0,160.0,320.0,90.0,115.0,120.0,90.0,210.0,127.0,190.0,175.0,267.0,241.0,83.0,240.0,145.0,null,165.0,178.0,133.0,180.0,220.0,null,166.0,151.0,260.0,87.0,140.0,null,167.0,119.0,131.0,319.0,100.0,317.0,115.0,127.0,607.0,215.0,260.0,120.0,372.0,230.0,88.0,100.0,266.0,127.0,120.0,105.0,286.0,220.0,345.0,110.0,720.0,177.0,155.0,236.0,110.0,159.0,207.0,448.0,106.0,266.0,182.0,488.0,315.0,495.0,429.0,135.0,175.0,123.0,125.0,429.0,135.0,276.0,225.0,540.0,180.0,144.0,164.0,485.0,170.0,120.0,189.0,150.0,98.0,308.0,193.0,138.0,135.0,116.0,246.0,115.0,133.0,140.0,85.0,201.0,142.0,144.0,null,105.0,136.0,445.0,68.0,150.0,330.0,188.0,190.0,163.0,80.0,250.0,210.0,302.0,176.0,344.0,146.0,200.0,80.0,142.0,160.0,176.0,105.0,206.0,260.0,114.0,115.0,110.0,158.0,135.0,178.0,148.0,234.0,164.0,160.0,202.0,220.0,260.0,198.0,153.0,448.0,245.0,190.0,205.0,225.0,130.0,179.0,100.0,567.0,282.0,172.0,190.0,76.0,140.0,130.0,100.0,400.0,181.0,215.0,235.0,107.0,85.0,240.0,174.0,125.0,290.0,147.0,87.0,152.0,207.0,100.0,304.0,153.0,135.0,135.0,282.0,346.0,169.0,116.0,240.0,60.0,330.0,168.0,null,179.0,90.0,180.0,175.0,179.0,null,103.0,200.0,150.0,148.0,285.0,200.0,133.0,265.0,229.0,80.0,150.0,130.0,340.0,255.0,555.0,324.0,226.0,106.0,142.0,410.0,188.0,60.0,285.0,251.0,170.0,200.0,350.0,200.0,220.0,147.0,120.0,204.0,174.0,380.0,259.0,135.0,287.0,197.0,720.0,113.0,154.0,164.0,214.0,315.0,240.0,400.0,137.0,166.0,466.0,160.0,224.0,232.0,290.0,386.0,218.0,176.0,176.0,147.0,202.0,91.0,316.0,473.0,326.0,250.0,252.0,266.0,135.0,179.0,140.0,140.0,73.0,203.0,265.0,118.0,165.0,250.0,250.0,278.0,135.0,138.0,70.0,105.0,222.0,125.0,200.0,150.0,200.0,200.0,70.0,230.0,250.0,142.0,320.0,140.0,173.0,107.0,117.0,180.0,112.0,276.0,222.0,267.0,365.0,129.0,125.0,112.0,80.0,172.0,null,167.0,258.0,191.0,150.0,173.0,135.0,130.0,175.0,90.0,430.0,260.0,195.0,184.0,160.0,240.0,279.0,267.0,249.0,208.0,186.0,312.0,350.0,143.0,160.0,142.0,170.0,112.0,123.0,408.0,282.0,113.0,140.0,307.0,118.0,260.0,269.0,164.0,176.0,467.0,208.0,270.0,119.0,347.0,207.0,100.0,340.0,133.0,185.0,185.0,170.0,168.0,290.0,136.0,125.0,550.0,192.0,151.0,450.0,221.0,132.0,315.0,166.0,180.0,130.0,140.0,284.0,155.0,null,217.0,180.0,99.0,160.0,110.0,95.0,80.0,189.0,515.0,107.0,160.0,200.0,505.0,180.0,200.0,337.0,null,210.0,150.0,220.0,110.0,117.0,320.0,214.0,250.0,null,154.0,300.0,429.0,146.0,122.0,110.0,285.0,222.0,288.0,370.0,136.0,320.0,440.0,420.0,85.0,610.0,590.0,150.0,123.0,195.0,130.0,170.0,66.0,120.0,150.0,148.0,368.0,155.0,170.0,300.0,100.0,148.0,190.0,260.0,null,260.0,595.0,393.0,148.0,546.0,328.0,160.0,200.0,988.0,156.0,60.0,434.0,392.0,440.0,382.0,293.0,261.0,275.0,285.0,200.0,182.0,215.0,470.0,256.0,160.0,95.0,200.0,234.0,170.0,243.0,322.0,369.0,132.0,720.0,125.0,321.0,400.0,90.0,449.0,400.0,120.0,169.0,207.0,286.0,219.0,120.0,330.0,241.0,115.0,183.0,178.0,147.0,102.0,400.0,268.0,197.0,250.0,202.0,213.0,117.0,250.0,146.0,132.0,250.0,102.0,201.0,216.0,82.0,150.0,168.0,280.0,222.0,136.0,194.0,106.0,130.0,194.0,100.0,281.0,164.0,180.0,167.0,275.0,237.0,123.0,149.0,175.0,114.0,130.0,40.0,130.0,110.0,375.0,170.0,463.0,200.0,234.0,204.0,190.0,160.0,260.0,275.0,405.0,535.0,120.0,173.0,278.0,315.0,240.0,104.0,216.0,133.0,135.0,107.0,81.0,177.0,190.0,156.0,340.0,202.0,126.0,243.0,210.0,370.0,255.0,239.0,200.0,135.0,636.0,220.0,506.0,280.0,200.0,230.0,450.0,276.0,303.0,170.0,253.0,570.0,200.0,260.0,225.0,60.0,445.0,87.0,320.0,344.0,540.0,150.0,130.0,110.0,180.0,270.0,244.0,142.0,120.0,350.0,152.0,629.0,135.0,233.0,149.0,350.0,240.0,300.0,113.0,113.0,262.0,160.0,211.0,160.0,211.0,176.0,128.0,101.0,535.0,416.0,163.0,700.0,110.0,145.0,179.0,185.0,220.0,90.0,77.0,361.0,240.0,209.0,305.0,174.0,552.0,200.0,198.0,356.0,154.0,123.0,121.0,172.0,280.0,153.0,110.0,312.0,140.0,400.0,331.0,89.0,155.0,131.0,890.0,175.0,145.0,200.0,320.0,131.0,85.0,221.0,564.0,136.0,146.0,201.0,264.0,250.0,162.0,175.0,150.0,124.0,257.0,127.0,110.0,155.0,165.0,405.0,240.0,289.0,176.0,350.0,200.0,114.0,507.0,126.0,314.0,524.0,125.0,273.0,170.0,184.0,160.0,76.0,500.0,128.0,68.0,252.0,125.0,181.0,285.0,258.0,291.0,180.0,185.0,null,107.0,220.0,415.0,160.0,161.0,250.0,93.0,280.0,95.0,186.0,65.0,450.0,128.0,300.0,135.0,158.0,429.0,80.0,275.0,336.0,130.0,115.0,105.0,92.0,120.0,399.0,172.0,140.0,142.0,287.0,239.0,159.0,212.0,148.0,142.0,533.0,215.0,247.0,126.0,133.0,151.0,133.0,125.0,445.0,118.0,200.0,240.0,180.0,157.0,275.0,116.0,145.0,150.0,495.0,135.0,153.0,192.0,250.0,297.0,100.0,673.0,170.0,230.0,225.0,285.0,240.0,140.0,192.0,210.0,180.0,115.0,110.0,260.0,260.0,160.0,180.0,155.0,336.0,436.0,178.0,210.0,131.0,208.0,187.0,119.0,144.0,92.0,512.0,163.0,445.0,100.0,256.0,263.0,421.0,200.0,100.0,390.0,168.0,90.0,216.0,230.0,138.0,234.0,193.0,106.0,150.0,200.0,200.0,153.0,310.0,407.0,135.0,116.0,92.0,200.0,220.0,144.0,228.0,null,127.0,450.0,281.0,550.0,275.0,103.0,251.0,null,211.0,175.0,250.0,168.0,150.0,191.0,120.0,423.0,100.0,232.0,267.0,231.0,174.0,300.0,200.0,405.0,148.0,217.0,140.0,162.0,148.0,210.0,61.0,100.0,200.0,365.0,170.0,100.0,241.0,165.0,160.0,100.0,138.0,155.0,135.0,126.0,50.0,247.0,630.0,250.0,370.0,127.0,69.0,361.0,200.0,234.0,170.0,125.0,320.0,304.0,182.0,180.0,188.0,300.0,248.0,161.0,125.0,103.0,160.0,257.0,null,292.0,180.0,106.0,250.0,153.0,65.0,198.0,245.0,218.0,238.0,180.0,98.0,103.0,221.0,375.0,120.0,159.0,122.0,200.0,113.0,147.0,120.0,165.0,180.0,156.0,180.0,184.0,240.0,90.0,353.0,287.0,167.0,407.0,260.0,710.0,310.0,340.0,168.0,154.0,80.0,440.0,188.0,165.0,382.0,526.0,150.0,239.0,105.0,126.0,217.0,321.0,135.0,330.0,220.0,300.0,202.0,203.0,560.0,250.0,215.0,350.0,560.0,164.0,102.0,145.0,133.0,132.0,139.0,234.0,350.0,800.0,119.0,72.0,460.0,85.0,500.0,288.0,181.0,171.0,250.0,363.0,268.0,150.0,110.0,197.0,548.0,120.0,160.0,null,220.0,300.0,171.0,167.0,185.0,181.0,90.0,351.0,128.0,90.0,275.0,115.0,407.0,190.0,95.0,377.0,194.0,281.0,580.0,200.0,335.0,485.0,140.0,370.0,294.0,104.0,69.0,448.0,244.0,175.0,140.0,36.0,146.0,151.0,null,156.0,705.0,108.0,383.0,120.0,154.0,160.0,132.0,220.0,172.0,165.0,105.0,200.0,220.0,null,330.0,98.0,370.0,425.0,130.0,150.0,385.0,171.0,350.0,260.0,398.0,112.0,245.0,230.0,554.0,370.0,155.0,304.0,195.0,147.0,170.0,307.0,260.0,125.0,125.0,204.0,270.0,120.0,159.0,132.0,190.0,250.0,366.0,120.0,135.0,200.0,492.0,229.0,172.0,187.0,null,329.0,270.0,277.0,120.0,194.0,169.0,145.0,250.0,104.0,277.0,107.0,137.0,248.0,247.0,230.0,386.0,224.0,150.0,110.0,128.0,119.0,215.0,400.0,121.0,702.0,232.0,215.0,172.0,145.0,150.0,221.0,188.0,null,610.0,123.0,200.0,275.0,265.0,126.0,240.0,273.0,140.0,207.0,246.0,117.0,60.0,200.0,133.0,791.0,109.0,135.0,140.0,180.0,660.0,200.0,160.0,136.0,239.0,148.0,172.0,98.0,100.0,297.0,150.0,255.0,100.0,280.0,356.0,89.0,126.0,500.0,125.0,240.0,200.0,123.0,270.0,167.0,127.0,null,130.0,630.0,116.0,218.0,135.0,215.0,185.0,187.0,248.0,98.0,145.0,130.0,80.0,118.0,162.0,110.0,275.0,140.0,198.0,200.0,360.0,240.0,147.0,164.0,174.0,1165.0,145.0,116.0,236.0,200.0,176.0,290.0,175.0,400.0,195.0,226.0,303.0,232.0,120.0,258.0,200.0,90.0,230.0,150.0,131.0,210.0,185.0,214.0,272.0,274.0,70.0,156.0,171.0,86.0,176.0,288.0,104.0,84.0,128.0,119.0,157.0,345.0,129.0,130.0,196.0,170.0,140.0,67.0,485.0,80.0,52.0,108.0,231.0,200.0,450.0,117.0,259.0,135.0,368.0,140.0,113.0,124.0,160.0,260.0,190.0,230.0,242.0,140.0,263.0,236.0,190.0,370.0,250.0,190.0,159.0,224.0,130.0,130.0,166.0,152.0,204.0,90.0,323.0,188.0,91.0,139.0,130.0,221.0,160.0,369.0,119.0,330.0,340.0,177.0,120.0,180.0,640.0,305.0,144.0,162.0,260.0,153.0,null,311.0,132.0,235.0,450.0,85.0,191.0,220.0,183.0,140.0,811.0,135.0,257.0,120.0,83.0,400.0,100.0,101.0,448.0,145.0,75.0,227.0,155.0,240.0,112.0,311.0,500.0,400.0,212.0,105.0,191.0,262.0,205.0,100.0,185.0,360.0,158.0,300.0,147.0,290.0,246.0,321.0,96.0,130.0,326.0,115.0,86.0,220.0,150.0,140.0,190.0,236.0,228.0,216.0,148.0,394.0,282.0,131.0,231.0,93.0,128.0,137.0,303.0,168.0,300.0,null,209.0,330.0,270.0,182.0,150.0,80.0,1005.0,257.0,450.0,114.0,287.0,150.0,205.0,290.0,166.0,155.0,260.0,133.0,105.0,140.0,137.0,115.0,550.0,440.0,404.0,150.0,139.0,116.0,184.0,235.0,122.0,552.0,195.0,340.0,106.0,416.0,205.0,240.0,297.0,163.0,100.0,146.0,118.0,55.0,175.0,150.0,265.0,190.0,200.0,570.0,173.0,367.0,213.0,116.0,229.0,168.0,130.0,239.0,198.0,400.0,86.0,300.0,178.0,106.0,null,185.0,363.0,92.0,205.0,175.0,190.0,160.0,200.0,200.0,215.0,257.0,146.0,168.0,191.0,196.0,170.0,128.0,237.0,201.0,181.0,166.0,288.0,160.0,251.0,176.0,95.0,115.0,125.0,150.0,130.0,157.0,600.0,250.0,280.0,317.0,120.0,275.0,200.0,173.0,223.0,182.0,340.0,264.0,165.0,98.0,231.0,135.0,192.0,null,450.0,300.0,150.0,70.0,165.0,120.0,170.0,90.0,180.0,null,203.0,253.0,150.0,175.0,160.0,282.0,104.0,82.0,150.0,206.0,250.0,267.0,480.0,170.0,116.0,125.0,100.0,261.0,197.0,295.0,165.0,152.0,180.0,125.0,135.0,75.0,334.0,174.0,86.0,162.0,170.0,null,289.0,82.0,265.0,185.0,102.0,147.0,152.0,265.0,338.0,128.0,213.0,177.0,890.0,260.0,156.0,80.0,null,260.0,150.0,219.0,180.0,130.0,242.0,111.0,260.0,413.0,295.0,112.0,148.0,140.0,120.0,131.0,202.0,140.0,238.0,650.0,513.0,182.0,107.0,155.0,197.0,211.0,237.0,260.0,285.0,180.0,150.0,121.0,476.0,744.0,270.0,130.0,269.0,300.0,181.0,150.0,95.0,157.0,221.0,110.0,130.0,614.0,463.0,417.0,451.0,411.0,160.0,130.0,189.0,360.0,125.0,150.0,375.0,220.0,325.0,171.0,115.0,177.0,135.0,200.0,144.0,195.0,329.0,214.0,300.0,277.0,300.0,315.0,269.0,440.0,85.0,150.0,150.0,185.0,310.0,150.0,140.0,116.0,175.0,200.0,328.0,153.0,195.0,145.0,252.0,170.0,null,161.0,217.0,250.0,380.0,175.0,132.0,180.0,130.0,568.0,221.0,105.0,200.0,150.0,284.0,452.0,123.0,98.0,200.0,81.0,290.0,308.0,175.0,180.0,255.0,177.0,170.0,253.0,170.0,336.0,224.0,88.0,179.0,137.0,230.0,72.0,190.0,205.0,100.0,135.0,325.0,176.0,87.0,185.0,410.0,252.0,216.0,81.0,130.0,225.0,387.0,164.0,194.0,70.0,110.0,176.0,65.0,478.0,179.0,111.0,132.0,null,193.0,368.0,194.0,421.0,758.0,200.0,335.0,147.0,237.0,250.0,301.0,315.0,130.0,176.0,224.0,60.0,172.0,390.0,158.0,430.0,160.0,343.0,265.0,110.0,48.0,259.0,215.0,143.0,227.0,285.0,125.0,395.0,240.0,175.0,360.0,117.0,127.0,90.0,93.0,185.0,379.0,165.0,93.0,404.0,270.0,215.0,642.0,125.0,184.0,425.0,227.0,372.0,null,80.0,234.0,212.0,135.0,null,188.0,107.0,178.0,127.0,200.0,350.0,194.0,190.0,310.0,160.0,120.0,200.0,133.0,162.0,301.0,120.0,228.0,53.0,202.0,125.0,535.0,92.0,144.0,352.0,null,125.0,490.0,155.0,180.0,120.0,55.0,140.0,535.0,250.0,240.0,297.0,320.0,284.0,340.0,138.0,116.0,188.0,160.0,220.0,210.0,125.0,200.0,132.0,180.0,124.0,180.0,174.0,280.0,91.0,400.0,145.0,183.0,367.0,65.0,220.0,150.0,148.0,155.0,574.0,195.0,275.0,137.0,246.0,151.0,155.0,241.0,90.0,377.0,610.0,162.0,325.0,218.0,184.0,360.0,180.0,208.0,320.0,188.0,320.0,139.0,180.0,230.0,null,144.0,150.0,114.0,158.0,142.0,227.0,140.0,275.0,140.0,93.0,128.0,211.0,180.0,728.0,80.0,192.0,217.0,96.0,130.0,68.0,320.0,125.0,420.0,138.0,156.0,120.0,160.0,260.0,320.0,151.0,207.0,141.0,213.0,125.0,149.0,160.0,140.0,210.0,151.0,217.0,173.0,350.0,340.0,295.0,265.0,173.0,650.0,75.0,285.0,363.0,240.0,180.0,253.0,237.0,125.0,424.0,162.0,285.0,110.0,171.0,300.0,153.0,222.0,90.0,140.0,387.0,160.0,160.0,291.0,167.0,702.0,422.0,125.0,160.0,151.0,144.0,127.0,310.0,229.0,162.0,495.0,155.0,131.0,275.0,72.0,117.0,70.0,120.0,286.0,190.0,110.0,165.0,260.0,182.0,154.0,160.0,509.0,245.0,110.0,360.0,100.0,151.0,135.0,187.0,270.0,200.0,68.0,79.0,1200.0,294.0,115.0,60.0,209.0,59.0,160.0,330.0,241.0,290.0,218.0,223.0,null,148.0,240.0,115.0,510.0,252.0,88.0,368.0,204.0,367.0,115.0,151.0,177.0,327.0,195.0,210.0,85.0,310.0,137.0,490.0,110.0,166.0,1264.0,192.0,300.0,214.0,280.0,256.0,75.0,61.0,200.0,180.0,1461.0,183.0,323.0,321.0,null,240.0,267.0,190.0,159.0,132.0,140.0,90.0,185.0,265.0,138.0,552.0,383.0,230.0,125.0,218.0,259.0,230.0,445.0,319.0,190.0,264.0,99.0,150.0,142.0,215.0,280.0,200.0,200.0,339.0,73.0,300.0,100.0,321.0,348.0,370.0,346.0,157.0,114.0,95.0,188.0,110.0,133.0,220.0,178.0,247.0,317.0,336.0,125.0,153.0,250.0,216.0,null,139.0,95.0,130.0,207.0,192.0,197.0,185.0,294.0,350.0,376.0,120.0,225.0,182.0,230.0,133.0,141.0,130.0,174.0,260.0,217.0,200.0,277.0,150.0,270.0,152.0,298.0,141.0,140.0,200.0,176.0,155.0,350.0,280.0,153.0,330.0,254.0,null,245.0,175.0,209.0,130.0,50.0,269.0,228.0,136.0,230.0,122.0,140.0,240.0,320.0,202.0,394.0,145.0,425.0,100.0,150.0,85.0,250.0,125.0,176.0,187.0,236.0,200.0,175.0,157.0,420.0,310.0,150.0,191.0,240.0,169.0,122.0,202.0,120.0,196.0,230.0,130.0,310.0,218.0,300.0,320.0,400.0,385.0,120.0,164.0,115.0,100.0,333.0,218.0,121.0,173.0,195.0,160.0,null,373.0,142.0,198.0,197.0,210.0,252.0,120.0,320.0,116.0,139.0,506.0,130.0,135.0,111.0,90.0,158.0,120.0,143.0,290.0,135.0,256.0,180.0,200.0,103.0,206.0,135.0,117.0,194.0,348.0,170.0,114.0,60.0,264.0,152.0,155.0,144.0,176.0,440.0,150.0,117.0,161.0,132.0,85.0,180.0,210.0,160.0,500.0,149.0,215.0,181.0,150.0,188.0,243.0,180.0,160.0,165.0,150.0,155.0,367.0,344.0,260.0,240.0,250.0,225.0,120.0,160.0,183.0,115.0,261.0,178.0,180.0,85.0,106.0,204.0,260.0,102.0,93.0,542.0,140.0,420.0,209.0,264.0,210.0,75.0,82.0,180.0,135.0,108.0,214.0,136.0,85.0,188.0,299.0,238.0,350.0,139.0,244.0,125.0,183.0,125.0,120.0,124.0,501.0,192.0,70.0,423.0,230.0,363.0,945.0,169.0,106.0,230.0,235.0,80.0,250.0,179.0,208.0,155.0,135.0,235.0,157.0,114.0,75.0,110.0,132.0,265.0,295.0,264.0,305.0,140.0,488.0,190.0,110.0,140.0,552.0,115.0,363.0,183.0,110.0,122.0,268.0,148.0,210.0,825.0,162.0,250.0,161.0,184.0,260.0,150.0,null,240.0,150.0,158.0,141.0,129.0,95.0,80.0,103.0,263.0,202.0,180.0,150.0,80.0,155.0,327.0,68.0,144.0,165.0,64.0,175.0,350.0,285.0,114.0,300.0,42.0,null,220.0,111.0,200.0,375.0,124.0,132.0,327.0,null,160.0,137.0,108.0,345.0,120.0,124.0,152.0,170.0,90.0,200.0,162.0,314.0,366.0,85.0,null,180.0,189.0,290.0,162.0,160.0,181.0,425.0,193.0,340.0,118.0,475.0,112.0,175.0,100.0,160.0,445.0,292.0,188.0,112.0,144.0,324.0,175.0,223.0,225.0,197.0,80.0,150.0,202.0,100.0,126.0,210.0,157.0,163.0,253.0,268.0,137.0,118.0,181.0,715.0,495.0,150.0,162.0,200.0,150.0,350.0,209.0,210.0,179.0,173.0,210.0,140.0,145.0,212.0,240.0,206.0,192.0,139.0,110.0,219.0,250.0,175.0,475.0,100.0,316.0,230.0,226.0,420.0,78.0,509.0,186.0,170.0,146.0,140.0,121.0,200.0,156.0,153.0,121.0,120.0,180.0,125.0,131.0,263.0,120.0,450.0,295.0,230.0,389.0,181.0,120.0,282.0,130.0,213.0,176.0,75.0,132.0,253.0,179.0,92.0,126.0,497.0,115.0,185.0,176.0,250.0,200.0,270.0,144.0,390.0,92.0,300.0,90.0,225.0,130.0,300.0,201.0,133.0,380.0,120.0,265.0,98.0,281.0,279.0,null,137.0,117.0,250.0,166.0,250.0,135.0,279.0,336.0,180.0,140.0,145.0,204.0,319.0,141.0,43.0,287.0,150.0,228.0,185.0,145.0,149.0,334.0,320.0,106.0,157.0,162.0,150.0,180.0,111.0,125.0,105.0,340.0,110.0,230.0,150.0,145.0,296.0,110.0,134.0,316.0,267.0,190.0,116.0,121.0,340.0,110.0,217.0,240.0,275.0,900.0,500.0,500.0,234.0,279.0,160.0,60.0,177.0,250.0,166.0,165.0,336.0,350.0,269.0,165.0,362.0,138.0,110.0,167.0,193.0,250.0,125.0,199.0,135.0,174.0,198.0,260.0,120.0,182.0,182.0,110.0,110.0,233.0,115.0,175.0,48.0,290.0,96.0,270.0,280.0,215.0,89.0,130.0,153.0,140.0,190.0,163.0,204.0,190.0,144.0,578.0,162.0,700.0,164.0,429.0,300.0,552.0,130.0,195.0,459.0,380.0,160.0,153.0,164.0,402.0,287.0,220.0,110.0,217.0,160.0,171.0,193.0,140.0,151.0,175.0,94.0,157.0,116.0,423.0,452.0,315.0,549.0,300.0,296.0,288.0,168.0,208.0,250.0,100.0,356.0,111.0,116.0,250.0,758.0,162.0,null,68.0,280.0,341.0,130.0,100.0,231.0,308.0,131.0,92.0,180.0,168.0,150.0,220.0,120.0,176.0,294.0,235.0,280.0,75.0,187.0,104.0,136.0,80.0,201.0,107.0,155.0,300.0,550.0,127.0,401.0,300.0,170.0,523.0,156.0,181.0,209.0,200.0,120.0,238.0,254.0,300.0,131.0,210.0,307.0,360.0,155.0,521.0,174.0,220.0,192.0,192.0,175.0,130.0,84.0,119.0,190.0,197.0,182.0,163.0,180.0,115.0,515.0,174.0,139.0,381.0,96.0,220.0,249.0,410.0,200.0,145.0,170.0,155.0,193.0,239.0,240.0,130.0,292.0,263.0,178.0,121.0,506.0,94.0,200.0,109.0,244.0,117.0,123.0,130.0,287.0,251.0,212.0,190.0,137.0,216.0,305.0,111.0,160.0,240.0,199.0,384.0,279.0,156.0,297.0,105.0,195.0,534.0,255.0,130.0,160.0,130.0,184.0,200.0,133.0,218.0,256.0,178.0,120.0,50.0,102.0,113.0,150.0,171.0,145.0,650.0,75.0,350.0,345.0,350.0,177.0,115.0,210.0,129.0,101.0,257.0,227.0,80.0,205.0,262.0,192.0,370.0,269.0,109.0,300.0,264.0,249.0,225.0,195.0],
"price":[5.278753600952829,5.997823080745725,5.662757831681574,5.2552725051033065,5.681241237375588,6.036628895362161,5.662757831681574,5.423245873936808,5.928907690243952,5.872156272748293,5.113609151073028,5.596597095626461,5.378397900948138,5.596597095626461,5.252853030979893,5.371067862271736,5.096910013008056,5.230448921378274,5.298853076409706,5.238046103128795,5.173186268412274,5.567026366159061,5.371067862271736,5.623249290397901,4.977723605288848,5.431363764158987,5.176091259055681,5.628388930050312,6.239299479126893,5.252853030979893,5.414973347970818,5.1303337684950066,6.039414119176137,5.826074802700826,6.921686475483602,6.012837224705172,5.7774268223893115,5.648360010980932,5.69810054562339,5.676693609624866,5.396199347095736,5.7774268223893115,5.371067862271736,5.230448921378274,5.653212513775344,5.201397124320452,5.547774705387822,5.396199347095736,5.517195897949974,5.243038048686294,5.54282542695918,5.740362689494244,6.458637849025649,5.648360010980932,5.447002898466162,5.505149978319906,5.6180480967120925,5.896526217489555,5.9164539485499255,5.68930885912362,5.860338006570994,5.298853076409706,5.841984804590114,5.76715586608218,5.298853076409706,5.662757831681574,5.3404441148401185,5.7363965022766426,5.2552725051033065,5.342422680822207,5.7596678446896306,4.977723605288848,5.396199347095736,5.5301996982030825,5.600972895686748,5.518513939877887,6.469822015978163,5.57978359661681,5.662757831681574,6.088136088700551,5.47567118832443,5.6020599913279625,6.058805486675907,5.8750612633917,5.332438459915605,5.396199347095736,5.037426497940624,5.697229342759718,5.841984804590114,5.770852011642144,5.739572344450092,5.378397900948138,5.525044807036846,5.276461804173244,5.6523430550627145,5.902546779313991,5.5910646070264995,5.997823080745725,5.69810054562339,5.413299764081252,5.544068044350276,5.469822015978163,5.748188027006201,6.037426497940624,5.396199347095736,5.662757831681574,5.8444771757456815,5.662757831681574,5.429752280002408,5.385606273598312,5.933993163831242,5.439332693830263,5.555094448578319,5.929418925714293,5.359835482339888,5.252853030979893,6.161368002234975,5.917505509552547,5.361727836017593,5.589949601325708,5.819543935541868,5.7558748556724915,5.596597095626461,5.021189299069938,6.1303337684950066,5.575224804587434,5.715585551893196,5.159867847092567,5.676693609624866,5.9164539485499255,5.298853076409706,5.276461804173244,5.517195897949974,5.690196080028514,5.447158031342219,5.623249290397901,5.638489256954637,5.643353961976863,6.392696953259666,5.201397124320452,5.47567118832443,5.2552725051033065,5.653212513775344,6.079181246047625,5.469822015978163,5.652246341003323,6.276461804173244,5.2027606873932,5.47567118832443,5.652246341003323,5.298853076409706,5.628388930050312,5.648360010980932,5.544068044350276,6.174641192660449,5.469822015978163,5.574031267727719,5.230448921378274,5.832508912706237,5.5910646070264995,6.071882007306125,5.7596678446896306,5.518184804218403,5.267171728403014,6.229169702539101,5.951823035315912,5.6414741105041,5.694605198933568,5.76715586608218,5.359835482339888,5.060697840353612,5.899820502427096,6.295567099962479,5.872156272748293,5.812244696800369,5.525044807036846,5.951823035315912,5.54282542695918,5.1303337684950066,5.54282542695918,5.161368002234975,5.54282542695918,5.503790683057181,5.589949601325708,5.740362689494244,6.3414345245781405,5.69810054562339,5.854306041801081,5.176091259055681,6.439332693830263,5.209515014542631,5.371067862271736,6.290034611362518,5.77451696572855,5.298853076409706,5.4281347940287885,5.756636108245848,5.652246341003323,5.380211241711606,5.414973347970818,5.174641192660449,6.079181246047625,5.434568904034199,4.989004615698537,5.28443073384452,5.397070549959409,5.378397900948138,5.217483944213907,5.894869656745253,5.589949601325708,6.073718350346122,5.3414345245781405,5.342225229360791,5.698970004336019,5.298853076409706,5.469822015978163,5.290034611362518,5.352182518111363,5.477121254719663,5.47567118832443,5.993436230497612,5.445604203273597,5.7596678446896306,5.414973347970818,5.748188027006201,5.173186268412274,5.54282542695918,5.675778341674085,5.267171728403014,5.653212513775344,5.531478917042255,5.378397900948138,5.363611979892144,5.173186268412274,5.537819095073274,5.460897842756548,5.872156272748293,5.447158031342219,5.8750612633917,5.1702617153949575,5.697229342759718,5.874481817699467,5.812244696800369,6.2552725051033065,5.389166084364533,5.685741738602264,6.371067862271736,5.173186268412274,5.498310553789601,6.210853365314893,6.290034611362518,5.9003671286564705,5.352182518111363,5.173186268412274,5.628388930050312,5.161368002234975,5.707570176097937,5.350248018334163,5.694605198933568,6.290034611362518,5.911157608739977,4.99563519459755,5.600972895686748,5.423245873936808,5.267171728403014,5.984527313343793,5.989004615698537,5.173186268412274,5.724275869600789,6.095169351431755,5.567026366159061,5.825426117767823,5.201397124320452,5.600972895686748,5.378397900948138,5.397070549959409,5.3979400086720375,5.217483944213907,5.7626785637274365,5.54282542695918,5.6985354925620015,5.230193378869045,5.77451696572855,5.361727836017593,5.47567118832443,5.041392685158225,5.431363764158987,5.860338006570994,5.505149978319906,5.201397124320452,5.76715586608218,5.276461804173244,6.077367905284157,5.8750612633917,5.6127838567197355,5.77451696572855,6.491361693834273,5.54282542695918,5.176091259055681,5.146128035678238,5.997823080745725,5.143014800254095,5.439332693830263,5.685741738602264,5.474216264076255,5.812913356642856,5.929418925714293,5.585460729508501,6.297760511099134,5.739572344450092,5.354108439147401,5.389166084364533,6.628388930050312,5.77451696572855,5.860338006570994,5.694605198933568,5.4769764657595275,4.838849090737256,5.585460729508501,5.230448921378274,5.413299764081252,5.812244696800369,5.54282542695918,5.47567118832443,5.537819095073274,5.785329835010767,5.567026366159061,5.638489256954637,6.088136088700551,5.650307523131937,5.174641192660449,5.841984804590114,5.230193378869045,5.54282542695918,5.628388930050312,5.694605198933568,5.423245873936808,5.652246341003323,5.278753600952829,5.537819095073274,5.9003671286564705,5.544068044350276,5.447158031342219,5.267171728403014,5.379305517750582,5.477121254719663,5.252853030979893,5.993436230497612,5.298853076409706,5.928907690243952,6.088136088700551,5.748188027006201,5.648360010980932,5.439332693830263,5.429752280002408,4.903089986991944,6.112269768417271,6.229169702539101,5.589949601325708,5.3404441148401185,5.201397124320452,5.384711742938283,5.47567118832443,5.76715586608218,5.5301996982030825,5.902546779313991,5.77451696572855,5.8095597146352675,5.544068044350276,6.1303337684950066,5.676693609624866,5.469822015978163,5.1303337684950066,5.623249290397901,5.556302500767287,5.811909980420099,5.5532760461371,5.57287160220048,5.8061799739838875,5.252853030979893,5.413299764081252,5.361727836017593,5.537819095073274,5.176091259055681,5.47567118832443,5.638489256954637,5.812244696800369,5.47567118832443,5.511883360978874,6.290034611362518,5.596597095626461,5.628388930050312,5.3404441148401185,5.619615005742807,5.698970004336019,5.676693609624866,5.250420002308894,5.439332693830263,5.76715586608218,5.342422680822207,5.230448921378274,5.841984804590114,5.396199347095736,5.578639209968072,5.56643749219507,5.518513939877887,5.523746466811565,5.589949601325708,5.469822015978163,5.942008053022313,5.359835482339888,5.146128035678238,5.77451696572855,5.298853076409706,5.69810054562339,5.690196080028514,5.951823035315912,6.318063334962762,6.161368002234975,5.812913356642856,5.600972895686748,5.439332693830263,6.02530586526477,5.845098040014257,5.394451680826216,5.6674529528899535,5.5301996982030825,5.359835482339888,6.075546961392531,5.445604203273597,5.732393759822968,5.252853030979893,6.060697840353612,5.643452676486188,5.977723605288848,5.252853030979893,6.414137362184476,5.7626785637274365,5.653212513775344,6.075546961392531,5.69810054562339,5.585460729508501,5.643452676486188,5.697229342759718,6.077367905284157,5.447158031342219,5.6512780139981444,5.190331698170292,5.77451696572855,6.1303337684950066,4.949390006644912,5.6875289612146345,5.77451696572855,5.770852011642144,5.418301291319746,5.110589710299249,5.694605198933568,5.45484486000851,5.311753861055754,5.731588765186738,5.469822015978163,5.740362689494244,5.6875289612146345,5.671172842715083,4.949390006644912,5.227886704613674,6.144574207609616,5.290034611362518,5.3222192947339195,5.600972895686748,5.662757831681574,5.662757831681574,5.977266212427293,5.503790683057181,5.589949601325708,5.45484486000851,5.954242509439325,5.993436230497612,5.919078092376074,5.9164539485499255,5.690196080028514,5.143014800254095,5.928907690243952,5.76715586608218,6.096910013008056,5.4623979978989565,5.544068044350276,5.7160033436347994,5.600972895686748,5.531478917042255,5.079181246047625,6.439332693830263,5.6674529528899535,6.138302698166282,5.963787827345556,5.60151678365001,5.47567118832443,5.795184589682424,5.229169702539101,5.371067862271736,5.697229342759718,5.469822015978163,5.352182518111363,5.53135116458306,5.445604203273597,5.204119982655925,5.243038048686294,6.469822015978163,5.320146286111054,4.954242509439325,5.389166084364533,6.249198357391113,5.161368002234975,5.060697840353612,5.623249290397901,5.90200289135073,5.652246341003323,5.623249290397901,5.5439439424829065,5.676693609624866,5.413299764081252,5.77451696572855,5.812913356642856,5.414806279501013,5.537819095073274,5.413299764081252,5.460897842756548,5.204119982655925,5.720159303405957,5.252853030979893,5.793790384690818,5.54282542695918,6.040997692423491,5.574030109607556,5.6674529528899535,5.498310553789601,5.854306041801081,6.567614442730845,5.638489256954637,5.556302500767287,5.676693609624866,5.469822015978163,5.190331698170292,5.54282542695918,5.4769764657595275,5.600972895686748,6.290034611362518,5.54282542695918,5.511883360978874,6.277609214304091,5.3404441148401185,5.431041945335886,5.252853030979893,5.694605198933568,6.190331698170292,5.444044795918076,5.885926339801431,5.77451696572855,6.296665190261531,5.523746466811565,5.201397124320452,5.681241237375588,5.437750562820388,5.596597095626461,5.587710965018911,5.503790683057181,5.812244696800369,5.361727836017593,5.8228216453031045,5.537819095073274,5.47567118832443,5.681241237375588,5.600972895686748,5.139879086401237,5.7774268223893115,5.56466606425209,5.926856708949693,5.47567118832443,5.489958479424835,5.517195897949974,5.515634121156461,6.144574207609616,5.868644438394826,5.788875115775417,5.45484486000851,5.860338006570994,5.628388930050312,5.396199347095736,5.942008053022313,5.623249290397901,5.566816818546551,6.108903127667313,5.798650645445269,4.977723605288848,5.041392685158225,5.252853030979893,5.600972895686748,5.396199347095736,5.812913356642856,5.544068044350276,5.585460729508501,5.361727836017593,5.929418925714293,5.677515704798758,6.174641192660449,5.6875289612146345,5.574031267727719,5.173186268412274,5.986771734266245,5.685741738602264,5.45484486000851,6.077367905284157,5.474216264076255,5.489958479424835,5.250420002308894,5.389166084364533,5.740362689494244,6.525044807036846,5.812913356642856,5.276461804173244,4.986771734266245,5.469822015978163,5.201397124320452,5.110589710299249,5.628388930050312,5.7596678446896306,5.0,6.342422680822207,5.145817714491828,5.201397124320452,6.041392685158225,5.652246341003323,5.143014800254095,5.596597095626461,5.902546779313991,5.332438459915605,5.795880017344075,5.264817823009537,5.439332693830263,5.447158031342219,5.518513939877887,5.99563519459755,5.3414345245781405,5.423245873936808,5.562292864456475,5.243038048686294,5.738780558484369,5.243038048686294,5.650793039651931,5.795880017344075,5.829303772831025,5.841984804590114,5.638489256954637,5.469822015978163,5.342422680822207,5.681241237375588,5.841984804590114,6.299942900022767,5.096910013008056,5.361727836017593,5.57978359661681,5.556302500767287,5.359835482339888,5.6674529528899535,5.484299839346786,5.176091259055681,5.143014800254095,5.498310553789601,5.296665190261531,4.544068044350276,5.883661435153617,5.460897842756548,5.57172746066306,5.694605198933568,5.361727836017593,6.141449773400467,5.648360010980932,5.517195897949974,5.54282542695918,5.9003671286564705,5.60151678365001,5.276461804173244,5.378397900948138,5.290034611362518,5.389166084364533,5.76715586608218,5.439332693830263,5.648360010980932,5.574031267727719,6.0700378666077555,5.778151250383644,6.173186268412274,5.731588765186738,5.252853030979893,5.201397124320452,5.77451696572855,5.217483944213907,4.99563519459755,5.845098040014257,6.555698894718901,5.243038048686294,5.342422680822207,6.060697840353612,5.652246341003323,5.648360010980932,6.021189299069938,5.838849090737256,5.622214022966295,5.203848463746235,5.359835482339888,5.113943352306837,5.565847818673518,5.99563519459755,6.439332693830263,5.518513939877887,5.76715586608218,5.161368002234975,5.469822015978163,5.54282542695918,5.45484486000851,5.732393759822968,5.190331698170292,5.176091259055681,5.477121254719663,5.599883072073688,5.252853030979893,5.176091259055681,5.5910646070264995,5.544068044350276,5.54282542695918,5.503790683057181,5.648360010980932,5.489958479424835,5.498310553789601,5.694605198933568,5.078819183098848,5.653212513775344,5.676693609624866,5.929418925714293,5.653212513775344,5.396199347095736,5.2405492482825995,5.431363764158987,5.676693609624866,5.041392685158225,6.397070549959409,5.596597095626461,5.694605198933568,5.54282542695918,5.204119982655925,5.997823080745725,5.342422680822207,5.863322860120456,5.445604203273597,5.889301702506311,5.585460729508501,5.267171728403014,5.2552725051033065,5.843855422623161,5.1303337684950066,4.951823035315912,5.633468455579586,5.69810054562339,5.7774268223893115,6.060697840353612,5.201397124320452,5.977723605288848,5.445604203273597,5.332438459915605,5.54282542695918,5.3404441148401185,5.54282542695918,5.361727836017593,5.977723605288848,5.672097857935717,5.562292864456475,5.633468455579586,6.146128035678238,5.396199347095736,6.4734869700645685,5.951823035315912,5.653212513775344,5.544068044350276,5.469822015978163,5.439332693830263,6.230448921378274,5.537819095073274,5.77451696572855,5.7626785637274365,6.371067862271736,5.611723308007342,5.5910646070264995,5.661812685537261,6.359835482339888,5.76715586608218,5.359835482339888,5.622214022966295,5.555094448578319,5.694605198933568,5.903089986991944,5.230448921378274,5.503790683057181,5.491361693834273,5.423245873936808,5.937016107464814,5.671172842715083,5.298853076409706,5.430558769522757,5.252853030979893,5.47567118832443,5.298853076409706,5.445604203273597,4.949390006644912,5.146128035678238,5.413299764081252,5.544068044350276,5.041392685158225,5.9003671286564705,5.638489256954637,5.361538971269279,5.4623979978989565,5.6674529528899535,5.254064452914338,5.173186268412274,5.652246341003323,5.928907690243952,5.565257343420214,5.812913356642856,5.378397900948138,5.77451696572855,5.217483944213907,5.54282542695918,5.413299764081252,5.565257343420214,5.511883360978874,5.694605198933568,5.690196080028514,5.47567118832443,5.544068044350276,5.378397900948138,5.596597095626461,5.69810054562339,5.699751031689514,5.6211762817750355,5.841359470454855,5.445604203273597,5.47567118832443,5.7774268223893115,5.841984804590114,5.562292864456475,5.685741738602264,5.489958479424835,5.652246341003323,5.829303772831025,5.951823035315912,5.396199347095736,5.911157608739977,5.298853076409706,5.578639209968072,5.1303337684950066,5.600972895686748,6.229169702539101,5.640481436970422,5.6006135561423145,5.173186268412274,5.7558748556724915,5.326335860928752,5.056904851336473,5.880813592280791,5.671172842715083,5.795880017344075,5.997823080745725,5.139879086401237,5.161368002234975,5.977723605288848,5.252853030979893,5.445604203273597,5.357934847000454,5.096910013008056,5.1303337684950066,5.47639682672533,5.652246341003323,5.596597095626461,5.556302500767287,5.658011396657113,5.376576957056512,5.6674529528899535,6.021189299069938,5.926856708949693,5.628388930050312,5.413299764081252,5.676693609624866,5.198657086954422,5.77451696572855,5.652246341003323,5.926856708949693,5.763427993562937,5.296665190261531,5.505149978319906,5.461648568063455,5.623249290397901,5.7160033436347994,5.2552725051033065,5.469822015978163,5.4065401804339555,5.552668216112194,5.8095597146352675,5.511883360978874,5.69810054562339,5.889301702506311,5.161368002234975,5.175801632848279,4.949390006644912,5.648360010980932,5.698752802790154,5.653202862679622,5.600972895686748,6.544068044350276,5.949390006644912,5.298853076409706,5.145817714491828,6.146128035678238,6.060697840353612,5.075546961392531,5.954242509439325,5.69810054562339,5.225309281725863,5.740362689494244,6.096910013008056,5.7596678446896306,5.872156272748293,5.469822015978163,5.431363764158987,5.600972895686748,5.648360010980932,5.9003671286564705,5.993436230497612,5.447158031342219,5.829303772831025,5.731588765186738,6.077367905284157,5.201397124320452,5.2405492482825995,5.562292864456475,5.54282542695918,5.298853076409706,5.585460729508501,6.112269768417271,5.652246341003323,5.658011396657113,5.99563519459755,5.396199347095736,5.711807229041191,5.76715586608218,5.394451680826216,6.161068385471174,5.857332496431268,5.845098040014257,5.378397900948138,5.652246341003323,5.739572344450092,5.060697840353612,6.031408464251625,5.8088858673598125,5.929418925714293,5.7363965022766426,5.694605198933568,5.574031267727719,5.389166084364533,5.525044807036846,5.096562438374136,5.5301996982030825,5.298853076409706,6.027349607774757,5.352182518111363,5.096910013008056,5.694605198933568,6.229169702539101,6.041392685158225,5.457881896733992,5.556302500767287,5.7160033436347994,5.075546961392531,5.423245873936808,5.731588765186738,5.505828033854836,5.7774268223893115,5.555094448578319,5.544068044350276,5.460897842756548,5.190331698170292,5.928907690243952,5.578639209968072,5.47567118832443,5.8095597146352675,5.352182518111363,5.623249290397901,5.413299764081252,5.227886704613674,5.469822015978163,4.897627091290442,5.874481817699467,5.672097857935717,5.371067862271736,5.685741738602264,5.380211241711606,5.676693609624866,5.060697840353612,5.077367905284157,5.212187604403958,5.041392685158225,5.041392685158225,5.911157608739977,5.290034611362518,5.252853030979893,5.676693609624866,5.389166084364533,5.446381812222442,5.620656479819621,5.190331698170292,6.201397124320452,5.47567118832443,5.203848463746235,5.653212513775344,5.474216264076255,5.740361899867195,5.47567118832443,5.748188027006201,5.469822015978163,5.5910646070264995,5.469822015978163,6.071882007306125,6.201397124320452,5.075546961392531,5.54282542695918,5.361727836017593,5.3222192947339195,5.4048337166199385,5.352182518111363,5.977266212427293,5.919078092376074,4.949390006644912,5.290034611362518,5.7923916894982534,5.562292864456475,5.866287339084195,5.77451696572855,5.2552725051033065,5.77451696572855,6.273001272063738,5.69810054562339,5.841984804590114,5.434568904034199,5.812913356642856,5.755112266395071,5.175801632848279,5.661812685537261,5.389166084364533,5.552668216112194,5.278753600952829,5.320146286111054,5.396199347095736,5.954242509439325,5.694605198933568,5.267171728403014,6.295567099962479,5.676693609624866,5.243038048686294,6.173186268412274,5.139879086401237,5.3404441148401185,5.77451696572855,5.298853076409706,5.176091259055681,5.3414345245781405,5.7363965022766426,5.600972895686748,5.672097857935717,5.175801632848279,5.652246341003323,5.599883072073688,5.096910013008056,4.903089986991944,5.1303337684950066,5.352182518111363,4.874481817699467,5.601951404133522,6.296665190261531,5.217483944213907,5.294466226161593,5.525044807036846,5.45484486000851,5.854306041801081,5.484299839346786,6.171726453653231,5.600972895686748,5.574031267727719,5.396199347095736,5.298853076409706,5.466867620354109,5.110589710299249,5.812913356642856,5.9003671286564705,5.429752280002408,6.276461804173244,5.611723308007342,5.954242509439325,5.99563519459755,5.359835482339888,5.396199347095736,5.252853030979893,5.6464037262230695,5.6674529528899535,5.984527313343793,5.748188027006201,5.4623979978989565,5.505149978319906,6.173186268412274,6.174641192660449,5.112269768417271,6.319896858814888,6.266936911159173,5.113943352306837,5.491361693834273,5.676693609624866,5.4065401804339555,5.599883072073688,5.2552725051033065,5.060697840353612,5.599883072073688,5.505149978319906,5.826074802700826,5.45484486000851,5.332438459915605,5.752048447819439,4.949390006644912,5.217483944213907,5.460897842756548,5.694605198933568,5.3979400086720375,5.997823080745725,5.423245873936808,6.250420002308894,5.359835482339888,6.254064452914338,5.997823080745725,5.658011396657113,5.7160033436347994,6.544068044350276,5.389166084364533,5.096910013008056,5.567026366159061,6.077367905284157,5.544068044350276,5.7596678446896306,5.578639209968072,6.430558769522757,5.715167357848458,5.599883072073688,5.596597095626461,5.47567118832443,5.616107757092463,6.175801632848279,5.841984804590114,5.632457292184724,5.396199347095736,5.505149978319906,5.469822015978163,5.290034611362518,5.7774268223893115,5.380211241711606,5.7774268223893115,5.550228353055094,6.469822015978163,5.445604203273597,5.812244696800369,5.77451696572855,5.1303337684950066,6.217483944213907,5.652246341003323,5.585460729508501,5.505149978319906,5.396199347095736,5.9164539485499255,5.380211241711606,5.060697840353612,5.6020589055904,5.653212513775344,5.144574207609616,5.54282542695918,5.622214022966295,5.477121254719663,5.290034611362518,6.060697840353612,5.829303772831025,5.9003671286564705,5.77451696572855,5.342422680822207,5.707570176097937,5.460897842756548,5.623249290397901,5.173186268412274,5.600972895686748,5.623249290397901,5.439332693830263,5.429752280002408,5.52244423350632,5.252853030979893,5.672097857935717,5.650307523131937,5.694605198933568,5.589949601325708,5.585460729508501,5.694605198933568,5.1303337684950066,5.300812794118117,5.795880017344075,5.243038048686294,5.997823080745725,5.600972895686748,5.812913356642856,5.69810054562339,5.694605198933568,5.445604203273597,5.173186268412274,5.158362492095249,5.829303772831025,5.45484486000851,5.252853030979893,5.060697840353612,5.187520720836463,5.4769764657595275,5.600972895686748,5.574031267727719,5.68930885912362,5.785329835010767,5.276461804173244,5.517195897949974,5.680335513414564,5.217483944213907,5.694605198933568,5.556302500767287,5.752240571017397,6.254064452914338,5.439332693830263,5.623249290397901,5.628388930050312,5.9003671286564705,5.54282542695918,5.503790683057181,5.445604203273597,5.298853076409706,5.894869656745253,5.352182518111363,4.929418925714293,5.633468455579586,5.8750612633917,5.627365856592733,5.69810054562339,5.913813852383717,4.889301702506311,5.835690571492425,5.841984804590114,5.913813852383717,5.643452676486188,5.795880017344075,5.600972895686748,5.146128035678238,5.54282542695918,5.694605198933568,5.748188027006201,5.919078092376074,5.650793039651931,5.672097857935717,6.1702617153949575,5.942008053022313,5.45484486000851,5.503790683057181,5.8444771757456815,5.812913356642856,5.929418925714293,5.7558748556724915,5.567026366159061,5.298853076409706,5.872156272748293,5.176091259055681,5.770852011642144,5.977723605288848,6.3414345245781405,5.378397900948138,5.243038048686294,5.555094448578319,5.161368002234975,5.9661417327390325,5.835690571492425,5.139879086401237,5.47567118832443,6.290034611362518,5.3222192947339195,6.096910013008056,5.5301996982030825,5.799340549453582,5.525044807036846,6.079181246047625,5.352182518111363,5.5439439424829065,5.201397124320452,5.4623979978989565,5.643452676486188,5.041392685158225,5.445604203273597,5.6127838567197355,5.45484486000851,5.352182518111363,5.276461804173244,5.173186268412274,6.254064452914338,6.3222192947339195,5.841984804590114,6.469822015978163,5.3414345245781405,5.230448921378274,5.267171728403014,5.585460729508501,5.648360010980932,5.110589710299249,5.204119982655925,5.954242509439325,5.505149978319906,5.596597095626461,5.913813852383717,5.201397124320452,6.278753600952829,5.567026366159061,5.477121254719663,5.544068044350276,5.8095597146352675,5.252853030979893,5.143014800254095,5.145817714491828,6.229169702539101,5.460897842756548,5.298853076409706,5.997823080745725,5.724275869600789,6.3404441148401185,6.060697840353612,5.173186268412274,5.311753861055754,5.56466606425209,6.45484486000851,5.311753861055754,5.298853076409706,5.414973347970818,5.770852011642144,5.652246341003323,5.229169702539101,5.69810054562339,5.993436230497612,5.350248018334163,5.694605198933568,5.841984804590114,5.623249290397901,5.676693609624866,5.267171728403014,5.596597095626461,5.628388930050312,5.585460729508501,5.740362689494244,5.511883360978874,5.110589710299249,5.739572344450092,5.694605198933568,5.977266212427293,5.54282542695918,5.829303772831025,5.201397124320452,5.585460729508501,5.6180480967120925,5.252853030979893,6.143014800254095,5.525044807036846,5.9164539485499255,5.949390006644912,5.585460729508501,5.9003671286564705,5.1303337684950066,5.1303337684950066,5.469822015978163,5.243038048686294,5.947923619831727,5.378397900948138,5.096910013008056,5.740362689494244,5.5938396610812715,5.423245873936808,5.7363965022766426,5.531478917042255,6.76715586608218,5.680335513414564,5.173186268412274,5.4623979978989565,5.267171728403014,5.47567118832443,6.143014800254095,5.276461804173244,6.30015944903796,6.017033339298781,5.187520720836463,5.897627091290442,5.332438459915605,5.227886704613674,5.146128035678238,6.229169702539101,5.653212513775344,6.19728055812562,5.2552725051033065,5.54282542695918,5.99563519459755,5.371067862271736,5.662757831681574,5.926856708949693,5.596597095626461,5.173186268412274,5.498310553789601,5.252853030979893,5.3404441148401185,5.77451696572855,5.642464520242122,5.176091259055681,5.574031267727719,6.021189299069938,5.460897842756548,5.574031267727719,5.829303772831025,5.477121254719663,5.503790683057181,5.812913356642856,5.498310553789601,5.676693609624866,5.47567118832443,5.252853030979893,5.81888541459401,5.860338006570994,5.343408593803857,5.997823080745725,5.359835482339888,5.511214701136388,5.469822015978163,5.276461804173244,5.173186268412274,5.7283537820212285,5.352182518111363,5.445604203273597,5.298853076409706,6.096910013008056,5.6674529528899535,5.176091259055681,5.676693609624866,6.112269768417271,6.1303337684950066,5.544068044350276,5.600972895686748,5.431363764158987,5.841984804590114,6.47639682672533,6.096562438374136,5.439332693830263,5.598790506763115,5.075546961392531,5.929418925714293,5.4065401804339555,5.175801632848279,5.110589710299249,5.642464520242122,6.60151678365001,5.653212513775344,5.4065401804339555,5.45484486000851,6.144574207609616,5.795880017344075,5.4623979978989565,5.9003671286564705,5.54282542695918,5.9614210940664485,5.681241237375588,5.110589710299249,5.628388930050312,4.977723605288848,6.077367905284157,5.439332693830263,5.841984804590114,5.173186268412274,5.77451696572855,5.690196080028514,5.889301702506311,5.574031267727719,5.5301996982030825,6.371067862271736,5.298853076409706,5.298853076409706,5.73538888670613,5.7363965022766426,5.568201724066995,6.039414119176137,5.227886704613674,5.69810054562339,5.278753600952829,5.243038048686294,5.332438459915605,5.544068044350276,5.7558748556724915,5.8095597146352675,5.210853365314893,5.359835482339888,5.144574207609616,5.829303772831025,5.694605198933568,5.633468455579586,5.841984804590114,5.505149978319906,5.276461804173244,6.290034611362518,5.9003671286564705,6.277609214304091,5.54282542695918,5.54282542695918,5.975431808509263,5.77451696572855,5.517195897949974,5.537819095073274,5.8095597146352675,5.423245873936808,5.423245873936808,5.389166084364533,5.3979400086720375,6.027349607774757,4.99563519459755,5.894869656745253,5.69810054562339,5.518513939877887,5.977266212427293,6.060697840353612,5.47567118832443,5.838849090737256,5.396199347095736,5.714329759745233,5.469822015978163,5.352182518111363,5.600972895686748,5.574031267727719,4.838849090737256,5.301029995663981,5.623249290397901,5.926856708949693,5.720159303405957,5.230448921378274,5.7283537820212285,5.6180480967120925,5.585460729508501,5.429752280002408,5.342422680822207,5.681241237375588,5.430558769522757,5.243038048686294,5.2027606873932,5.431363764158987,5.977266212427293,5.173186268412274,6.3979400086720375,5.1303337684950066,5.204119982655925,5.897627091290442,5.371067862271736,5.685741738602264,5.361727836017593,4.897627091290442,5.628388930050312,6.060697840353612,5.413299764081252,5.676693609624866,5.680335513414564,5.77451696572855,5.423245873936808,5.414973347970818,5.342422680822207,5.3979400086720375,5.975431808509263,5.694605198933568,5.531478917042255,5.939019776448666,5.359835482339888,5.1303337684950066,5.951823035315912,5.469822015978163,5.378397900948138,5.681241237375588,5.9003671286564705,5.361727836017593,5.598790506763115,5.685741738602264,5.176091259055681,5.599883072073688,5.694605198933568,6.133538908370218,5.662757831681574,5.511883360978874,5.361727836017593,5.252853030979893,5.243038048686294,5.320146286111054,5.243038048686294,5.6020589055904,5.39776625612645,5.378397900948138,5.47567118832443,5.252853030979893,5.6674529528899535,5.113943352306837,5.173186268412274,5.829303772831025,5.214843848047698,5.975431808509263,5.8095597146352675,6.110589710299249,6.296665190261531,5.45484486000851,5.600972895686748,5.418301291319746,5.517195897949974,5.949390006644912,5.511883360978874,5.332438459915605,6.299942900022767,5.7774268223893115,5.537819095073274,5.599883072073688,5.243038048686294,5.298853076409706,5.7923916894982534,6.0,5.623249290397901,5.740362689494244,5.872156272748293,5.781755374652469,5.596597095626461,5.371067862271736,6.439332693830263,5.6950436588212945,5.6127838567197355,6.201397124320452,6.491361693834273,5.648360010980932,5.359835482339888,5.359835482339888,5.146128035678238,5.567026366159061,5.252853030979893,5.7363965022766426,5.883661435153617,5.902546779313991,5.378397900948138,5.161068385471174,6.36078268987328,5.47567118832443,5.977723605288848,5.7774268223893115,5.378397900948138,5.658011396657113,5.7596678446896306,6.380211241711606,5.8095597146352675,5.638489256954637,5.217483944213907,5.037426497940624,6.227886704613674,5.517195897949974,5.739572344450092,5.874481817699467,6.112269768417271,5.812846536967071,4.999565488225982,5.7626785637274365,5.3404441148401185,5.568201724066995,5.350248018334163,5.685293781386784,5.342422680822207,5.243038048686294,5.600972895686748,5.662757831681574,5.975431808509263,5.544068044350276,5.161368002234975,6.653212513775344,5.267171728403014,5.096910013008056,6.112269768417271,5.544068044350276,5.7363965022766426,6.342422680822207,5.110589710299249,6.060697840353612,5.812913356642856,5.298853076409706,5.049218022670182,5.948901760970213,5.589949601325708,5.517195897949974,5.505149978319906,4.929418925714293,5.423245873936808,5.201397124320452,5.332438459915605,5.5910646070264995,6.921686475483602,5.1003705451175625,5.744292983122676,5.515634121156461,5.628388930050312,5.3404441148401185,5.359835482339888,5.469822015978163,5.544068044350276,5.880813592280791,5.158362492095249,5.9164539485499255,5.68930885912362,5.837588438235511,5.77451696572855,5.096910013008056,6.161368002234975,6.112269768417271,5.517195897949974,5.429752280002408,5.7283537820212285,5.758911892397974,6.20002926655377,5.642464520242122,6.3414345245781405,5.537819095073274,5.429752280002408,5.672097857935717,5.685741738602264,5.929418925714293,5.550228353055094,5.45484486000851,5.770852011642144,5.443575879750258,5.469822015978163,5.811575005870593,5.694605198933568,5.301029995663981,5.3222192947339195,5.217483944213907,5.267171728403014,5.3222192947339195,5.3404441148401185,5.5301996982030825,5.778151250383644,5.5301996982030825,5.600972895686748,5.4281347940287885,5.201397124320452,5.62314587463794,6.176091259055681,5.7619278384205295,5.474216264076255,5.146128035678238,5.531478917042255,6.096910013008056,5.832508912706237,5.968482948553935,5.439332693830263,5.57978359661681,5.469822015978163,5.477121254719663,5.7596678446896306,5.041392685158225,5.600972895686748,5.567026366159061,5.2552725051033065,5.896526217489555,5.724275869600789,5.7596678446896306,6.105510184769974,5.567026366159061,5.08278537031645,5.298853076409706,5.276461804173244,5.108903127667313,5.755112266395071,5.447158031342219,5.096910013008056,5.825426117767823,5.628388930050312,5.77451696572855,5.267171728403014,5.491361693834273,5.414806279501013,5.707570176097937,6.060697840353612,5.460897842756548,6.298853076409706,5.380211241711606,5.977723605288848,5.949390006644912,6.201397124320452,5.582327042848944,5.929418925714293,5.447158031342219,5.45484486000851,5.6148972160331345,5.740362689494244,5.447158031342219,5.096910013008056,5.229169702539101,5.47639682672533,6.2041197112217885,5.190331698170292,5.201397124320452,5.146128035678238,5.389166084364533,6.544068044350276,5.784617292632875,5.829303772831025,5.217483944213907,5.841984804590114,5.585460729508501,5.243038048686294,5.225309281725863,5.161368002234975,6.039414119176137,5.298853076409706,5.812244696800369,5.143014800254095,5.897627091290442,5.9614210940664485,5.3222192947339195,5.350248018334163,5.951823035315912,5.439332693830263,5.769377326076138,5.681241237375588,5.227886704613674,5.77451696572855,5.5918700883362344,5.267171728403014,5.799340549453582,5.423245873936808,6.060697840353612,5.628388930050312,5.396199347095736,5.396199347095736,5.628388930050312,5.6875289612146345,5.544068044350276,5.227886704613674,5.311753861055754,5.47567118832443,5.376576957056512,5.096910013008056,5.429752280002408,5.671172842715083,5.161368002234975,5.9003671286564705,5.829303772831025,5.69810054562339,5.47567118832443,6.252853030979893,5.841984804590114,5.3404441148401185,5.812913356642856,5.460897842756548,6.290034611362518,5.460897842756548,5.413299764081252,5.6020599913279625,5.926856708949693,5.694605198933568,5.685741738602264,5.498310553789601,6.212187604403958,5.632457292184724,5.627365856592733,5.8055008581584,5.894869656745253,5.585460729508501,6.021189299069938,5.929418925714293,5.653212513775344,5.7664128471124,5.6180480967120925,5.252853030979893,5.7596678446896306,5.872156272748293,5.437750562820388,6.105510184769974,5.963787827345556,5.1303337684950066,5.477121254719663,5.371067862271736,5.414973347970818,5.510545010206612,5.511883360978874,5.518513939877887,5.161368002234975,5.413299764081252,5.342422680822207,5.54282542695918,6.276461804173244,5.173186268412274,5.414137362184476,5.439332693830263,5.388988785124714,5.332438459915605,5.243038048686294,6.079181246047625,4.903089986991944,5.110589710299249,5.359835482339888,5.517195897949974,5.423245873936808,5.951823035315912,5.267171728403014,5.7596678446896306,5.301029995663981,6.805840548814673,5.252853030979893,5.298853076409706,5.230448921378274,5.57978359661681,5.69810054562339,5.447158031342219,5.770115294787102,5.8444771757456815,5.173186268412274,5.938519725176492,5.8061799739838875,5.511883360978874,5.596597095626461,5.6127838567197355,5.45484486000851,5.541579243946581,5.84323277809801,5.204119982655925,5.600972895686748,5.633468455579586,5.648360010980932,5.3979400086720375,5.041392685158225,5.802773725291976,5.267171728403014,5.556302500767287,5.176091259055681,5.320146286111054,5.679427896612119,5.439332693830263,5.997823080745725,5.201397124320452,5.880813592280791,5.574031267727719,5.531478917042255,5.204119982655925,5.445604203273597,6.607455023214668,5.600972895686748,5.040997692423491,5.5301996982030825,5.676693609624866,5.518513939877887,6.0603200286882855,5.352182518111363,5.447158031342219,5.574031267727719,6.216165902285993,5.041392685158225,5.161368002234975,5.431363764158987,5.989004615698537,5.413299764081252,6.414137362184476,5.510545010206612,5.697229342759718,5.2405492482825995,5.143014800254095,5.841984804590114,5.217483944213907,5.227886704613674,5.652246341003323,5.489958479424835,5.201397124320452,5.723455672035186,5.652246341003323,5.298853076409706,5.474216264076255,5.600972895686748,6.217483944213907,5.902546779313991,5.921686475483602,5.161368002234975,5.719331286983727,5.638489256954637,5.375663613960885,5.204119982655925,4.991226075692495,6.201397124320452,5.469822015978163,5.913813852383717,5.190331698170292,5.835690571492425,5.5301996982030825,5.8750612633917,5.173186268412274,5.574030109607556,6.210853365314893,4.99563519459755,4.929418925714293,5.371067862271736,5.537819095073274,5.174641192660449,5.6180480967120925,5.243038048686294,5.380211241711606,5.544068044350276,5.146128035678238,6.060697840353612,5.694605198933568,5.275311354541811,5.230448921378274,5.187520720836463,5.1303337684950066,5.396199347095736,5.45484486000851,5.64738297011462,5.903089986991944,5.54282542695918,5.894869656745253,6.153814864344529,6.019116290447073,5.632457292184724,5.517195897949974,5.143014800254095,5.977723605288848,5.204119982655925,5.951823035315912,5.477121254719663,5.544068044350276,5.477121254719663,6.021189299069938,6.105510184769974,5.276461804173244,5.3979400086720375,5.54282542695918,5.110589710299249,5.037426497940624,5.332438459915605,5.517195897949974,5.217483944213907,6.295567099962479,5.755112266395071,6.089905111439398,5.445604203273597,5.389166084364533,5.2552725051033065,5.740362689494244,5.872156272748293,5.342422680822207,5.970811610872518,5.7923916894982534,5.997823080745725,4.982271233039568,5.874481817699467,5.267171728403014,5.8750612633917,5.841984804590114,5.565847818673518,5.173186268412274,5.173186268412274,5.439332693830263,5.332438459915605,5.175801632848279,5.469822015978163,5.423245873936808,5.47639682672533,5.544068044350276,5.845035993513415,5.525044807036846,5.812913356642856,5.628388930050312,5.6512780139981444,5.9003671286564705,5.652246341003323,5.250420002308894,5.5301996982030825,6.161368002234975,5.9003671286564705,5.096910013008056,6.039414119176137,5.600972895686748,5.342422680822207,5.720159303405957,5.3404441148401185,5.7160033436347994,5.217483944213907,5.227886704613674,5.332438459915605,5.8095597146352675,5.7363965022766426,5.929418925714293,5.600972895686748,5.622214022966295,5.931966114728173,4.903089986991944,5.555094448578319,5.8750612633917,5.544068044350276,5.680335513414564,5.57978359661681,5.7774268223893115,5.697229342759718,5.661812685537261,5.662757831681574,6.054995861529141,5.276461804173244,5.77451696572855,5.252853030979893,5.359835482339888,5.298853076409706,5.423245873936808,5.469822015978163,5.3414345245781405,5.396199347095736,6.176091259055681,5.866287339084195,5.447158031342219,5.672005445022952,5.515634121156461,5.951823035315912,5.54282542695918,5.326335860928752,5.469822015978163,5.54282542695918,5.989004615698537,5.795880017344075,5.7160033436347994,5.190331698170292,6.054995861529141,5.658011396657113,5.47567118832443,5.857332496431268,6.267171728403014,5.45484486000851,5.447158031342219,5.021189299069938,5.173186268412274,5.041392685158225,5.562292864456475,5.113609151073028,5.928907690243952,5.54282542695918,5.389166084364533,5.518513939877887,5.653212513775344,5.574031267727719,5.428944290035575,5.9003671286564705,5.161368002234975,4.929418925714293,5.298853076409706,5.47567118832443,5.429752280002408,5.720159303405957,6.077367905284157,5.600972895686748,5.45484486000851,5.176091259055681,5.143014800254095,5.472756449317212,5.6674529528899535,5.680335513414564,5.628388930050312,5.332438459915605,5.567026366159061,5.498310553789601,5.396199347095736,5.176091259055681,5.600972895686748,5.600972895686748,5.600972895686748,5.267171728403014,5.662757831681574,6.36078268987328,5.829303772831025,5.143014800254095,5.860338006570994,5.6180480967120925,5.250420002308894,5.445604203273597,5.365487984890899,5.829303772831025,6.1126050015345745,5.3222192947339195,5.474216264076255,5.525044807036846,6.469822015978163,5.997823080745725,5.755112266395071,5.517195897949974,5.7774268223893115,6.102090525511836,5.36078268987328,5.567026366159061,5.45484486000851,5.371067862271736,5.8444771757456815,4.8750612633917,5.562292864456475,5.833784374656479,5.942008053022313,5.201397124320452,5.474216264076255,5.469822015978163,5.143014800254095,5.277609214304091,5.611723308007342,5.267171728403014,5.652246341003323,6.469822015978163,5.8750612633917,5.770852011642144,5.143014800254095,5.585460729508501,5.590507462008583,6.077367905284157,5.505149978319906,6.096910013008056,5.389166084364533,5.6020599913279625,5.352182518111363,5.267171728403014,6.342422680822207,6.1003705451175625,5.47567118832443,5.301029995663981,5.429752280002408,5.829303772831025,5.54282542695918,5.720159303405957,5.173186268412274,5.653212513775344,5.638489256954637,5.445604203273597,5.175801632848279,5.653212513775344,5.68930885912362,5.937016107464814,6.220108088040055,6.628388930050312,5.617000341120899,5.161368002234975,5.267171728403014,6.096910013008056,5.342422680822207,5.7923916894982534,6.230448921378274,5.267171728403014,5.9003671286564705,5.795880017344075,5.217483944213907,5.69810054562339,5.623249290397901,5.770852011642144,5.661812685537261,5.518513939877887,5.628388930050312,5.47567118832443,5.413299764081252,5.630427875025024,5.788875115775417,5.883661435153617,5.77451696572855,5.739572344450092,5.276461804173244,5.568201724066995,5.541579243946581,5.841984804590114,5.414973347970818,5.190331698170292,5.4623979978989565,5.320146286111054,5.54282542695918,5.3222192947339195,5.600972895686748,5.6674529528899535,5.474216264076255,5.589949601325708,5.8750612633917,5.544068044350276,5.47567118832443,5.676693609624866,5.54282542695918,5.977723605288848,6.190331698170292,5.301029995663981,5.1303337684950066,5.361727836017593,5.585460729508501,6.079181246047625,5.707570176097937,5.276461804173244,5.544068044350276,5.77451696572855,5.7923916894982534,5.989004615698537,5.676693609624866,5.173186268412274,5.874481817699467,5.176091259055681,5.47567118832443,5.685741738602264,5.574031267727719,5.719331286983727,5.953759691733229,5.298853076409706,5.252853030979893,5.652246341003323,5.39776625612645,6.144574207609616,5.77451696572855,5.596597095626461,5.628388930050312,5.252853030979893,5.69810054562339,5.060697840353612,5.460897842756548,5.8444771757456815,4.99563519459755,5.5301996982030825,5.47567118832443,5.7774268223893115,5.201397124320452,5.578639209968072,5.872156272748293,6.278753600952829,5.596597095626461,5.161368002234975,5.4623979978989565,5.517195897949974,5.991226075692495,5.812913356642856,5.69810054562339,5.060697840353612,5.429752280002408,5.600972895686748,5.3979400086720375,5.993436230497612,5.638489256954637,5.378397900948138,5.396199347095736,5.531478917042255,5.47567118832443,5.860338006570994,5.816241299991783,5.889301702506311,6.439332693830263,5.681241237375588,6.077367905284157,5.3404441148401185,5.8750612633917,5.590953235187985,5.556302500767287,5.525044807036846,5.396199347095736,5.732480610034617,5.578639209968072,5.2027606873932,5.574031267727719,6.371067862271736,5.271841606536499,6.469822015978163,5.7283537820212285,5.90200289135073,5.928907690243952,5.3404441148401185,4.897627091290442,5.602005701124516,5.926856708949693,5.7160033436347994,5.460897842756548,5.9237619608287,5.267171728403014,6.168792020314182,5.763427993562937,5.47567118832443,6.290034611362518,5.218797998111738,5.278753600952829,5.159867847092567,5.230193378869045,5.530839778616521,5.841984804590114,5.574031267727719,5.352182518111363,6.73996769675951,5.954242509439325,5.617157665694944,6.095169351431755,5.3404441148401185,5.642464520242122,6.112269768417271,5.632457292184724,5.73996769675951,5.469822015978163,5.264817823009537,5.676693609624866,5.567026366159061,5.350248018334163,5.88309335857569,5.361727836017593,5.204119982655925,5.3979400086720375,5.290034611362518,5.446847710155809,5.439332693830263,5.638489256954637,5.371067862271736,5.959041392321094,5.57978359661681,5.439332693830263,5.511883360978874,5.47639682672533,5.491361693834273,5.460897842756548,5.075546961392531,5.649334858712142,5.173186268412274,5.6674529528899535,5.574031267727719,5.953759691733229,5.321184027302314,5.2405492482825995,6.243038048686294,5.204119982655925,5.290034611362518,5.902546779313991,5.719289844693328,5.477121254719663,5.371067862271736,4.8750612633917,5.439332693830263,6.112269768417271,5.578639209968072,5.841984804590114,5.770115294787102,5.889301702506311,5.653212513775344,6.2552725051033065,5.298853076409706,5.217483944213907,5.511883360978874,5.267171728403014,5.7774268223893115,5.503790683057181,5.54282542695918,5.567026366159061,5.6127838567197355,5.371067862271736,5.352182518111363,5.146128035678238,5.559308010907013,5.694605198933568,5.176091259055681,5.880813592280791,5.648360010980932,5.8750612633917,6.039414119176137,5.161368002234975,5.926856708949693,5.7558748556724915,5.517195897949974,5.8512583487190755,6.273001272063738,5.977266212427293,5.77451696572855,5.041392685158225,5.568201724066995,5.332438459915605,5.671172842715083,5.552668216112194,5.146128035678238,5.662757831681574,6.174641192660449,5.589949601325708,5.977723605288848,5.589949601325708,5.517195897949974,5.902546779313991,5.6127838567197355,4.951823035315912,5.991226075692495,5.841984804590114,5.812913356642856,5.631443769013172,5.298853076409706,5.6527296960692475,5.469822015978163,5.644241585843728,5.342422680822207,5.498310553789601,5.652246341003323,5.857332496431268,6.47639682672533,5.544068044350276,5.715167357848458,5.698970004336019,5.252853030979893,5.47567118832443,5.671172842715083,5.389166084364533,5.951823035315912,5.096910013008056,5.176091259055681,5.77451696572855,5.190331698170292,5.578639209968072,5.173186268412274,5.7774268223893115,5.413299764081252,5.469822015978163,5.05307844348342,5.69810054562339,5.352182518111363,5.690196080028514,5.68930885912362,5.7596678446896306,5.589949601325708,5.4623979978989565,5.711807229041191,5.378397900948138,5.224014811372864,5.6180480967120925,5.255031163345551,5.056904851336473,5.361727836017593,5.517195897949974,5.841984804590114,5.623249290397901,5.77451696572855,5.720159303405957,5.841984804590114,5.835690571492425,5.596597095626461,6.439332693830263,5.574031267727719,6.299942900022767,6.6429588794097905,5.841984804590114,5.661812685537261,5.596597095626461,5.45484486000851,5.375663613960885,6.276461804173244,5.252853030979893,5.9003671286564705,5.252853030979893,5.989004615698537,5.975431808509263,5.544068044350276,5.724275869600789,5.361727836017593,5.174641192660449,5.3222192947339195,5.429752280002408,5.6020599913279625,5.652246341003323,5.590199611519773,5.825426117767823,6.0,5.447158031342219,5.3979400086720375,5.496929648073215,5.557507201905658,5.3404441148401185,5.959041392321094,5.671172842715083,5.290034611362518,5.825426117767823,5.444044795918076,5.378397900948138,5.9003671286564705,4.812913356642856,5.672097857935717,5.113943352306837,5.690196080028514,5.929418925714293,5.596597095626461,5.056904851336473,5.378397900948138,5.607455023214668,5.628388930050312,5.298853076409706,5.278753600952829,6.292256071356476,5.676693609624866,5.298853076409706,6.290034611362518,5.201397124320452,5.489958479424835,5.568201724066995,5.201397124320452,5.892094602690481,5.989004615698537,5.110589710299249,4.949390006644912,6.707570176097937,5.628388930050312,5.517195897949974,4.99563519459755,5.672559627763276,5.060697840353612,5.568201724066995,5.694605198933568,5.740362689494244,5.770852011642144,5.113609151073028,5.6020599913279625,5.313867220369153,5.146128035678238,5.685741738602264,5.203848463746235,6.292256071356476,5.903089986991944,5.505149978319906,5.841984804590114,5.47567118832443,5.812913356642856,5.47567118832443,5.460897842756548,5.628388930050312,6.012837224705172,5.5434471800817,5.720159303405957,4.977723605288848,5.951823035315912,5.413299764081252,5.926856708949693,5.429752280002408,5.76715586608218,5.929418925714293,5.45484486000851,5.903089986991944,5.62314587463794,5.653212513775344,5.889301702506311,5.252853030979893,5.096910013008056,5.544068044350276,5.570542939881897,6.389166084364533,5.250420002308894,5.69810054562339,6.0,5.7774268223893115,5.6523430550627145,6.096910013008056,5.57978359661681,5.628388930050312,5.352182518111363,5.1303337684950066,5.447158031342219,5.929418925714293,5.54282542695918,5.396199347095736,5.970811610872518,5.854306041801081,5.359835482339888,5.45484486000851,5.5843312243675305,5.600972895686748,6.037426497940624,5.841984804590114,6.173186268412274,5.57287160220048,5.544068044350276,5.550228353055094,5.57978359661681,5.1003705451175625,5.359835482339888,5.977723605288848,5.423245873936808,5.600972895686748,5.45484486000851,5.204119982655925,5.812913356642856,5.298853076409706,5.850190875527597,5.555094448578319,6.190331698170292,5.77451696572855,5.517195897949974,5.276461804173244,5.537819095073274,6.060697840353612,5.342422680822207,4.944482672150168,5.5301996982030825,5.638489256954637,5.555094448578319,5.924279286061882,5.8095597146352675,5.469822015978163,5.518513939877887,5.9164539485499255,6.041390711087912,5.7774268223893115,5.550228353055094,5.396199347095736,5.389166084364533,5.517195897949974,5.685741738602264,5.469822015978163,5.845098040014257,5.638489256954637,5.9003671286564705,6.168792020314182,5.359835482339888,5.7596678446896306,5.461648568063455,6.077367905284157,5.204119982655925,5.596597095626461,5.413299764081252,5.45484486000851,5.778151250383644,5.77451696572855,5.290034611362518,5.568201724066995,5.45484486000851,5.5301996982030825,5.361727836017593,5.770852011642144,5.371067862271736,5.5301996982030825,5.723455672035186,5.578639209968072,5.429752280002408,5.991226075692495,5.567026366159061,5.540329474790874,6.254064452914338,5.977723605288848,5.47567118832443,5.891537457672564,5.600972895686748,5.652246341003323,5.414973347970818,5.2027606873932,5.951823035315912,5.389166084364533,5.511883360978874,5.230448921378274,5.173186268412274,5.795880017344075,5.653212513775344,5.505149978319906,5.562292864456475,5.720159303405957,5.380030247967831,6.112269768417271,5.3414345245781405,5.928907690243952,5.230448921378274,5.7283537820212285,5.298853076409706,5.45484486000851,5.176091259055681,5.7363965022766426,5.740362689494244,5.332438459915605,5.643452676486188,6.174641192660449,5.795184589682424,5.445604203273597,5.596597095626461,6.041392685158225,5.243038048686294,5.396199347095736,5.503790683057181,5.561485397401995,5.596597095626461,5.661812685537261,5.568201724066995,5.926856708949693,5.378397900948138,5.380211241711606,5.812913356642856,5.9003671286564705,5.987666264926275,5.278753600952829,5.812913356642856,5.445604203273597,5.276461804173244,6.112269768417271,5.9003671286564705,5.600972895686748,5.552668216112194,5.755112266395071,5.8095597146352675,5.429752280002408,5.989004615698537,5.628388930050312,5.511214701136388,5.203848463746235,5.951823035315912,5.396199347095736,5.2027606873932,5.770852011642144,5.173186268412274,5.653212513775344,5.748188027006201,5.632457292184724,5.413299764081252,5.600972895686748,5.3222192947339195,5.510545010206612,5.301029995663981,5.437750562820388,5.812913356642856,5.47567118832443,5.896526217489555,5.359835482339888,5.8750612633917,5.243038048686294,5.4769764657595275,5.54282542695918,5.217483944213907,5.503790683057181,5.555094448578319,5.469822015978163,5.173186268412274,5.096910013008056,5.694605198933568,5.596597095626461,5.252853030979893,5.469822015978163,5.2552725051033065,6.2552725051033065,5.414973347970818,5.352182518111363,5.460897842756548,5.371067862271736,4.949390006644912,5.894869656745253,5.653212513775344,5.429752280002408,6.105510184769974,5.380211241711606,5.690196080028514,5.720159303405957,5.47639682672533,5.633468455579586,5.694605198933568,5.611723308007342,5.252853030979893,5.739572344450092,5.320146286111054,5.352182518111363,5.8444771757456815,5.690196080028514,6.60151678365001,5.778151250383644,5.7596678446896306,5.911157608739977,5.396199347095736,5.578639209968072,5.648360010980932,5.201397124320452,5.628388930050312,5.578639209968072,5.854306041801081,5.1303337684950066,5.173186268412274,5.531478917042255,5.57978359661681,5.243038048686294,5.389166084364533,6.73996769675951,4.99563519459755,6.146128035678238,5.880813592280791,5.977266212427293,5.352182518111363,5.201397124320452,4.903089986991944,5.628388930050312,5.47567118832443,5.2552725051033065,5.862727528317975,5.47567118832443,5.079181246047625,5.676693609624866,5.9003671286564705,5.748188027006201,5.894869656745253,5.537819095073274,5.47567118832443,5.361727836017593,5.460897842756548,5.5301996982030825,5.301029995663981,5.342422680822207,6.190331698170292,5.685741738602264,5.175801632848279,5.7363965022766426,5.389166084364533,6.6429588794097905,7.041392685158225,5.350248018334163,5.227886704613674,5.484299839346786,5.474216264076255,5.075546961392531,5.874481817699467,5.8061799739838875,5.77451696572855,5.385606273598312,5.567026366159061,5.740362689494244,5.469822015978163,5.298853076409706,5.276461804173244,5.161368002234975,5.6127838567197355,5.652246341003323,5.740362689494244,5.079181246047625,5.204119982655925,5.431202884556517,5.63748972951251,5.518513939877887,5.578639209968072,5.431202884556517,5.970811610872518,5.230193378869045,5.997823080745725,5.652246341003323,5.380211241711606,5.439332693830263,5.110589710299249,5.352182518111363,5.5044708624944185,6.201123897207379,5.278753600952829,5.7596678446896306,5.643452676486188,5.585460729508501,5.578639209968072,5.254064452914338,5.547774705387822,5.723455672035186,5.451018452155457,5.47567118832443,5.383815365980431,5.544068044350276,5.173186268412274,5.585460729508501,5.267171728403014,5.938519725176492,5.574031267727719,5.676693609624866,5.5910646070264995,5.143014800254095,5.69810054562339,5.601951404133522,5.173186268412274,5.113943352306837,5.537819095073274,5.342422680822207,5.447158031342219,5.874481817699467,5.997823080745725,5.951823035315912,5.585460729508501,4.954242509439325,5.146128035678238,5.505149978319906,5.227886704613674,5.525044807036846,6.138302698166282,5.173186268412274,5.332438459915605,6.079181246047625,5.585460729508501,5.2552725051033065,4.949390006644912,5.217483944213907,5.439332693830263,5.359835482339888,5.267171728403014,5.352182518111363,5.5910646070264995,5.3404441148401185,5.57978359661681,5.623249290397901,5.929418925714293,5.770115294787102,5.332438459915605,5.361727836017593,5.469822015978163,5.653212513775344,5.556302500767287,5.544068044350276,5.7363965022766426,5.671172842715083,5.894869656745253,5.252853030979893,6.19728055812562,5.230448921378274,5.841984804590114,5.173186268412274,5.45484486000851,5.299942900022767,5.525044807036846,5.997823080745725,5.921686475483602,5.136720567156407,5.300812794118117,5.252853030979893,6.544068044350276,5.439332693830263,5.739572344450092,5.173186268412274,5.350248018334163,5.396199347095736,5.8750612633917,5.6180480967120925,5.260071387985075,5.694605198933568,5.652246341003323,5.642464520242122,5.567026366159061,5.491361693834273,5.841984804590114,5.505149978319906,5.1303337684950066,5.514547752660286,5.951823035315912,6.4734869700645685,5.556302500767287,5.763427993562937,5.57978359661681,5.676693609624866,5.929418925714293,5.1303337684950066,5.6180480967120925,5.489958479424835,5.739572344450092,5.874481817699467,5.724275869600789,5.7596678446896306,5.531478917042255,5.76715586608218,5.531478917042255,5.632457292184724,5.549003262025788,5.474216264076255,5.68930885912362,5.720159303405957,5.45484486000851,6.079181246047625,5.265996370495079,5.949390006644912,5.812913356642856,5.378397900948138,5.929418925714293,5.096910013008056,6.292256071356476,5.6180480967120925,5.537819095073274,5.204119982655925,5.724275869600789,5.176091259055681,5.555094448578319,6.4623979978989565,5.3979400086720375,5.227886704613674,5.359835482339888,5.720159303405957,5.38738982633873,5.371067862271736,5.556302500767287,5.99563519459755,6.171726453653231,5.942008053022313,6.077367905284157,5.642464520242122,5.54282542695918,5.445604203273597,5.431363764158987,5.359835482339888,5.525044807036846,5.723455672035186,4.929418925714293,5.332438459915605,5.697229342759718,5.445604203273597,5.505149978319906,5.596597095626461,6.290034611362518,5.380211241711606,5.469822015978163,5.517195897949974,5.829303772831025,5.672097857935717,5.628388930050312,5.5301996982030825,5.76715586608218,5.217483944213907,5.812913356642856,5.423245873936808,5.676693609624866,5.396199347095736,5.903089986991944,5.585460729508501,5.511883360978874,5.841984804590114,5.378397900948138,6.201397124320452,5.060697840353612,5.423245873936808,6.021189299069938,5.623249290397901,5.1303337684950066,5.218797998111738,5.795880017344075,5.204119982655925,5.720159303405957,5.628388930050312,6.105510184769974,5.7774268223893115,5.744292983122676,5.243038048686294,5.3404441148401185,5.763427993562937,5.981818607170664,5.332438459915605,5.298853076409706,5.596597095626461,5.505149978319906,5.755112266395071,5.143014800254095,5.525044807036846,5.585460729508501,6.095169351431755,5.874481817699467,5.562292864456475,5.5301996982030825,5.110589710299249,5.190331698170292,5.54282542695918,5.190331698170292,5.298853076409706,5.201397124320452,5.653212513775344,5.600972895686748,5.632457292184724,5.872156272748293,5.562292864456475,6.243038048686294,5.037426497940624,5.47567118832443,5.812913356642856,5.574031267727719,5.642464520242122,5.187520720836463,5.567026366159061,6.439332693830263,5.243038048686294,5.623249290397901,5.77451696572855,5.9003671286564705,6.299942900022767,6.110589710299249,5.951823035315912,5.396199347095736,5.77451696572855,5.681241237375588,5.217483944213907,5.517195897949974,5.661812685537261,5.5439439424829065,5.361727836017593,6.342422680822207,5.763427993562937,5.738780558484369,5.628388930050312,5.977723605288848,5.648360010980932,5.217483944213907,5.517195897949974,5.9003671286564705,5.7363965022766426,5.3404441148401185,5.7160033436347994,5.3414345245781405,5.505149978319906,5.662757831681574,5.838219221907626,5.565696733446075,5.54282542695918,5.267171728403014,5.671172842715083,5.385606273598312,4.99563519459755,5.474216264076255,5.224014811372864,4.897627091290442,5.623249290397901,5.426511261364575,5.724275869600789,5.937016107464814,5.596597095626461,5.252853030979893,5.525044807036846,5.556302500767287,5.298853076409706,5.937016107464814,5.301029995663981,5.423245873936808,5.643452676486188,5.396199347095736,6.883661435153617,5.439332693830263,6.039414119176137,6.217483944213907,5.99563519459755,5.642464520242122,5.970811610872518,5.460897842756548,5.4623979978989565,5.672097857935717,6.144574207609616,5.589949601325708,5.600972895686748,5.578639209968072,6.73996769675951,5.596597095626461,5.874481817699467,5.190331698170292,5.060697840353612,5.841984804590114,5.511883360978874,5.47567118832443,5.423245873936808,5.276461804173244,5.3979400086720375,5.176091259055681,5.555094448578319,5.278753600952829,5.7923916894982534,5.989004615698537,5.911157608739977,6.414137362184476,5.544068044350276,5.556302500767287,5.831229693867063,5.537819095073274,5.648360010980932,5.574031267727719,5.143014800254095,5.812244696800369,5.638489256954637,5.515873843711679,5.720159303405957,6.439332693830263,5.544068044350276,4.949390006644912,5.122215878272827,5.731588765186738,5.57978359661681,5.230448921378274,5.254064452914338,5.396199347095736,5.942008053022313,5.720159303405957,5.173186268412274,5.739572344450092,5.469822015978163,5.544068044350276,5.562292864456475,5.389166084364533,5.510545010206612,5.770115294787102,5.511883360978874,5.841984804590114,5.217483944213907,5.190331698170292,5.173186268412274,5.503790683057181,5.648360010980932,5.600972895686748,5.243038048686294,5.110589710299249,5.596597095626461,5.951823035315912,5.53135116458306,5.951823035315912,5.928907690243952,5.378397900948138,5.8095597146352675,5.460897842756548,5.872156272748293,5.8095597146352675,5.217483944213907,5.346352974450639,5.685741738602264,5.974050902792877,6.146128035678238,5.143014800254095,5.740362689494244,5.628388930050312,6.146128035678238,5.371067862271736,5.989004615698537,5.559308010907013,5.176091259055681,5.7363965022766426,5.54282542695918,5.596597095626461,5.537819095073274,5.1303337684950066,5.599883072073688,5.380211241711606,5.590507462008583,5.217483944213907,5.474216264076255,5.652246341003323,5.413299764081252,6.469822015978163,5.56643749219507,5.47567118832443,6.174641192660449,5.278753600952829,5.841984804590114,5.396199347095736,5.628388930050312,5.243038048686294,5.2552725051033065,5.720159303405957,5.8512583487190755,5.795880017344075,5.739572344450092,5.799340549453582,5.204119982655925,5.652246341003323,5.47567118832443,5.648360010980932,5.243038048686294,5.748188027006201,5.352182518111363,5.707570176097937,5.190331698170292,5.875032309461098,5.2552725051033065,5.567026366159061,5.361727836017593,5.829303772831025,5.99563519459755,5.230448921378274,5.267171728403014,5.414973347970818,5.715167357848458,5.929418925714293,5.252853030979893,5.567026366159061,5.47567118832443,5.505149978319906,5.77451696572855,5.9003671286564705,5.681241237375588,5.929418925714293,5.439332693830263,5.544068044350276,5.874481817699467,5.643452676486188,5.3404441148401185,5.371067862271736,5.352182518111363,5.517195897949974,5.740362689494244,5.491361693834273,5.739572344450092,5.841984804590114,5.525044807036846,5.6674529528899535,5.720159303405957,5.217483944213907,5.230448921378274,5.556302500767287,5.5532760461371,5.69888313675259,5.697229342759718,5.47567118832443,6.144574207609616,5.997823080745725,5.929418925714293,5.653212513775344,5.379305517750582,5.653212513775344,5.468716471515473,5.633468455579586,5.951823035315912,5.477121254719663,5.267171728403014,5.60151678365001,5.556302500767287,5.690196080028514,5.748188027006201,5.739572344450092,5.113943352306837,5.740362689494244,6.071882007306125,5.54282542695918,6.589949601325708,5.928907690243952]
},
"mapping":{
"x":"cadastral_income",
"y":"living_area",
"fill":"price",
"size":"price"
},
"data_meta":{
"series_annotations":[{
"type":"float",
"column":"bedrooms"
},{
"type":"str",
"column":"state"
},{
"type":"str",
"column":"kitchen_type"
},{
"type":"float",
"column":"number_of_frontages"
},{
"type":"float",
"column":"toilets"
},{
"type":"str",
"column":"street"
},{
"type":"float",
"column":"lng"
},{
"type":"float",
"column":"primary_energy_consumption"
},{
"type":"float",
"column":"bathrooms"
},{
"type":"float",
"column":"yearly_theoretical_total_energy_consumption"
},{
"type":"float",
"column":"surface_of_the_plot"
},{
"type":"str",
"column":"building_condition"
},{
"type":"str",
"column":"city"
},{
"type":"float",
"column":"lat"
},{
"type":"float",
"column":"cadastral_income"
},{
"type":"float",
"column":"living_area"
},{
"type":"float",
"column":"price"
}]
},
"ggtitle":{
"text":"Assessing Potential Outliers",
"subtitle":" By employing the default parameters of LocalOutlierFactor, we've reduced our training set from 3660 instances to 3427.\n            This is expected to enhance our model's performance and its ability to generalize well to new data.\n            "
},
"guides":{
"x":{
"title":"Cadastral income (EUR)"
},
"y":{
"title":"Living area (m2)"
}
},
"theme":{
"plot_title":{
"face":"bold",
"size":15.0,
"blank":false
},
"plot_subtitle":{
"face":"italic",
"size":12.0,
"blank":false
}
},
"ggsize":{
"width":800.0,
"height":600.0
},
"kind":"plot",
"scales":[{
"aesthetic":"fill",
"scale_mapper_kind":"color_gradient",
"low":"#1a9641",
"high":"#d7191c"
}],
"layers":[{
"geom":"point",
"mapping":{
},
"show_legend":false,
"data_meta":{
},
"alpha":0.5,
"shape":21.0,
"stroke":0.5,
"data":{
}
}],
"metainfo_list":[],
"spec_id":"2"
};
               window.letsPlotCall(function() {
       
               var toolbar = null;
               var plotContainer = containerDiv;               
               
                   var options = {
                       sizing: {
                           width_mode: "min",
                           height_mode: "scaled",
                           width: width
                       }
                   };
                   var fig = LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer, options);
                   if (toolbar) {
                     toolbar.bind(fig);
                   }
               });
               
               break;
           }
       }
   });
   
   observer.observe(containerDiv);
   
   // ----------
   })();
   
   </script>
</div>
</div>
<p>Now, let’s assess whether our efforts to improve the model by addressing outliers have enhanced its predictive capabilities:</p>
<div id="20f40ab8-2085-4aa6-8261-11cc6da6f75d" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_model.run_catboost_CV(X_wo_outliers, y_wo_outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(0.11052917780860605, 0.004569457889717371)</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>By removing the outliers, our cross-validation RMSE score decreased from 0.1125 to 0.1105.</p>
</div>
</div>
</section>
<section id="feature-engineering" class="level1">
<h1>Feature Engineering</h1>
<p>Feature engineering is vital in machine learning as it directly influences a model’s performance and predictive capabilities. By crafting and selecting relevant features, it allows the model to capture meaningful patterns and relationships within the data. Effective feature engineering helps improve model accuracy, enhances its ability to generalize to new data, and enables the extraction of valuable insights, ultimately driving the success and efficacy of machine learning algorithms.</p>
<p>Feature Engineering ideas we will test in this section: - Utilize categorical columns for grouping and transform each numerical variable based on the median. - Generate bins from the continuous variables and apply the same process as described above. - Introduce polynomial features, either individually with a single feature or in combinations of two features. - Form clusters of instances using k-means clustering to capture data similarities and use these clusters as additional features. - Implement other ideas derived from empirical observations or assumptions</p>
<section id="utilize-categorical-columns-for-grouping-and-transform-each-numerical-variable-based-on-the-median" class="level2">
<h2 class="anchored" data-anchor-id="utilize-categorical-columns-for-grouping-and-transform-each-numerical-variable-based-on-the-median">Utilize categorical columns for grouping and transform each numerical variable based on the median</h2>
<p>The idea behind this feature engineering step is to leverage categorical columns as grouping criteria and then calculate the median value for each numerical variable within each group. By doing so, it aims to create new features that capture the central tendency of the numerical data for different categories, allowing the model to better understand and utilize the inherent patterns and variations within the data.</p>
<div id="0d164b87-bef4-4a59-abd1-a0926e55330c" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of unique categories per categorical variables:</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>X_wo_outliers.select_dtypes(<span class="st">"object"</span>).nunique()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>state                   9
kitchen_type            9
street                456
building_condition      7
city                  230
dtype: int64</code></pre>
</div>
</div>
<div id="08d1da86-1b70-4d59-ac38-24f210974dbe" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_categorical_transform(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame, y: pd.Series, transform_type: <span class="bu">str</span> <span class="op">=</span> <span class="st">"mean"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Feature Engineering: Transform categorical features using CatBoost Cross-Validation.</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    This function performs feature engineering by transforming categorical features using CatBoost</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Cross-Validation. It calculates the mean and standard deviation of Out-Of-Fold (OOF) Root Mean</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Squared Error (RMSE) scores for various combinations of categorical and numerical features.</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">    - X (pd.DataFrame): The input DataFrame containing both categorical and numerical features.</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - transform_type (str, optional): The transformation type, such as "mean" or other valid</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">      CatBoost transformations. Defaults to "mean".</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">    - pd.DataFrame: A DataFrame with columns "mean_OOFs," "std_OOFs," "categorical," and "numerical,"</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">      sorted by "mean_OOFs" in ascending order.</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your DataFrame with features (X)</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co">    X = load_data()</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co">    # Perform feature engineering</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co">    result_df = FE_categorical_transform(X, transform_type="mean")</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co">    # View the DataFrame with sorted results</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co">    print(result_df.head())</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Notes:</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co">    - This function uses CatBoost Cross-Validation to assess the quality of transformations for</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="co">      various combinations of categorical and numerical features.</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="co">    - The resulting DataFrame provides insights into the effectiveness of different transformations.</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="co">    - Feature engineering can help improve the performance of machine learning models.</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store results</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get a list of categorical and numerical columns</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    categorical_columns <span class="op">=</span> X.select_dtypes(<span class="st">"object"</span>).columns</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> X.select_dtypes(<span class="st">"number"</span>).columns</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine the loops to have a single progress bar</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> categorical <span class="kw">in</span> tqdm(categorical_columns, desc<span class="op">=</span><span class="st">"Progress"</span>):</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> numerical <span class="kw">in</span> tqdm(numerical_columns):</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a deep copy of the input data</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>            temp <span class="op">=</span> X.copy(deep<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate the transformation for each group within the categorical column</span></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>            temp[<span class="st">"new_column"</span>] <span class="op">=</span> temp.groupby(categorical)[numerical].transform(</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>                transform_type</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Run CatBoost Cross-Validation with the transformed data</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>            mean_OOF, std_OOF <span class="op">=</span> train_model.run_catboost_CV(temp, y)</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store the results as a tuple</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> (mean_OOF, std_OOF, categorical, numerical)</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>            results.append(result)</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>            <span class="kw">del</span> temp, mean_OOF, std_OOF</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a DataFrame from the results and sort it by mean OOF scores</span></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>        results, columns<span class="op">=</span>[<span class="st">"mean_OOFs"</span>, <span class="st">"std_OOFs"</span>, <span class="st">"categorical"</span>, <span class="st">"numerical"</span>]</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(by<span class="op">=</span><span class="st">"mean_OOFs"</span>)</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Please, bear in mind that these feature engineering steps were precomputed due to the considerable computational time required. The outcomes were saved rather than executed during the notebook rendering to save time. However, it’s important to note that the results should remain unchanged.</p>
</div>
</div>
<div id="f3443f1d-7840-4521-ac93-9ceb9b349465" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>FE_categorical_transform_mean <span class="op">=</span> feature_engineering.FE_categorical_transform(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers, y_wo_outliers</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<div id="46f939d1-2b4c-4bf3-ba9a-ac24f863c2b6" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>FE_categorical_transform_mean.to_parquet(</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_categorical_transform_mean"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>FE_categorical_transform_mean.head(<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<p>As evident, the best result was obtained by treating the city feature as a categorical variable and calculating the median of cadastral_income based on this categorization. This result aligns logically with the feature importances seen in Part 3.</p>
<div id="ef81da53-c9ea-47b6-9249-1caddf010d66" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    Path.cwd().joinpath(<span class="st">"data"</span>).joinpath(<span class="st">"FE_categorical_transform_mean.parquet.gzip"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">categorical</th>
<th data-quarto-table-cell-role="th">numerical</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">53</td>
<td>0.108973</td>
<td>0.006262</td>
<td>city</td>
<td>cadastral_income</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>0.108985</td>
<td>0.004980</td>
<td>building_condition</td>
<td>yearly_theoretical_total_energy_consumption</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">33</td>
<td>0.109381</td>
<td>0.005434</td>
<td>building_condition</td>
<td>bedrooms</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>0.109478</td>
<td>0.004887</td>
<td>street</td>
<td>cadastral_income</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">43</td>
<td>0.109540</td>
<td>0.004944</td>
<td>building_condition</td>
<td>living_area</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="generate-bins-from-the-continuous-variables" class="level2">
<h2 class="anchored" data-anchor-id="generate-bins-from-the-continuous-variables">Generate bins from the continuous variables</h2>
<p>The idea behind this feature engineering step is to discretize continuous variables by creating bins or categories from their values. These bins then serve as categorical columns. By using these new categorical columns for grouping, we can transform each numerical variable by replacing its values with the median of the respective category it belongs to, just like the feature engineering method we demonstrated above.</p>
<div id="503cddfd-3224-489e-82f6-1c3804e38723" class="cell" data-scrolled="true" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_continuous_transform(</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame, y: pd.Series, transform_type: <span class="bu">str</span> <span class="op">=</span> <span class="st">"mean"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Feature Engineering: Transform continuous features using CatBoost Cross-Validation.</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">    This function performs feature engineering by transforming continuous features using CatBoost</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Cross-Validation. It calculates the mean and standard deviation of Out-Of-Fold (OOF) Root Mean</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Squared Error (RMSE) scores for various combinations of discretized and transformed continuous</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">    features.</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - X (pd.DataFrame): The input DataFrame containing both continuous and categorical features.</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">    - y (pd.Series): The target variable for prediction.</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">    - transform_type (str, optional): The transformation type, such as "mean" or other valid</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">      CatBoost transformations. Defaults to "mean".</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">    - pd.DataFrame: A DataFrame with columns "mean_OOFs," "std_OOFs," "discretized_continuous,"</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co">      and "transformed_continuous," sorted by "mean_OOFs" in ascending order.</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your DataFrame with features (X) and target variable (y)</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y = load_data()</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co">    # Perform feature engineering</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">    result_df = FE_continuous_transform(X, y, transform_type="mean")</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="co">    # View the DataFrame with sorted results</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="co">    print(result_df.head())</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co">    Notes:</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="co">    - This function uses CatBoost Cross-Validation to assess the quality of transformations for</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="co">      various combinations of discretized and transformed continuous features.</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co">    - The number of bins for discretization is determined using Sturges' rule.</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="co">    - The resulting DataFrame provides insights into the effectiveness of different transformations.</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="co">    - Feature engineering can help improve the performance of machine learning models.</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store results</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get a list of continuous and numerical columns</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>    continuous_columns <span class="op">=</span> X.select_dtypes(<span class="st">"number"</span>).columns</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>    optimal_bins <span class="op">=</span> <span class="bu">int</span>(np.floor(np.log2(X.shape[<span class="dv">0</span>])) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine the loops to have a single progress bar</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> discretized_continuous <span class="kw">in</span> tqdm(continuous_columns, desc<span class="op">=</span><span class="st">"Progress:"</span>):</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> transformed_continuous <span class="kw">in</span> tqdm(continuous_columns):</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> discretized_continuous <span class="op">!=</span> transformed_continuous:</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Create a deep copy of the input data</span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>                temp <span class="op">=</span> X.copy(deep<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>                discretizer <span class="op">=</span> pipeline.Pipeline(</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>                    steps<span class="op">=</span>[</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>                        (<span class="st">"imputer"</span>, impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"median"</span>)),</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>                        (</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"add_bins"</span>,</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>                            preprocessing.KBinsDiscretizer(</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>                                encode<span class="op">=</span><span class="st">"ordinal"</span>, n_bins<span class="op">=</span>optimal_bins</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>                            ),</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>                        ),</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>                    ]</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>                temp[discretized_continuous] <span class="op">=</span> discretizer.fit_transform(</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>                    X[[discretized_continuous]]</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate the transformation for each group within the categorical column</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>                temp[<span class="st">"new_column"</span>] <span class="op">=</span> temp.groupby(discretized_continuous)[</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>                    transformed_continuous</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>                ].transform(transform_type)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Run CatBoost Cross-Validation with the transformed data</span></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>                mean_OOF, std_OOF <span class="op">=</span> train_model.run_catboost_CV(temp, y)</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Store the results as a tuple</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>                result <span class="op">=</span> (</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>                    mean_OOF,</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>                    std_OOF,</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>                    discretized_continuous,</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>                    transformed_continuous,</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>                results.append(result)</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>                <span class="kw">del</span> temp, mean_OOF, std_OOF</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a DataFrame from the results and sort it by mean OOF scores</span></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>        results,</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>        columns<span class="op">=</span>[</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mean_OOFs"</span>,</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>            <span class="st">"std_OOFs"</span>,</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>            <span class="st">"discretized_continuous"</span>,</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>            <span class="st">"transformed_continuous"</span>,</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(by<span class="op">=</span><span class="st">"mean_OOFs"</span>)</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="d279df62-4788-41a9-a74c-2a955ceb9500" class="cell" data-scrolled="true" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>FE_continuous_transform_mean <span class="op">=</span> feature_engineering.FE_continuous_transform(</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers, y_wo_outliers</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>FE_continuous_transform_mean.to_parquet(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_continuous_transform_mean"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>FE_categorical_transform_mean.head(<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<p>This approach was not as effective as our prior method. However, combining bathrooms with yearly_theoretical_total_energy_consumption yielded the best outcome.</p>
<div id="e9bf6228-9edd-4817-ba59-8d6a1ad1aa82" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    Path.cwd().joinpath(<span class="st">"data"</span>).joinpath(<span class="st">"FE_continuous_transform_mean.parquet.gzip"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">discretized_continuous</th>
<th data-quarto-table-cell-role="th">transformed_continuous</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">55</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>yearly_theoretical_total_energy_consumption</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">59</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>living_area</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">58</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>cadastral_income</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">57</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>lat</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">56</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>surface_of_the_plot</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>bedrooms</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">52</td>
<td>0.109328</td>
<td>0.005094</td>
<td>bathrooms</td>
<td>toilets</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>0.109417</td>
<td>0.004831</td>
<td>lng</td>
<td>living_area</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.109426</td>
<td>0.004587</td>
<td>bedrooms</td>
<td>toilets</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.109426</td>
<td>0.004587</td>
<td>bedrooms</td>
<td>bathrooms</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="introduce-polynomial-features" class="level2">
<h2 class="anchored" data-anchor-id="introduce-polynomial-features">Introduce polynomial features</h2>
<p>The idea behind introducing polynomial features is to capture non-linear relationships within the data. By raising individual features to higher powers or considering interactions between pairs of features, this step allows the model to better represent complex patterns that cannot be adequately expressed with linear relationships alone. It enhances the model’s ability to learn and predict outcomes that exhibit curvilinear or interactive behavior.</p>
<div id="adf47d82-5752-49f7-8db8-c6a01fa2f9b7" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_polynomial_features(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame, y: pd.Series, combinations: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate polynomial features for combinations of numerical columns and train a CatBoost model.</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X (pd.DataFrame): The input DataFrame with features.</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">        y (pd.Series): The target variable.</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">        combinations (int, optional): The number of combinations of numerical columns. Default is 1.</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame containing results sorted by mean OOF scores.</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">        X_wo_outliers = pd.DataFrame(...)  # Your input data</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co">        y_wo_outliers = pd Series(...)  # Your target variable</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co">        result = FE_polynomial_features(X_wo_outliers, y_wo_outliers)</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Transformations:</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="co">        - Imputes missing values in numerical columns using the median.</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co">        - Generates polynomial features, including interaction terms, for selected numerical columns.</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co">        - Trains a CatBoost model and calculates mean and standard deviation of out-of-fold (OOF) scores.</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store results</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get a list of continuous and numerical columns</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> X.select_dtypes(<span class="st">"number"</span>).columns</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine the loops to have a single progress bar</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> numerical_col <span class="kw">in</span> tqdm(</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>        <span class="bu">list</span>(itertools.combinations(numerical_columns, r<span class="op">=</span>combinations))</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        polyfeatures <span class="op">=</span> compose.make_column_transformer(</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>            (</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>                pipeline.make_pipeline(</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>                    impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"median"</span>),</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>                    preprocessing.PolynomialFeatures(interaction_only<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>                <span class="bu">list</span>(numerical_col),</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>            remainder<span class="op">=</span><span class="st">"passthrough"</span>,</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>        ).set_output(transform<span class="op">=</span><span class="st">"pandas"</span>)</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>        temp <span class="op">=</span> polyfeatures.fit_transform(X)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>        mean_OOF, std_OOF <span class="op">=</span> train_model.run_catboost_CV(X<span class="op">=</span>temp, y<span class="op">=</span>y)</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the results as a tuple</span></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> (</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>            mean_OOF,</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>            std_OOF,</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>            numerical_col,</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>        results.append(result)</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> temp, mean_OOF, std_OOF</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a DataFrame from the results and sort it by mean OOF scores</span></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>        results,</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>        columns<span class="op">=</span>[</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mean_OOFs"</span>,</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">"std_OOFs"</span>,</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>            <span class="st">"numerical_col"</span>,</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(by<span class="op">=</span><span class="st">"mean_OOFs"</span>)</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="n1" class="level3">
<h3 class="anchored" data-anchor-id="n1">n=1</h3>
<p>Let’s see the impact of applying polynomial feature engineering to a single feature.</p>
<div id="a6d4296b-76e0-4b6d-9e7c-247d6af927ea" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_1 <span class="op">=</span> FE_polynomial_features(</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers, y_wo_outliers</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_1.to_parquet(</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_polynomial_features_combinations_1"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_1.head(<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<div id="2672ed57-3010-4c78-bf33-657df58ebe5a" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    Path.cwd()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    .joinpath(<span class="st">"data"</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    .joinpath(<span class="st">"FE_polynomial_features_combinations_1.parquet.gzip"</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">numerical_col</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>0.109938</td>
<td>0.005047</td>
<td>[living_area]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>0.110339</td>
<td>0.004012</td>
<td>[cadastral_income]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.110628</td>
<td>0.004018</td>
<td>[lng]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>0.111066</td>
<td>0.004765</td>
<td>[bedrooms]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.111099</td>
<td>0.005039</td>
<td>[lat]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.111166</td>
<td>0.004879</td>
<td>[primary_energy_consumption]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.111271</td>
<td>0.004908</td>
<td>[yearly_theoretical_total_energy_consumption]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.111276</td>
<td>0.005359</td>
<td>[number_of_frontages]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>0.111332</td>
<td>0.004815</td>
<td>[surface_of_the_plot]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0.111782</td>
<td>0.004741</td>
<td>[toilets]</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="n2" class="level3">
<h3 class="anchored" data-anchor-id="n2">n=2</h3>
<p>How about two features combined…</p>
<div id="9bd8d39a-8386-4e24-85ab-22e09b042c6d" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_2 <span class="op">=</span> FE_polynomial_features(</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers, y_wo_outliers, combinations<span class="op">=</span><span class="dv">2</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_2.to_parquet(</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_polynomial_features_combinations_2"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>FE_polynomial_features_combinations_2.head(<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<div id="1bc6c241-9f61-429e-9232-949cbadfe6db" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    Path.cwd()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    .joinpath(<span class="st">"data"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    .joinpath(<span class="st">"FE_polynomial_features_combinations_2.parquet.gzip"</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">numerical_col</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">31</td>
<td>0.109413</td>
<td>0.004690</td>
<td>[lng, lat]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>0.109625</td>
<td>0.005558</td>
<td>[bedrooms, living_area]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">53</td>
<td>0.109809</td>
<td>0.005321</td>
<td>[lat, living_area]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">52</td>
<td>0.109814</td>
<td>0.003485</td>
<td>[lat, cadastral_income]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>0.109847</td>
<td>0.005399</td>
<td>[bedrooms, lat]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>0.109962</td>
<td>0.004999</td>
<td>[toilets, lng]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">17</td>
<td>0.110057</td>
<td>0.004554</td>
<td>[number_of_frontages, cadastral_income]</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">42</td>
<td>0.110124</td>
<td>0.004511</td>
<td>[bathrooms, lat]</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">46</td>
<td>0.110128</td>
<td>0.004944</td>
<td>[yearly_theoretical_total_energy_consumption, ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">28</td>
<td>0.110154</td>
<td>0.004644</td>
<td>[lng, bathrooms]</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="form-clusters-of-instances-using-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="form-clusters-of-instances-using-k-means-clustering">Form clusters of instances using k-means clustering</h2>
<p>The idea behind using k-means clustering in feature engineering is to group data points into clusters based on their similarity. By doing so, we create a new set of features that represent these clusters, which can capture patterns or relationships within the data that might be less apparent in the original features. These cluster features can be valuable for machine learning models, as they provide a more compact and informative representation of the data, potentially improving predictive performance.</p>
<div id="cb08cb73-1e17-4c67-af85-51424aec5533" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FeatureSelector(BaseEstimator, TransformerMixin):</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">    A transformer for selecting specific columns from a DataFrame.</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This class inherits from the BaseEstimator and TransformerMixin classes from sklearn.base.</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co">    It overrides the fit and transform methods from the parent classes.</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Attributes:</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co">        feature_names_in_ (list): The names of the features to select.</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co">        n_features_in_ (int): The number of features to select.</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Methods:</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co">        fit(X, y=None): Fit the transformer. Returns self.</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co">        transform(X, y=None): Apply the transformation. Returns a DataFrame with selected features.</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feature_names_in_):</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Constructs all the necessary attributes for the FeatureSelector object.</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co">            feature_names_in_ (list): The names of the features to select.</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_names_in_ <span class="op">=</span> feature_names_in_</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_features_in_ <span class="op">=</span> <span class="bu">len</span>(feature_names_in_)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Fit the transformer. This method doesn't do anything as no fitting is necessary.</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co">            X (DataFrame): The input data.</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="co">            y (array-like, optional): The target variable. Defaults to None.</span></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="co">            self: The instance itself.</span></span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the transformation. Selects the features from the input data.</span></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a><span class="co">            X (DataFrame): The input data.</span></span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a><span class="co">            y (array-like, optional): The target variable. Defaults to None.</span></span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a><span class="co">            DataFrame: A DataFrame with only the selected features.</span></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X.loc[:, <span class="va">self</span>.feature_names_in_].copy(deep<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="194e33c9-d9d8-4838-8e6d-bdb429a8b37d" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_KMeans(</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    y: pd.Series,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    n_clusters_min: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    n_clusters_max: <span class="bu">int</span> <span class="op">=</span> <span class="dv">8</span>,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Performs K-Means clustering-based feature engineering followed by model training.</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co">        X (pd.DataFrame): The input feature matrix.</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co">        y (pd.Series): The target variable.</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co">        n_clusters_min (int, optional): The minimum number of clusters to consider. Defaults to 1.</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co">        n_clusters_max (int, optional): The maximum number of clusters to consider. Defaults to 8.</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame containing the results of feature engineering with K-Means clustering.</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co">        &gt;&gt;&gt; results_df = FE_KNN(X_wo_outliers, y_wo_outliers)</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store results</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get a list of continuous and numerical columns</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> X.head().select_dtypes(<span class="st">"number"</span>).columns.to_list()</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    categorical_columns <span class="op">=</span> X.head().select_dtypes(<span class="st">"object"</span>).columns.to_list()</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n_cluster <span class="kw">in</span> tqdm(<span class="bu">range</span>(n_clusters_min, n_clusters_max)):</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare pipelines for corresponding columns:</span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        numerical_pipeline <span class="op">=</span> pipeline.Pipeline(</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>            steps<span class="op">=</span>[</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"num_selector"</span>, FeatureSelector(numerical_columns)),</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"imputer"</span>, impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"median"</span>)),</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        categorical_pipeline <span class="op">=</span> pipeline.Pipeline(</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>            steps<span class="op">=</span>[</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"cat_selector"</span>, FeatureSelector(categorical_columns)),</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"imputer"</span>, impute.SimpleImputer(strategy<span class="op">=</span><span class="st">"most_frequent"</span>)),</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>                (</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"onehot"</span>,</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>                    preprocessing.OneHotEncoder(</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>                        handle_unknown<span class="op">=</span><span class="st">"ignore"</span>, sparse_output<span class="op">=</span><span class="va">False</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>                    ),</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Put all the pipelines inside a FeatureUnion:</span></span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>        data_preprocessing_pipeline <span class="op">=</span> pipeline.FeatureUnion(</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>            n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>            transformer_list<span class="op">=</span>[</span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"numerical_pipeline"</span>, numerical_pipeline),</span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>                (<span class="st">"categorical_pipeline"</span>, categorical_pipeline),</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>        temp <span class="op">=</span> pd.DataFrame(data_preprocessing_pipeline.fit_transform(X))</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>        KMeans <span class="op">=</span> cluster.KMeans(n_init<span class="op">=</span><span class="dv">10</span>, n_clusters<span class="op">=</span>n_cluster)</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>        KMeans.fit_transform(temp)</span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>        groups <span class="op">=</span> pd.Series(KMeans.labels_, name<span class="op">=</span><span class="st">"groups"</span>)</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>        concatanated_df <span class="op">=</span> pd.concat([temp, groups], axis<span class="op">=</span><span class="st">"columns"</span>)</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>        mean_OOF, std_OOF <span class="op">=</span> train_model.run_catboost_CV(X<span class="op">=</span>concatanated_df, y<span class="op">=</span>y)</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the results as a tuple</span></span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> (</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>            mean_OOF,</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a>            std_OOF,</span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a>            n_cluster,</span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a>        results.append(result)</span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> temp, mean_OOF, std_OOF, KMeans, groups, concatanated_df, result</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-80"><a href="#cb35-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a DataFrame from the results and sort it by mean OOF scores</span></span>
<span id="cb35-81"><a href="#cb35-81" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb35-82"><a href="#cb35-82" aria-hidden="true" tabindex="-1"></a>        results,</span>
<span id="cb35-83"><a href="#cb35-83" aria-hidden="true" tabindex="-1"></a>        columns<span class="op">=</span>[</span>
<span id="cb35-84"><a href="#cb35-84" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mean_OOFs"</span>,</span>
<span id="cb35-85"><a href="#cb35-85" aria-hidden="true" tabindex="-1"></a>            <span class="st">"std_OOFs"</span>,</span>
<span id="cb35-86"><a href="#cb35-86" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_cluster"</span>,</span>
<span id="cb35-87"><a href="#cb35-87" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb35-88"><a href="#cb35-88" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb35-89"><a href="#cb35-89" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(by<span class="op">=</span><span class="st">"mean_OOFs"</span>)</span>
<span id="cb35-90"><a href="#cb35-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="e4b6d05b-1ff9-4a07-be0b-290da1bf41de" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>FE_KMeans_df <span class="op">=</span> FE_KMeans(</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    y_wo_outliers,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    n_clusters_min<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    n_clusters_max<span class="op">=</span><span class="dv">101</span>,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>FE_KMeans_df.to_parquet(</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_KNN_df"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>FE_KNN_df.head(<span class="dv">15</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<p>As k-means clustering is an unsupervised algorithm, determining the appropriate k-values requires testing various values to assess their impact on our validation scores. As observed, this approach didn’t yield significant results in our case, as the best validation score was obtained when n=1.</p>
<div id="1184b2d8-6a24-4dc1-aa22-b3d2f6c7e68d" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(Path.cwd().joinpath(<span class="st">"data"</span>).joinpath(<span class="st">"FE_KNN_df.parquet.gzip"</span>)).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">n_cluster</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.111884</td>
<td>0.005143</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.112153</td>
<td>0.006174</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>0.112264</td>
<td>0.005858</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">24</td>
<td>0.112313</td>
<td>0.005602</td>
<td>25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>0.112326</td>
<td>0.005124</td>
<td>8</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>0.112333</td>
<td>0.005819</td>
<td>44</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">31</td>
<td>0.112352</td>
<td>0.005588</td>
<td>32</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>0.112366</td>
<td>0.005206</td>
<td>12</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">95</td>
<td>0.112454</td>
<td>0.006621</td>
<td>96</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">26</td>
<td>0.112472</td>
<td>0.006096</td>
<td>27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="implement-other-ideas-derived-from-empirical-observations-or-assumptions" class="level2">
<h2 class="anchored" data-anchor-id="implement-other-ideas-derived-from-empirical-observations-or-assumptions">Implement other ideas derived from empirical observations or assumptions</h2>
<p>Though new features can be generated through systematic methods, domain knowledge can also inspire their creation. The idea behind this is to allow for the incorporation of unconventional or domain-specific insights that may not fit standard feature engineering techniques. It encourages the exploration of novel features or transformations based on practical experiences or theoretical assumptions to potentially uncover hidden patterns or relationships within the data. This open-ended approach can lead to creative and tailored feature engineering solutions.</p>
<p><strong>Here are some ideas to consider:</strong></p>
<ol type="1">
<li><strong>Geospatial Features:</strong>
<ul>
<li>Create clusters or neighborhoods based on features to capture similarities.</li>
</ul></li>
<li><strong>Area-related Features:</strong>
<ul>
<li>Calculate the ratio of “living_area” to “surface_of_the_plot” to get an idea of the density or spaciousness of the property.</li>
</ul></li>
<li><strong>Energy Efficiency Features:</strong>
<ul>
<li>Compute the energy efficiency ratio by dividing “yearly_theoretical_total_energy_consumption” by “primary_energy_consumption.”</li>
<li>Compute energy efficiency by dividing primary_energy_consumption with living_area</li>
</ul></li>
<li><strong>Toilet and Bathroom Features:</strong>
<ul>
<li>Combine “toilets” and “bathrooms” into a single “total_bathrooms” feature to simplify the model.</li>
<li>Calculate total number of rooms by adding up bedrooms + toilets + bathrooms</li>
</ul></li>
<li><strong>Taxation Features:</strong>
<ul>
<li>Incorporate “cadastral_income” as a measure of property value for taxation. You can create bins or categories for this variable.</li>
</ul></li>
<li><strong>Value for Money:</strong>
<ul>
<li>Divide cadastral_income by bedrooms to see if the property is a good bargain</li>
<li>similarly, Divide cadastral_income by living_area</li>
</ul></li>
</ol>
<div id="fa7365cc-aec4-4d9f-8cc3-d71092fd4637" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_ideas(X):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Performs additional feature engineering on the input DataFrame.</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">        X (pd.DataFrame): The input DataFrame containing the original features.</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame with additional engineered features.</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">        &gt;&gt;&gt; engineered_data = FE_ideas(original_data)</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> X.assign(</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        energy_efficiency_1<span class="op">=</span><span class="kw">lambda</span> df: df.yearly_theoretical_total_energy_consumption</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="op">/</span> df.primary_energy_consumption,</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        energy_efficiency_2<span class="op">=</span><span class="kw">lambda</span> df: df.primary_energy_consumption <span class="op">/</span> df.living_area,</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        total_bathrooms<span class="op">=</span><span class="kw">lambda</span> df: df.toilets <span class="op">+</span> df.bathrooms,</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        total_number_rooms<span class="op">=</span><span class="kw">lambda</span> df: df.toilets <span class="op">+</span> df.bathrooms <span class="op">+</span> df.bedrooms,</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>        spaciousness_1<span class="op">=</span><span class="kw">lambda</span> df: df.living_area <span class="op">/</span> df.surface_of_the_plot,</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>        spaciousness_2<span class="op">=</span><span class="kw">lambda</span> df: df.living_area <span class="op">/</span> df.total_number_rooms,</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        bargain_1<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.bedrooms,</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        bargain_2<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.living_area,</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> temp.loc[:, <span class="st">"energy_efficiency_1"</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="a24297aa-fdff-4034-ae26-4a383f27f767" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> FE_try_ideas(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    X: pd.DataFrame,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    y: pd.Series,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> pd.DataFrame:</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Performs feature engineering experiments by adding new features and evaluating their impact on model performance.</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co">        X (pd.DataFrame): The input feature matrix.</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co">        y (pd.Series): The target variable.</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: A DataFrame containing the results of feature engineering experiments.</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co">        &gt;&gt;&gt; results_df = FE_try_ideas(X, y)</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to store results</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get a list of continuous and numerical columns</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> X.select_dtypes(<span class="st">"number"</span>).columns</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply additional feature engineering ideas</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    feature_df <span class="op">=</span> FE_ideas(X)</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feature <span class="kw">in</span> tqdm(feature_df.columns):</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate the original features with the newly engineered feature</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>        temp <span class="op">=</span> pd.concat([X, feature_df[feature]], axis<span class="op">=</span><span class="st">"columns"</span>)</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train the model with the augmented features and get the mean and standard deviation of OOF scores</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>        mean_OOF, std_OOF <span class="op">=</span> train_model.run_catboost_CV(X<span class="op">=</span>temp, y<span class="op">=</span>y)</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store the results as a tuple</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> (</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>            mean_OOF,</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>            std_OOF,</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>            feature,</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>        results.append(result)</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> temp, mean_OOF, std_OOF</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a DataFrame from the results and sort it by mean OOF scores</span></span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a>        results,</span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>        columns<span class="op">=</span>[</span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">"mean_OOFs"</span>,</span>
<span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">"std_OOFs"</span>,</span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">"feature"</span>,</span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb40-51"><a href="#cb40-51" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> result_df.sort_values(by<span class="op">=</span><span class="st">"mean_OOFs"</span>)</span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="abd5518f-2a07-4850-8264-bbd5d881c9eb" class="cell" data-execution_count="31">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>script echo skipping</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>FE_try_ideas <span class="op">=</span> FE_try_ideas(X_wo_outliers, y_wo_outliers)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>FE_try_ideas.to_parquet(</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f'</span><span class="sc">{</span>utils<span class="sc">.</span>Configuration<span class="sc">.</span>INTERIM_DATA_PATH<span class="sc">.</span>joinpath(<span class="st">"FE_try_ideas"</span>)<span class="sc">}</span><span class="ss">.parquet.gzip'</span>,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    compression<span class="op">=</span><span class="st">"gzip"</span>,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>FE_try_ideas</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Couldn't find program: 'echo'</code></pre>
</div>
</div>
<p>As can be seen below, the best feature this time was <code>spaciousness_1</code>, representing <code>df.living_area</code> divided by <code>df.surface_of_the_plot</code>.</p>
<div id="31d160a3-181e-48e3-830d-c32a2251e863" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>pd.read_parquet(Path.cwd().joinpath(<span class="st">"data"</span>).joinpath(<span class="st">"FE_try_ideas.parquet.gzip"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_OOFs</th>
<th data-quarto-table-cell-role="th">std_OOFs</th>
<th data-quarto-table-cell-role="th">feature</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.109305</td>
<td>0.004652</td>
<td>spaciousness_1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0.109558</td>
<td>0.004372</td>
<td>bargain_2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.109969</td>
<td>0.005117</td>
<td>total_number_rooms</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>0.109976</td>
<td>0.004303</td>
<td>bargain_1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.110545</td>
<td>0.004884</td>
<td>total_bathrooms</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.110603</td>
<td>0.004715</td>
<td>spaciousness_2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.110666</td>
<td>0.005749</td>
<td>energy_efficiency_2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>0.110722</td>
<td>0.005120</td>
<td>energy_efficiency_1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="summary-table-of-the-tested-conditions" class="level1">
<h1>Summary table of the tested conditions</h1>
<p>The initial model achieved the best mean out-of-folds score of 0.1107. However, we made modifications to expedite training by reducing iterations to 100 and increasing the learning rate to 0.2, resulting in a new baseline model with a score of 0.1105 after outlier removal. This serves as our reference point to assess the impact of various feature engineering techniques.</p>
<p>Subsequent feature engineering approaches, including utilizing categorical columns for groupby and transformation, creating bins from continuous data, and implementing other ideas, led to marginal score improvements, with the lowest at 0.1089. Polynomial features, with n=2 and n=1, demonstrated slightly higher scores of 0.1094 and 0.1099, respective.</p>
<p>Now, we will proceed to assess the efficacy of two of the best approaches, namely: utilizing categorical columns for groupby and transformation and implementing additional ideas. We will conduct this evaluation using CatBoost’s built-in <code>select_features</code> as outlined in part 3. Let’s dive in…</p>
<table class="caption-top table">
<colgroup>
<col style="width: 64%">
<col style="width: 20%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Condition</strong></th>
<th style="text-align: center;"><strong>Best mean OOFs</strong></th>
<th style="text-align: center;"><strong>std OOFs</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><em>Original</em></strong></td>
<td style="text-align: center;"><strong><em>0.1107</em></strong></td>
<td style="text-align: center;"><strong><em>NA</em></strong></td>
</tr>
<tr class="even">
<td>Use categorical columns for groupby/transform</td>
<td style="text-align: center;">0.1089</td>
<td style="text-align: center;">0.0062</td>
</tr>
<tr class="odd">
<td>Create bins from continuous data and use groupby/transform</td>
<td style="text-align: center;">0.1093</td>
<td style="text-align: center;">0.0050</td>
</tr>
<tr class="even">
<td>Implementing the rest of the ideas</td>
<td style="text-align: center;">0.1093</td>
<td style="text-align: center;">0.0046</td>
</tr>
<tr class="odd">
<td>Polynomial features (n=2)</td>
<td style="text-align: center;">0.1094</td>
<td style="text-align: center;">0.0046</td>
</tr>
<tr class="even">
<td>Polynomial features (n=1)</td>
<td style="text-align: center;">0.1099</td>
<td style="text-align: center;">0.0050</td>
</tr>
<tr class="odd">
<td>After Outlier filter</td>
<td style="text-align: center;">0.1105</td>
<td style="text-align: center;">0.0045</td>
</tr>
<tr class="even">
<td>k-means clustering</td>
<td style="text-align: center;">0.1118</td>
<td style="text-align: center;">0.0051</td>
</tr>
<tr class="odd">
<td>Sped up version</td>
<td style="text-align: center;">0.1125</td>
<td style="text-align: center;">0.0044</td>
</tr>
</tbody>
</table>
</section>
<section id="final-feature-selection" class="level1">
<h1>Final feature selection</h1>
<div id="8bdccd5d-68c3-48b5-9180-0223f300a8c8" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_df_for_final_feature_selection(X):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X.assign(</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>        city_group<span class="op">=</span><span class="kw">lambda</span> df: df.groupby(<span class="st">"city"</span>)[<span class="st">"cadastral_income"</span>].transform(</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">"median"</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>        building_condition_group<span class="op">=</span><span class="kw">lambda</span> df: df.groupby(<span class="st">"building_condition"</span>)[</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"yearly_theoretical_total_energy_consumption"</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        ].transform(<span class="st">"median"</span>),</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        energy_efficiency_1<span class="op">=</span><span class="kw">lambda</span> df: df.yearly_theoretical_total_energy_consumption</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        <span class="op">/</span> df.primary_energy_consumption,</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        energy_efficiency_2<span class="op">=</span><span class="kw">lambda</span> df: df.primary_energy_consumption <span class="op">/</span> df.living_area,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        total_bathrooms<span class="op">=</span><span class="kw">lambda</span> df: df.toilets <span class="op">+</span> df.bathrooms,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        total_number_rooms<span class="op">=</span><span class="kw">lambda</span> df: df.toilets <span class="op">+</span> df.bathrooms <span class="op">+</span> df.bedrooms,</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>        spaciousness_1<span class="op">=</span><span class="kw">lambda</span> df: df.living_area <span class="op">/</span> df.surface_of_the_plot,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>        spaciousness_2<span class="op">=</span><span class="kw">lambda</span> df: df.living_area <span class="op">/</span> df.total_number_rooms,</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>        bargain_1<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.bedrooms,</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>        bargain_2<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.living_area,</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>X_final_feature_selection <span class="op">=</span> prepare_df_for_final_feature_selection(X_wo_outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="efdb8a06-4b3d-4edb-9aab-93255c99d6a0" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> model_selection.train_test_split(</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    X_final_feature_selection,</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    y_wo_outliers,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span>utils.Configuration.seed,</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="1a059df9-0adc-4dfa-a93b-af112fe9fdb5" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>regressor <span class="op">=</span> catboost.CatBoostRegressor(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    iterations<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    cat_features<span class="op">=</span>X_final_feature_selection.select_dtypes(<span class="st">"object"</span>).columns.to_list(),</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    random_seed<span class="op">=</span>utils.Configuration.seed,</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    loss_function<span class="op">=</span><span class="st">"RMSE"</span>,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>rfe_dict <span class="op">=</span> regressor.select_features(</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    algorithm<span class="op">=</span><span class="st">"RecursiveByShapValues"</span>,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    shap_calc_type<span class="op">=</span><span class="st">"Exact"</span>,</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X_train,</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y_train,</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>    eval_set<span class="op">=</span>(X_val, y_val),</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    features_for_select<span class="op">=</span><span class="st">"0-25"</span>,</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    num_features_to_select<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    train_final_model<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    plot<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Learning rate set to 0.059655
Step #1 out of 20
0:  learn: 0.3071998    test: 0.3029816 best: 0.3029816 (0) total: 13.6ms   remaining: 13.6s
999:    learn: 0.0482570    test: 0.1076466 best: 0.1075005 (964)   total: 14.9s    remaining: 0us

bestTest = 0.1075004858
bestIteration = 964

Shrink model to first 965 iterations.
Feature #21 eliminated
Feature #20 eliminated
Feature #23 eliminated
Feature #2 eliminated
Step #2 out of 20
0:  learn: 0.3070684    test: 0.3029727 best: 0.3029727 (0) total: 14.1ms   remaining: 14.1s
999:    learn: 0.0497732    test: 0.1094414 best: 0.1092710 (833)   total: 14.1s    remaining: 0us

bestTest = 0.1092709663
bestIteration = 833

Shrink model to first 834 iterations.
Feature #4 eliminated
Feature #22 eliminated
Feature #24 eliminated
Step #3 out of 20
0:  learn: 0.3058962    test: 0.3017255 best: 0.3017255 (0) total: 14.2ms   remaining: 14.1s
999:    learn: 0.0515838    test: 0.1074155 best: 0.1074083 (998)   total: 13.9s    remaining: 0us

bestTest = 0.1074082848
bestIteration = 998

Shrink model to first 999 iterations.
Feature #12 eliminated
Feature #0 eliminated
Feature #7 eliminated
Step #4 out of 20
0:  learn: 0.3062525    test: 0.3017927 best: 0.3017927 (0) total: 14.5ms   remaining: 14.4s
999:    learn: 0.0549456    test: 0.1092524 best: 0.1092519 (996)   total: 12.8s    remaining: 0us

bestTest = 0.1092518693
bestIteration = 996

Shrink model to first 997 iterations.
Feature #9 eliminated
Feature #3 eliminated
Step #5 out of 20
0:  learn: 0.3069279    test: 0.3031549 best: 0.3031549 (0) total: 20.9ms   remaining: 20.9s
999:    learn: 0.0566761    test: 0.1092288 best: 0.1091824 (846)   total: 12.5s    remaining: 0us

bestTest = 0.1091824436
bestIteration = 846

Shrink model to first 847 iterations.
Feature #6 eliminated
Feature #11 eliminated
Step #6 out of 20
0:  learn: 0.3065169    test: 0.3023901 best: 0.3023901 (0) total: 16.8ms   remaining: 16.8s
999:    learn: 0.0567811    test: 0.1114134 best: 0.1113041 (981)   total: 14.9s    remaining: 0us

bestTest = 0.1113040714
bestIteration = 981

Shrink model to first 982 iterations.
Feature #1 eliminated
Feature #25 eliminated
Step #7 out of 20
0:  learn: 0.3063087    test: 0.3019867 best: 0.3019867 (0) total: 15.1ms   remaining: 15.1s
999:    learn: 0.0554371    test: 0.1123259 best: 0.1122143 (920)   total: 31s  remaining: 0us

bestTest = 0.1122143004
bestIteration = 920

Shrink model to first 921 iterations.
Feature #5 eliminated
Feature #8 eliminated
Step #8 out of 20
0:  learn: 0.3068859    test: 0.3026476 best: 0.3026476 (0) total: 3.82ms   remaining: 3.81s
999:    learn: 0.0574991    test: 0.1152245 best: 0.1152077 (992)   total: 2.1s remaining: 0us

bestTest = 0.1152077068
bestIteration = 992

Shrink model to first 993 iterations.
Feature #13 eliminated
Step #9 out of 20
0:  learn: 0.3068033    test: 0.3025327 best: 0.3025327 (0) total: 2.82ms   remaining: 2.81s
999:    learn: 0.0640641    test: 0.1201366 best: 0.1201130 (689)   total: 2.13s    remaining: 0us

bestTest = 0.1201130073
bestIteration = 689

Shrink model to first 690 iterations.
Feature #19 eliminated
Step #10 out of 20
0:  learn: 0.3069152    test: 0.3030754 best: 0.3030754 (0) total: 1.96ms   remaining: 1.96s
999:    learn: 0.0703171    test: 0.1242382 best: 0.1236966 (778)   total: 2.13s    remaining: 0us

bestTest = 0.1236965761
bestIteration = 778

Shrink model to first 779 iterations.
Feature #18 eliminated
Step #11 out of 20
0:  learn: 0.3073732    test: 0.3033657 best: 0.3033657 (0) total: 2.05ms   remaining: 2.05s
999:    learn: 0.0750814    test: 0.1247368 best: 0.1246789 (969)   total: 2.14s    remaining: 0us

bestTest = 0.1246789365
bestIteration = 969

Shrink model to first 970 iterations.
Feature #10 eliminated
Step #12 out of 20
0:  learn: 0.3073693    test: 0.3032811 best: 0.3032811 (0) total: 1.83ms   remaining: 1.83s
999:    learn: 0.0914355    test: 0.1353158 best: 0.1351822 (880)   total: 2.25s    remaining: 0us

bestTest = 0.1351822259
bestIteration = 880

Shrink model to first 881 iterations.
Step #13 out of 20
0:  learn: 0.3073693    test: 0.3032811 best: 0.3032811 (0) total: 1.74ms   remaining: 1.74s
999:    learn: 0.0914355    test: 0.1353158 best: 0.1351822 (880)   total: 2.4s remaining: 0us

bestTest = 0.1351822259
bestIteration = 880

Shrink model to first 881 iterations.
Feature #17 eliminated
Step #14 out of 20
0:  learn: 0.3071755    test: 0.3033561 best: 0.3033561 (0) total: 1.86ms   remaining: 1.86s
999:    learn: 0.1071168    test: 0.1503970 best: 0.1496295 (720)   total: 2.19s    remaining: 0us

bestTest = 0.1496294939
bestIteration = 720

Shrink model to first 721 iterations.
Step #15 out of 20
0:  learn: 0.3071755    test: 0.3033561 best: 0.3033561 (0) total: 2.74ms   remaining: 2.74s
999:    learn: 0.1071168    test: 0.1503970 best: 0.1496295 (720)   total: 2.27s    remaining: 0us

bestTest = 0.1496294939
bestIteration = 720

Shrink model to first 721 iterations.
Feature #14 eliminated
Step #16 out of 20
0:  learn: 0.3069654    test: 0.3029158 best: 0.3029158 (0) total: 6.46ms   remaining: 6.45s
999:    learn: 0.1272584    test: 0.1579738 best: 0.1574747 (784)   total: 2.15s    remaining: 0us

bestTest = 0.1574747019
bestIteration = 784

Shrink model to first 785 iterations.
Step #17 out of 20
0:  learn: 0.3069654    test: 0.3029158 best: 0.3029158 (0) total: 2.92ms   remaining: 2.92s
999:    learn: 0.1272584    test: 0.1579738 best: 0.1574747 (784)   total: 2.2s remaining: 0us

bestTest = 0.1574747019
bestIteration = 784

Shrink model to first 785 iterations.
Step #18 out of 20
0:  learn: 0.3069654    test: 0.3029158 best: 0.3029158 (0) total: 1.77ms   remaining: 1.77s
999:    learn: 0.1272584    test: 0.1579738 best: 0.1574747 (784)   total: 2.15s    remaining: 0us

bestTest = 0.1574747019
bestIteration = 784

Shrink model to first 785 iterations.
Feature #16 eliminated
Step #19 out of 20
0:  learn: 0.3099541    test: 0.3058748 best: 0.3058748 (0) total: 4.3ms    remaining: 4.3s
999:    learn: 0.2075860    test: 0.2206064 best: 0.2148488 (114)   total: 2.06s    remaining: 0us

bestTest = 0.2148488447
bestIteration = 114

Shrink model to first 115 iterations.
Step #20 out of 20
0:  learn: 0.3099541    test: 0.3058748 best: 0.3058748 (0) total: 4.43ms   remaining: 4.43s
999:    learn: 0.2075860    test: 0.2206064 best: 0.2148488 (114)   total: 2.13s    remaining: 0us

bestTest = 0.2148488447
bestIteration = 114

Shrink model to first 115 iterations.</code></pre>
</div>
</div>
<p>Based on our evaluation, it is recommended to retain the following features:</p>
<ul>
<li>‘city_group’</li>
<li>‘building_condition_group’</li>
<li>‘energy_efficiency_1’</li>
<li>‘energy_efficiency_2’</li>
<li>‘bargain_1’</li>
<li>‘bargain_2’</li>
</ul>
<p>However, we should remove the following two features since our analysis indicates that better features have been incorporated:</p>
<ul>
<li>‘kitchen_type’</li>
<li>‘toilets’</li>
</ul>
<p>These feature selections should help optimize our model even further.</p>
<p>Based on these insights, we crafted the <code>prepare_data_for_modelling</code> function, which is stored in the <code>pre_process.py</code> file. This function includes the feature engineering steps we discussed, setting the stage for effective modeling performance.</p>
<div id="4f8714b7-c163-4124-a127-fa5cdf7eb7e9" class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_data_for_modelling(df: pd.DataFrame) <span class="op">-&gt;</span> Tuple[pd.DataFrame, pd.Series]:</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Prepare data for machine learning modeling.</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function takes a DataFrame and prepares it for machine learning by performing the following steps:</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co">    1. Randomly shuffles the rows of the DataFrame.</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co">    2. Converts the 'price' column to the base 10 logarithm.</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co">    3. Fills missing values in categorical variables with 'missing value'.</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co">    4. Separates the features (X) and the target (y).</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co">    5. Identifies and filters out outlier values based on LocalOutlierFactor.</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - df (pd.DataFrame): The input DataFrame containing the dataset.</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co">    - Tuple[pd.DataFrame, pd.Series]: A tuple containing the prepared features (X) and the target (y).</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Example use case:</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a><span class="co">    # Load your dataset into a DataFrame (e.g., df)</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="co">    df = load_data()</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a><span class="co">    # Prepare the data for modeling</span></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y = prepare_data_for_modelling(df)</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a><span class="co">    # Now you can use X and y for machine learning tasks.</span></span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a><span class="co">        df (pd.DataFrame): The input DataFrame containing the dataset.</span></span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb48-31"><a href="#cb48-31" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple[pd.DataFrame, pd.Series]: A tuple containing the prepared features (X) and the target (y).</span></span>
<span id="cb48-32"><a href="#cb48-32" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb48-33"><a href="#cb48-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-34"><a href="#cb48-34" aria-hidden="true" tabindex="-1"></a>    processed_df <span class="op">=</span> (</span>
<span id="cb48-35"><a href="#cb48-35" aria-hidden="true" tabindex="-1"></a>        df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>utils.Configuration.seed)</span>
<span id="cb48-36"><a href="#cb48-36" aria-hidden="true" tabindex="-1"></a>        .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-37"><a href="#cb48-37" aria-hidden="true" tabindex="-1"></a>        .assign(</span>
<span id="cb48-38"><a href="#cb48-38" aria-hidden="true" tabindex="-1"></a>            price<span class="op">=</span><span class="kw">lambda</span> df: np.log10(df.price),</span>
<span id="cb48-39"><a href="#cb48-39" aria-hidden="true" tabindex="-1"></a>            city_group<span class="op">=</span><span class="kw">lambda</span> df: df.groupby(<span class="st">"city"</span>)[<span class="st">"cadastral_income"</span>].transform(</span>
<span id="cb48-40"><a href="#cb48-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"median"</span></span>
<span id="cb48-41"><a href="#cb48-41" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb48-42"><a href="#cb48-42" aria-hidden="true" tabindex="-1"></a>            building_condition_group<span class="op">=</span><span class="kw">lambda</span> df: df.groupby(<span class="st">"building_condition"</span>)[</span>
<span id="cb48-43"><a href="#cb48-43" aria-hidden="true" tabindex="-1"></a>                <span class="st">"yearly_theoretical_total_energy_consumption"</span></span>
<span id="cb48-44"><a href="#cb48-44" aria-hidden="true" tabindex="-1"></a>            ].transform(<span class="st">"median"</span>),</span>
<span id="cb48-45"><a href="#cb48-45" aria-hidden="true" tabindex="-1"></a>            energy_efficiency_1<span class="op">=</span><span class="kw">lambda</span> df: df.yearly_theoretical_total_energy_consumption</span>
<span id="cb48-46"><a href="#cb48-46" aria-hidden="true" tabindex="-1"></a>            <span class="op">/</span> df.primary_energy_consumption,</span>
<span id="cb48-47"><a href="#cb48-47" aria-hidden="true" tabindex="-1"></a>            energy_efficiency_2<span class="op">=</span><span class="kw">lambda</span> df: df.primary_energy_consumption</span>
<span id="cb48-48"><a href="#cb48-48" aria-hidden="true" tabindex="-1"></a>            <span class="op">/</span> df.living_area,</span>
<span id="cb48-49"><a href="#cb48-49" aria-hidden="true" tabindex="-1"></a>            bargain_1<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.bedrooms,</span>
<span id="cb48-50"><a href="#cb48-50" aria-hidden="true" tabindex="-1"></a>            bargain_2<span class="op">=</span><span class="kw">lambda</span> df: df.cadastral_income <span class="op">/</span> df.living_area,</span>
<span id="cb48-51"><a href="#cb48-51" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb48-52"><a href="#cb48-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb48-53"><a href="#cb48-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-54"><a href="#cb48-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fill missing categorical variables with "missing value"</span></span>
<span id="cb48-55"><a href="#cb48-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> processed_df.columns:</span>
<span id="cb48-56"><a href="#cb48-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> processed_df[col].dtype.name <span class="kw">in</span> (<span class="st">"bool"</span>, <span class="st">"object"</span>, <span class="st">"category"</span>):</span>
<span id="cb48-57"><a href="#cb48-57" aria-hidden="true" tabindex="-1"></a>            processed_df[col] <span class="op">=</span> processed_df[col].fillna(<span class="st">"missing value"</span>)</span>
<span id="cb48-58"><a href="#cb48-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-59"><a href="#cb48-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Separate features (X) and target (y)</span></span>
<span id="cb48-60"><a href="#cb48-60" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> processed_df.loc[:, utils.Configuration.features_to_keep_v2]</span>
<span id="cb48-61"><a href="#cb48-61" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> processed_df[utils.Configuration.target_col]</span>
<span id="cb48-62"><a href="#cb48-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-63"><a href="#cb48-63" aria-hidden="true" tabindex="-1"></a>    outlier_mask <span class="op">=</span> pre_process.identify_outliers(X)</span>
<span id="cb48-64"><a href="#cb48-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-65"><a href="#cb48-65" aria-hidden="true" tabindex="-1"></a>    X_wo_outliers <span class="op">=</span> X.loc[outlier_mask, :].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-66"><a href="#cb48-66" aria-hidden="true" tabindex="-1"></a>    y_wo_outliers <span class="op">=</span> y.loc[outlier_mask].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-67"><a href="#cb48-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-68"><a href="#cb48-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Shape of X and y with outliers: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb48-69"><a href="#cb48-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb48-70"><a href="#cb48-70" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Shape of X and y without outliers: </span><span class="sc">{</span>X_wo_outliers<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>y_wo_outliers<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb48-71"><a href="#cb48-71" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb48-72"><a href="#cb48-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-73"><a href="#cb48-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_wo_outliers, y_wo_outliers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="9a07ac0a-9075-4ae1-a867-b8b8ae903d5e" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> pre_process.prepare_data_for_modelling(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of X and y with outliers: (3660, 14), (3660,)
Shape of X and y without outliers: (3427, 14), (3427,)</code></pre>
</div>
</div>
<p>In Part 4, we began with an initial selection of 16 features based on the work in Part 3. However, as we conclude this article, we’ve found that we can streamline our feature set even further by removing <code>kitchen_type</code> and <code>toilets</code> resulting in improved performance, thanks to the addition of new features. While there’s potential for further optimizations, such as dimensional reduction, we are currently happy with our progress. In the next, and final, part, we will focus on fine-tuning our model for optimal predictive performance. See you there!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/adamcseresznye\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2024, Adam Cseresznye</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>